<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?DTDIdentifier.IdentifierValue http://null/schema/dtds/document/fulltext/xcr/xocs-article.xsd?><?DTDIdentifier.IdentifierType schema?><?SourceDTD.DTDName xocs-article.xsd?><?SourceDTD.Version 1.0?><?ConverterInfo.XSLTName ftrr2jats.xsl?><?ConverterInfo.Version 1?><?origin publisher?><front><journal-meta><journal-id journal-id-type="nlm-ta">Med Hypotheses</journal-id><journal-id journal-id-type="iso-abbrev">Med. Hypotheses</journal-id><journal-title-group><journal-title>Medical Hypotheses</journal-title></journal-title-group><issn pub-type="ppub">0306-9877</issn><issn pub-type="epub">1532-2777</issn><publisher><publisher-name>Elsevier Ltd.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">S0306-9877(20)30770-2</article-id><article-id pub-id-type="doi">10.1016/j.mehy.2020.109761</article-id><article-id pub-id-type="publisher-id">109761</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>COVIDiagnosis-Net: Deep Bayes-SqueezeNet based diagnosis of the coronavirus disease 2019 (COVID-19) from X-ray images</article-title></title-group><contrib-group><contrib contrib-type="author" id="au005"><name><surname>Ucar</surname><given-names>Ferhat</given-names></name><email>fucar@firat.edu.tr</email><xref rid="af005" ref-type="aff">a</xref><xref rid="cor1" ref-type="corresp">&#x0204e;</xref></contrib><contrib contrib-type="author" id="au010"><name><surname>Korkmaz</surname><given-names>Deniz</given-names></name><xref rid="af010" ref-type="aff">b</xref></contrib><aff id="af005"><label>a</label>Firat University, Faculty of Technology, Department of Electrical and Electronics Engineering, Elazig 23119, Turkey</aff><aff id="af010"><label>b</label>Malatya Turgut Ozal University, Faculty of Engineering and Natural Sciences, Department of Electrical Engineering, Malatya 44210, Turkey</aff></contrib-group><author-notes><corresp id="cor1"><label>&#x0204e;</label>Corresponding author. <email>fucar@firat.edu.tr</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>23</day><month>4</month><year>2020</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="ppub"><month>7</month><year>2020</year></pub-date><pub-date pub-type="epub"><day>23</day><month>4</month><year>2020</year></pub-date><volume>140</volume><fpage>109761</fpage><lpage>109761</lpage><history><date date-type="received"><day>11</day><month>4</month><year>2020</year></date><date date-type="accepted"><day>21</day><month>4</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; 2020 Elsevier Ltd. All rights reserved.</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Elsevier Ltd</copyright-holder><license><license-p>Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.</license-p></license></permissions><abstract abstract-type="graphical" id="ab005"><title>Graphical abstract</title><fig id="f0065" position="anchor"><graphic xlink:href="ga1_lrg"/></fig></abstract><abstract abstract-type="author-highlights" id="ab010"><title>Highlights</title><p><list list-type="simple" id="l0005"><list-item id="o0005"><label>&#x02022;</label><p id="p0005">To develop an intelligent diagnosis system for COVID-19.</p></list-item><list-item id="o0010"><label>&#x02022;</label><p id="p0010">To design a practical deep learning network for medical image processing.</p></list-item><list-item id="o0015"><label>&#x02022;</label><p id="p0015">To propose a novel and efficient decision making system for COVID-19.</p></list-item><list-item id="o0020"><label>&#x02022;</label><p id="p0020">To integrate conventional and state-of-the-art methods for chest X-ray images.</p></list-item></list></p></abstract><abstract id="ab015"><p>The Coronavirus Disease 2019 (COVID-19) outbreak has a tremendous impact on global health and the daily life of people still living in more than two hundred countries. The crucial action to gain the force in the fight of COVID-19 is to have powerful monitoring of the site forming infected patients. Most of the initial tests rely on detecting the genetic material of the coronavirus, and they have a poor detection rate with the time-consuming operation. In the ongoing process, radiological imaging is also preferred where chest X-rays are highlighted in the diagnosis. Early studies express the patients with an abnormality in chest X-rays pointing to the presence of the COVID-19. On this motivation, there are several studies cover the deep learning-based solutions to detect the COVID-19 using chest X-rays. A part of the existing studies use non-public datasets, others perform on complicated Artificial Intelligent (AI) structures. In our study, we demonstrate an AI-based structure to outperform the existing studies. The SqueezeNet that comes forward with its light network design is tuned for the COVID-19 diagnosis with Bayesian optimization additive. Fine-tuned hyperparameters and augmented dataset make the proposed network perform much better than existing network designs and to obtain a higher COVID-19 diagnosis accuracy.</p></abstract><kwd-group id="kg005"><title>Keywords</title><kwd>Coronavirus Disease 2019</kwd><kwd>SARS-CoV-2</kwd><kwd>Rapid Diagnosis of COVID-19</kwd><kwd>Deep Learning</kwd><kwd>Bayesian Optimization</kwd></kwd-group></article-meta></front><body><sec id="s0005"><title>Introduction</title><p id="p0025">Coronavirus outbreak continues to surprise the world. To date, over one million people across the two hundred countries have been infected according to the last updates of the World Health Organization (WHO). Approximately sixty thousand confirmed deaths among the cases are reported <xref rid="b0005" ref-type="bibr">[1]</xref>. Humanity had not faced a pandemic through the history that spreads rapidly all over the earth. If a defined brand new virus is able to spread from person to person while infecting the contacts easily with a sustained and efficient way, then it is called a pandemic. The novel coronavirus (2019-nCoV) fulfills all those definitions strongly. At the end of the year 2019, Wuhan city of China cradled the first case of the novel coronavirus. Now from Europe to America, its deadly effects threaten the whole world. The WHO named the 2019-nCoV epidemic disease on February 11, 2020 as Coronavirus Disease 2019 (COVID-19). 2019-nCoV is a new member of the Severe Acute Respiratory Syndrome coronavirus family (SARS-CoV) and labeled as SARS-CoV-2 <xref rid="b0010" ref-type="bibr">[2]</xref>.</p><p id="p0030">With its spike surface for binding to receptors (see <xref rid="f0005" ref-type="fig">Fig. 1</xref>
), SARS-CoV-2 presents the COVID-19 with the symptoms of fever, sore throat and following pneumonia with severe acute respiratory distress. <xref rid="b0015" ref-type="bibr">[3]</xref>. For all that, the respiratory symptoms are not in a specific form. There are so many isolated cases i.e. the existence of the COVID-19 may not appear at the first clinical symptoms <xref rid="b0020" ref-type="bibr">[4]</xref>. The rapid spreading nature of the coronavirus and the serious respiratory effects to humans make the diagnosis of the COVID-19 an urgent situation <xref rid="b0025" ref-type="bibr">[5]</xref>. Today, health specialists use the Reverse Transcription Polymerase Chain Reaction (RT-PCR) test for the detection of the nucleic acid forms stem from the SARS-CoV-2. In the process, the respiratory specimens (such as oropharyngeal swabs or nasopharyngeal sampling) are collected and the very important issue when doing this is the receipt place of the specimens. The operation is categorically open to malfunctions by the expert mistakes <xref rid="b0030" ref-type="bibr">[6]</xref>. Besides the operation procedure, the PCR test is a time-consuming process. Because a patient has to be isolated in non-suitable circumstances for hours until getting the test results. In addition, these types of tests have a low detection rate of between 30 and 50%. Hence, most of the times they need to be repeated to make a confirmation <xref rid="b0035" ref-type="bibr">[7]</xref>.<fig id="f0005"><label>Fig. 1</label><caption><p>Three-dimensional medical image representing the shape of the coronavirus <xref rid="b0040" ref-type="bibr">[8]</xref>.</p></caption><graphic xlink:href="gr1_lrg"/></fig></p><p id="p0035">To be able to procure an atmosphere where the patients could get quick treatment and care is a crucial task in the fight of the COVID-19. Because of the fast-spreading essence of the pandemic, patients apply to the health center in batches. At this point, the need for rapid diagnosis methods is a very important issue. For monitoring the SARS-CoV-2 infections to diagnose, there is another option of visualization using the radiological images, for instance, chest X-rays or Computed Tomography (CT). Former studies prove that COVID-19 causes abnormalities that are visible in the chest X-rays and CT images, in the form of ground-glass opacities. With a strong suggestion, a diagnostic with radiological images could be a first step in monitoring the COVID-19 <xref rid="b0045" ref-type="bibr">[9]</xref>. Although the radiological images based diagnostic is a faster way and also it has some advances over the PCR testing in terms of the detection rate in earlier stages of the COVID-19, the backbone of the system is the need of experts in comprehending the images. Intrinsically, Artificial Intelligence (AI) based diagnostic options can encourage the experts to gain a rapid and accurate explication over the X-ray images on the way of the detection of the COVID-19 <xref rid="b0050" ref-type="bibr">[10]</xref>.</p><p id="p0040">For this motivation, there are several studies in the literature including the analysis conducted on AI-based diagnostic of the COVID-19 with the help of the radiological images <xref rid="b0055" ref-type="bibr">[11]</xref>, <xref rid="b0060" ref-type="bibr">[12]</xref>, <xref rid="b0065" ref-type="bibr">[13]</xref>, <xref rid="b0070" ref-type="bibr">[14]</xref>, <xref rid="b0075" ref-type="bibr">[15]</xref>. In <xref rid="b0075" ref-type="bibr">[15]</xref>, the authors propose a transfer learning model that processes a dataset including the CT images of the COVID-19 infected patients. They obtain a test accuracy of 79.3%. The study <xref rid="b0070" ref-type="bibr">[14]</xref> indicates a three-class model that can distinguish the COVID-19, Influenza-A viral-based pneumonia, and healthy cases. The segmentation-based study reaches the 86.7% accuracy value with the CT images dataset. In <xref rid="b0065" ref-type="bibr">[13]</xref>, the authors propose a rapid AI development cycle using a deep learning-based CT image analysis. Heretofore, the mentioned studies in the literature use non-public datasets through developing a deep learning-based diagnostic of the COVID-19. The studies <xref rid="b0055" ref-type="bibr">[11]</xref> and <xref rid="b0060" ref-type="bibr">[12]</xref> provides public datasets including the COVID-19 X-ray images of infected patients. In <xref rid="b0055" ref-type="bibr">[11]</xref>, the authors propose a combined public dataset besides a deep learning model called COVID-Net for the detection of COVID-19. COVID-Net architecture relies on a tailored Convolutional Neural Network (CNN) model which uses the chest X-rays as inputs. The authors reach a test accuracy of 92.4% with restricted COVID-19 class images. In our study, we use the same dataset of the <xref rid="b0055" ref-type="bibr">[11]</xref> to be able to outperform the existing COVID-Net accuracy in detecting the COVID-19. In addition, there are several more studies that we can consider in COVID-19 detection using chest X-rays <xref rid="b0080" ref-type="bibr">[16]</xref>, <xref rid="b0085" ref-type="bibr">[17]</xref>, <xref rid="b0090" ref-type="bibr">[18]</xref>, <xref rid="b0095" ref-type="bibr">[19]</xref>. With a detailed pre-processed dataset, our study captures the flag with a specially designed deep learning model.</p><p id="p0045">The usage of deep learning models in medical image processing and analysis is a challenging topic in the AI field <xref rid="b0050" ref-type="bibr">[10]</xref>, <xref rid="b0100" ref-type="bibr">[20]</xref>. In <xref rid="b0105" ref-type="bibr">[21]</xref>, the authors propose a CNN model for pneumonia detection. The authors of the study <xref rid="b0110" ref-type="bibr">[22]</xref> propose a vessel extraction from the fundus images. In <xref rid="b0115" ref-type="bibr">[23]</xref>, an expert system is proposed for brain tumor detection in high-resolution brain magnetic resonance images. To this end, in our study, we use a specially designed deep learning model called SqueezeNet first proposed in <xref rid="b0120" ref-type="bibr">[24]</xref>. The proposed deep learning model for the diagnostic of the COVID-19 is based on SqueezeNet architecture, as because it has a smaller structure, compared to the well-known pre-trained network designs <xref rid="b0125" ref-type="bibr">[25]</xref>, <xref rid="b0130" ref-type="bibr">[26]</xref>.</p><p id="p0050">In this study, we introduce a COVID-19 detection AI model, COVIDiagnosis-Net, based on deep SqueezeNet with Bayes optimization. With a view to obtain a higher accuracy rate, the hyper-parameter optimization of the deep learning models is a crucial task <xref rid="b0135" ref-type="bibr">[27]</xref>. The backbone of the proposed model i.e. the dataset is a public dataset that is detailed in <xref rid="b0055" ref-type="bibr">[11]</xref>. Differently from the study <xref rid="b0055" ref-type="bibr">[11]</xref>, we perform a multi-scale augmentation process to overcome the imbalance problem of the proposed public dataset. Since the focus is on COVID-19 diagnosis, we perform a detailed offline augmentation process for the limited number of COVID-19 infected chest X-rays of the patients. With the help of the offline well-defined augmentation process and Bayes-SqueezeNet, our proposed diagnostic model for COVID-19 outperforms the COVID-Net <xref rid="b0055" ref-type="bibr">[11]</xref> while reaching a test accuracy of <bold>0.983</bold>. In building our model, we first perform a detailed augmentation. After obtaining the augmented dataset, the data split is generated on the shuffled database to form the train, validation and test datasets. We manage the training process of the deep SqueezeNet while performing a Bayes optimization with the validation phase at the same time. Through the training, the best model is determined and the final network design is tested with the separate test dataset package. On through those developments, the proposed deep Bayes &#x02013; SqueezeNet obtains a higher detection rate in the diagnosis of the COVID-19 using the chest X-ray images.</p><p id="p0055">Herein, we can describe the contributions of our proposed model as listed below:<list list-type="simple" id="l0010"><list-item id="o0025"><label>1)</label><p id="p0060">Presents a novel model for the rapid diagnostic of the COVID-19 based on deep Bayes-SqueezeNet called COVIDiagnosis-Net,</p></list-item><list-item id="o0030"><label>2)</label><p id="p0065">Overcomes the imbalance problem of the public dataset, a multi-scale offline augmentation is performed,</p></list-item><list-item id="o0035"><label>3)</label><p id="p0070">Proposes an easy to implement deep learning network for embedded and mobile systems that could aid the health experts for a stable diagnosis of the COVID-19 in the control of the current epidemic.</p></list-item></list>
</p><p id="p0075">The composition of the rest of the article is as follows: Section 2 describes the materials and methods with details of the proposed deep Bayes-SqueezeNet along with the model components i.e. SqueezeNet architecture, Bayesian optimization, and dataset description. Section 3 presents the explanation of what we design in experiments with evaluation criteria, findings, and a comparison sub-section to draw the big picture of where our study stands among the other state-of-the-art methods. Finally, Section 4 briefs a conclusion of the study.</p></sec><sec id="s0010"><title>Materials and methods</title><p id="p0080">CNN models achieve human-like accuracies in image classification problems due to their self-learning abilities and superior classification results on multi-class problems. A convolution network occurs from a chain of a convolution layer (Conv) with a rectified linear unit (ReLu) activation functions, pooling layers (Pool) and batch normalization operation. CNNs are coordinated versions of multilayer perceptrons and each neuron in a layer is related to all neurons in the next layer. Layers convolute inputs with kernels and filters of the convolutions increase across the whole visual field. These processes compose more complex patterns using smaller and simpler patterns depending on the hierarchical patterns. Therefore, the hierarchical network structure provides high-level feature maps, reduced computation complexity and improved generalization ability <xref rid="b0110" ref-type="bibr">[22]</xref>, <xref rid="b0140" ref-type="bibr">[28]</xref>, <xref rid="b0145" ref-type="bibr">[29]</xref>. Considering these types of characteristics, Bayesian optimization based deep SqueezeNet architecture for diagnostic of COVID-19 disease from X-ray images is proposed in this paper.</p><p id="p0085">The main purpose of our framework is to provide distinctive visual properties as well as a rapid diagnostic system able to classify those properties on new COVID-19 X-ray images. This method may also be helpful for clinicians because it may be quickly decided which treatment plan to use depending on the type of infection. The following sections describe the proposed method, deep SqueezeNet architecture, Bayesian optimization, dataset description and offline augmentation techniques in detail.</p><sec id="s0015"><title>Proposed method: Deep Bayes-SqueezeNet based COVIDiagnosis-Net</title><p id="p0090">The overall architecture of the deep Bayes-SqueezeNet based rapid diagnostic system is presented in <xref rid="f0010" ref-type="fig">Fig. 2</xref>
. The proposed system is composed of three main stages as offline augmentation of the raw dataset, training of the Bayesian optimization-based SqueezeNet model and decision-making of the network with the testing phase. The proposed method classifies the three-class X-ray images labeled as Normal (no infection), Pneumonia (bacterial or none-COVID viral infection) and Covid (COVID-19 viral infection).<fig id="f0010"><label>Fig. 2</label><caption><p>Architecture of the deep Bayes-SqueezeNet based rapid diagnostic system.</p></caption><graphic xlink:href="gr2_lrg"/></fig></p><p id="p0095">In the first stage, the offline augmentation method is utilized to the raw input x-ray images due to their uneven sample distributions. This method is preferred for smaller classes with fewer sample numbers in order to increase the size of the classes by a transformation factor. After the augmentation, the augmented dataset is divided into three subsets as train, validation and test sets. Train and validation sets are set as the input of the training and optimization stage. The test set is used for the testing input. In the training and optimization stage, the SqueezeNet convolution network is utilized and it uses the squeeze and expands layers of the fire modules to construct a smaller and more effective CNN architecture. SqueezeNet is a pre-trained CNN model and it is pre-trained on the ILSVRC-12 challenge ImageNet dataset <xref rid="b0150" ref-type="bibr">[30]</xref>, <xref rid="b0155" ref-type="bibr">[31]</xref>. This supporting dataset is completely different from X-ray images and the SqueezeNet model needs to be fine-tuned to classify the COVIDx classes. In order to obtain the best decision-making model, the CNN network is optimized with the Bayesian-based method, which is a sequential design strategy, during training. A validation error is used to update the optimization process. Finally, the best SqueezeNet model is obtained and used for the decision-making process with the test set. The obtained best network model classifies the infection classes and classification performances are determined.</p></sec><sec id="s0020"><title>SqueezeNet architecture</title><p id="p0100">SqueezeNet is a convolution network that executes better performance than AlexNet with 50x fewer parameters <xref rid="b0115" ref-type="bibr">[23]</xref>, <xref rid="b0120" ref-type="bibr">[24]</xref>, <xref rid="b0150" ref-type="bibr">[30]</xref>. SqueezeNet consists of fifteen layers with five different layers as two convolution layers, three max pooling layers, eight fire layers, one global average pooling layer, and one output layer softmax. The architecture of the network is given in <xref rid="f0015" ref-type="fig">Fig. 3</xref>
.<fig id="f0015"><label>Fig. 3</label><caption><p>Details on the designed SqueezeNet architecture.</p></caption><graphic xlink:href="gr3_lrg"/></fig></p><p id="p0105">As shown in <xref rid="f0015" ref-type="fig">Fig. 3</xref>, K&#x000a0;&#x000d7;&#x000a0;K notation represents the receptive field size of the filters, s denotes the stride size and <italic>l</italic> is the feature map length, respectively. The input of the network has 227&#x000a0;&#x000d7;&#x000a0;227 dimensions with RGB channels. The input images are generalized by convolution and max pooling is applied. Convolution layer convolutes between the weights and small regions in the input volumes, with 3&#x000a0;&#x000d7;&#x000a0;3 kernels. Each convolution layer performs an element-wise activation function as the positive part of its argument. SqueezeNet utilizes from the fire layers, which constructed of squeeze and expansion phases, between the convolution layers. The output tensor scale and input of the fire are consistent. The squeeze phase uses the filter of size 1&#x000a0;&#x000d7;&#x000a0;1, whereas expansion uses the filters of size 1&#x000a0;&#x000d7;&#x000a0;1 and 3&#x000a0;&#x000d7;&#x000a0;3. Firstly, the input tensor H&#x000a0;&#x000d7;&#x000a0;W&#x000a0;&#x000d7;&#x000a0;C passes through the squeeze and the number of convolution is equal to C/4 of the number of input tensor channels. After the first phase, the data passes through the expansions and depth of the data is expanded to C/2 of the output tensor depth. Both squeeze and expansion phases are connected to the ReLu units. The squeeze operation compresses the depth, and expansion increases the depth by keeping the same feature size. Finally, expansion outputs are stacked in the depth dimension of input tensor with concatenate operation. <xref rid="f0020" ref-type="fig">Fig. 4</xref>
summarizes the fire layer and sub-operations. Assuming <italic>FM</italic> and <italic>C</italic> define the feature maps and channels, the output layer <italic>f</italic>{<italic>y</italic>} of the squeeze operation with the kernel <italic>w</italic> can be expressed as <xref rid="b0160" ref-type="bibr">[32]</xref>:<disp-formula id="e0005"><label>(1)</label><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:munderover><mml:mo movablelimits="false">&#x02211;</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mi>m</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="italic">FM</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:munderover><mml:mo movablelimits="false">&#x02211;</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:msubsup><mml:msubsup><mml:mi>x</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
<fig id="f0020"><label>Fig. 4</label><caption><p>Microstructure of the fire layer.</p></caption><graphic xlink:href="gr4_lrg"/></fig></p><p id="p0110">Here, <inline-formula><mml:math id="M2" altimg="si2.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M3" altimg="si3.svg"><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>F</mml:mi><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The squeeze outputs can be defined as a weighted combination of the feature maps of the different tensors. In the network, max pool layers execute a down-sampling operation along the spatial dimensions and global average pool convert the feature maps of the classes into one value. At the end of the network, softmax activation function gives the multiclass probability distributions.</p><p id="p0115">
<xref rid="t0005" ref-type="table">Table 1</xref>
presents the detailed layer configuration of the SqueezeNet architecture. The motivation for designing the SqueezeNet architecture in COVID-19 diagnosis is that the network provides three main advantages <xref rid="b0115" ref-type="bibr">[23]</xref>, <xref rid="b0120" ref-type="bibr">[24]</xref>: 1) The network is more efficient because it has fewer parameters, 2) Applications developed for this network are easy to move and require less communication, 3) It has a model size of less than 5&#x000a0;MB and it is easy to implement to embedded systems.<table-wrap position="float" id="t0005"><label>Table 1</label><caption><p>Detailed layer configuration of the designed network.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Layer</th><th>Type</th><th>Kernel Size</th><th>Stride</th><th>Padding</th><th>Output Size</th></tr></thead><tbody><tr><td>Input</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td><td>227&#x000a0;&#x000d7;&#x000a0;227&#x000a0;&#x000d7;&#x000a0;3</td></tr><tr><td>Conv1</td><td>{Conv&#x000a0;+&#x000a0;ReLu}</td><td>3&#x000a0;&#x000d7;&#x000a0;3</td><td>2</td><td>0</td><td>113&#x000a0;&#x000d7;&#x000a0;113&#x000a0;&#x000d7;&#x000a0;64</td></tr><tr><td>Pool1</td><td>Max Pool</td><td>3&#x000a0;&#x000d7;&#x000a0;3</td><td>2</td><td>0</td><td>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;64</td></tr><tr><td>Fire2</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;16<break/>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;64<break/>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;128</td></tr><tr><td>Fire3</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;16<break/>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;64<break/>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;128</td></tr><tr><td>Pool3</td><td>Max Pool</td><td>3&#x000a0;&#x000d7;&#x000a0;3</td><td>2</td><td>0</td><td>28&#x000a0;&#x000d7;&#x000a0;28&#x000a0;&#x000d7;&#x000a0;128</td></tr><tr><td>Fire4</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>28&#x000a0;&#x000d7;&#x000a0;28&#x000a0;&#x000d7;&#x000a0;32<break/>28&#x000a0;&#x000d7;&#x000a0;28&#x000a0;&#x000d7;&#x000a0;128<break/>28&#x000a0;&#x000d7;&#x000a0;28&#x000a0;&#x000d7;&#x000a0;256</td></tr><tr><td>Fire5</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>28&#x000a0;&#x000d7;&#x000a0;28&#x000a0;&#x000d7;&#x000a0;32<break/>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;128<break/>56&#x000a0;&#x000d7;&#x000a0;56&#x000a0;&#x000d7;&#x000a0;256</td></tr><tr><td>Pool5</td><td>Max Pool</td><td>3&#x000a0;&#x000d7;&#x000a0;3</td><td>2</td><td>0</td><td>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;256</td></tr><tr><td>Fire6</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;48<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;192<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;384</td></tr><tr><td>Fire7</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;48<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;192<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;384</td></tr><tr><td>Fire8</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;64<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;256<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;512</td></tr><tr><td>Fire9</td><td>{Squeeze&#x000a0;+&#x000a0;ReLu-Expand&#x000a0;+&#x000a0;ReLu-Concat}<break/>{Expand&#x000a0;+&#x000a0;ReLu}//2</td><td>1&#x000a0;&#x000d7;&#x000a0;1<break/>3&#x000a0;&#x000d7;&#x000a0;3</td><td>1<break/>1</td><td>0<break/>1</td><td>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;64<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;256<break/>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;512</td></tr><tr><td>Conv10</td><td>{Conv&#x000a0;+&#x000a0;ReLu}</td><td>1&#x000a0;&#x000d7;&#x000a0;1</td><td>1</td><td>0</td><td>14&#x000a0;&#x000d7;&#x000a0;14&#x000a0;&#x000d7;&#x000a0;3</td></tr><tr><td>Pool10</td><td>Global Average Pool</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td><td>1&#x000a0;&#x000d7;&#x000a0;1&#x000a0;&#x000d7;&#x000a0;3</td></tr><tr><td>Output</td><td>Softmax</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td><td>1&#x000a0;&#x000d7;&#x000a0;1&#x000a0;&#x000d7;&#x000a0;3</td></tr></tbody></table></table-wrap></p></sec><sec id="s0025"><title>Bayesian optimization</title><p id="p0120">Hyperparameters have a key role in both machine learning and deep learning algorithms inasmuch as those parameters are tightly managing the acts of the training algorithms and they affect the performance of the models significantly. Therefore, the optimization of hyperparameters is a crucial task, especially when it comes to deep learning in medical image processing. In general, there exist two ways of hyperparameters optimization called manual and automatic searching. The manual searching as the name suggests looks for the hyperparameters by hand. Hence, manual searching requires expertise. Unfortunately, when dealing with big data and so many model parameters for tuning, even expertise may be insufficient <xref rid="b0135" ref-type="bibr">[27]</xref>, <xref rid="b0165" ref-type="bibr">[33]</xref>. To handle the difficulties of manually searching, automatic searching alternatives take place in the literature. Grid search and random search algorithms can be considered in this topic. Nevertheless, there are still problems remaining in both methods such as the curse of dimensionality, and unavailability of the highly efficient performance with the time-consuming operations <xref rid="b0135" ref-type="bibr">[27]</xref>, <xref rid="b0170" ref-type="bibr">[34]</xref>.</p><p id="p0125">Tuning of hyperparameters is such an optimization problem that the objective function of it is latent and unknown, in other words, it is a black-box function. As its name suggests, stemming from the Bayesian theorem, the Bayesian optimization is an efficient algorithm dealing with such kind of optimization problem <xref rid="b0135" ref-type="bibr">[27]</xref>, <xref rid="b0175" ref-type="bibr">[35]</xref>. Bayesian optimization relies on a typical kind of approximation. Dealing with an unknown function requires an approximation with the help of some known samples i.e. prior knowledge. It is like the concept of the posteriori probability. Here, the food of the algorithm is observations generated by the model evaluations in which the outputs of the online learning. This means that, in Bayesian optimization, we need a training process. During the training, the model will trace a function that we only have its knowledge from the learned data. In the center of the Bayesian optimization algorithm, the main purpose is to obtain the related hyperparameters that make learning outline maximum <xref rid="b0180" ref-type="bibr">[36]</xref>. In mathematical expression, we can consider a global maximization or minimization problem of the black box (unknown) function<inline-formula><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula>,<disp-formula id="e0010"><label>(2)</label><mml:math id="M5" altimg="si5.svg"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>&#x02662;</mml:mo></mml:msup><mml:mo linebreak="goodbreak">=</mml:mo><mml:munder><mml:mrow><mml:mo>arg</mml:mo><mml:mo movablelimits="true">max</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="normal">X</mml:mi></mml:mrow></mml:munder><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p id="p0130">Here, <inline-formula><mml:math id="M6" altimg="si6.svg"><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula> stands for a searching space of<inline-formula><mml:math id="M7" altimg="si7.svg"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>. Caused by the nature of the Bayes&#x02019; theorem <xref rid="b0175" ref-type="bibr">[35]</xref>, Bayesian optimization calculates the posteriori probability <inline-formula><mml:math id="M8" altimg="si8.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> of a model <inline-formula><mml:math id="M9" altimg="si9.svg"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula> with the aid of the learned data <inline-formula><mml:math id="M10" altimg="si10.svg"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>. Posteriori probability is proportional to the likelihood <inline-formula><mml:math id="M11" altimg="si11.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> of observations <inline-formula><mml:math id="M12" altimg="si10.svg"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> and the multiplication of the prior probability<inline-formula><mml:math id="M13" altimg="si12.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>:<disp-formula id="e0015"><label>(3)</label><mml:math id="M14" altimg="si13.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0221d;</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p id="p0135">Eq. <xref rid="e0015" ref-type="disp-formula">(3)</xref> reflects the main behavior of the Bayesian optimization <xref rid="b0135" ref-type="bibr">[27]</xref>. In brief, Bayesian optimization searches for the best model amid many of them. At this point, one can recall the cross &#x02013; validation method. However, it is very hard to find the best model in many samples of pre-listed hundreds of alternatives. Thus, Bayesian optimization accelerates the operation by reducing the computational cost, and we do not need expertise to guess the outputs though <xref rid="b0185" ref-type="bibr">[37]</xref>. The algorithm combines the prior distribution of the<inline-formula><mml:math id="M15" altimg="si14.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>function with the samples of the prior knowledge to obtain the posteriors. Those posteriors calculate the value which describes the maximization point of the<inline-formula><mml:math id="M16" altimg="si15.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Herein, the criterion of the maximization process is the expression called acquisition function. We introduce a pseudo-code format of Bayesian optimization via Algorithm 1 table. In the algorithm, <inline-formula><mml:math id="M17" altimg="si16.svg"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> reflects the training dataset, which includes <inline-formula><mml:math id="M18" altimg="si17.svg"><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> observations of the <inline-formula><mml:math id="M19" altimg="si4.svg"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula>function.</p><p id="p0140">In the flow, we can clarify the two basic parts of the algorithm: 1) it updates the posterior distribution and 2) it maximizes the acquisition function. Bayesian optimization process continues repeatedly until the defined maximum iteration value is reached. Alternatively, it can also be quitted when it catches a threshold value, which is the difference between the actual value and the obtained optimal value <xref rid="b0135" ref-type="bibr">[27]</xref>, <xref rid="b0180" ref-type="bibr">[36]</xref>.<table-wrap position="float" id="t0045"><table frame="hsides" rules="groups"><tbody><tr><td colspan="2">Algorithm 1: Bayesian optimization</td></tr><tr><td>1:</td><td>for <inline-formula><mml:math id="M20" altimg="si18.svg"><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> do</td></tr><tr><td>2:</td><td>Search <inline-formula><mml:math id="M21" altimg="si19.svg"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> via optimizing the acquisition function <inline-formula><mml:math id="M22" altimg="si20.svg"><mml:mrow><mml:mi>&#x003c5;</mml:mi></mml:mrow></mml:math></inline-formula>,</td></tr><tr><td/><td><inline-formula><mml:math id="M23" altimg="si21.svg"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">arg</mml:mi><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>x</mml:mi></mml:munder><mml:mi>&#x003bd;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>3:</td><td>Evaluate the objective function: <inline-formula><mml:math id="M24" altimg="si22.svg"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>4:</td><td>Augment data<inline-formula><mml:math id="M25" altimg="si23.svg"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td/><td>Update the model</td></tr><tr><td>5:</td><td>end for</td></tr></tbody></table></table-wrap>In the proposed deep Bayes-SqueezeNet model, the most important hyperparameter of the deep network design called &#x0201c;initial learning rate&#x0201d; is optimized beside the L2-regularization and the momentum values. We also provide a validation dataset to be able to track the validation error (object function) in the online training. (Please find the experiment details of the Bayesian optimization in Section 3.)</p></sec><sec id="s0030"><title>Dataset description</title><p id="p0145">As declared before, the general detection method for COVID-19 disease is the RT-PCR testing that identifies SARS-CoV-2 RNA from sputum or nasopharyngeal swab. However, RT-PCR testing has a long time complex process and it is very troublesome <xref rid="b0030" ref-type="bibr">[6]</xref>. Another detection method is chest radiography imaging due to the abnormalities in chest X-ray images of patients infected with COVID-19 <xref rid="b0010" ref-type="bibr">[2]</xref>, <xref rid="b0055" ref-type="bibr">[11]</xref>. Therefore, we have selected a distinctive and public dataset including chest X-ray images to respond to the need for a rapid disease diagnosis system <xref rid="b0055" ref-type="bibr">[11]</xref>. In order to compose a special COVID-19 dataset, two different publicly available datasets were combined as COVID chest X-ray dataset <xref rid="b0060" ref-type="bibr">[12]</xref> and Kaggle chest X-ray pneumonia dataset <xref rid="b0190" ref-type="bibr">[38]</xref>. The obtained COVIDx dataset <xref rid="b0055" ref-type="bibr">[11]</xref> consists of a total of 5949 posteroanterior chest radiography images for 2839 patient cases. The dataset includes 1583 normal, 4290 pneumonia and 76 COVID-19 infection cases. In the pneumonia samples, diseases were caused by none-COVID-19 viral and bacterial effects. Considering the number of cases, there are a total of 1203 uninfected normal patients, 1591 pneumonia cases with none-COVID-19 and 45 COVID-19 patient cases. The dataset includes three classes and <xref rid="f0025" ref-type="fig">Fig. 5</xref>
shows a batch of images that are randomly selected from class samples. The images are transformed to RGB with 8-bit depth and have variable pixel-based resolution values.<fig id="f0025"><label>Fig. 5</label><caption><p>Randomly selected COVIDx X-ray samples: (a) Normal, (b) Pneumonia, (c) COVID-19.</p></caption><graphic xlink:href="gr5_lrg"/></fig></p><p id="p0150">The main purpose of the selection of COVIDx dataset is that it is public available, so it is accessible for researchers and to be extensible. Therefore, further studies based on this database may be more helpful in the diagnosis and treatment of COVID-19 cases.</p></sec><sec id="s0035"><title>Offline augmentation</title><p id="p0155">In the classification process of both classical machine learning and deep learning algorithms, the imbalance ratio of the class distribution of the dataset has a huge impact on the performances of the models. In the study <xref rid="b0195" ref-type="bibr">[39]</xref>, the authors conduct systematic research on how imbalance data affects the classification performance of CNN. The findings of the study point out a detrimental effect of the imbalanced class distribution on classification performance. In our dataset, there are very few COVID-19 class images compared to the other classes. To overcome this unfavorable situation, we perform a detailed offline augmentation over the COVID-19 class images in our dataset. Firstly, we obtain the mirrored version of the original images by flipping each image. Then, the listed augmentation technics are applied to both original and flipped images.<list list-type="simple" id="l0015"><list-item id="o0040"><label>1)</label><p id="p0160">Noise: Adding Gaussian noise to images,</p></list-item><list-item id="o0045"><label>2)</label><p id="p0165">Shear: Shearing the images in affine form,</p></list-item><list-item id="o0050"><label>3)</label><p id="p0170">Brightness decrease: Decreasing the brightness of the images by subtracting 30 from every pixel,</p></list-item><list-item id="o0055"><label>4)</label><p id="p0175">Brightness increase: Increasing the brightness of the images by adding 30 to every pixel.</p></list-item></list>
</p><p id="p0180">As <xref rid="f0030" ref-type="fig">Fig. 6</xref>
describes, we obtain twelve different images from a single image with the aid of the augmentation techniques and their combinations. The same operations depicted in <xref rid="f0030" ref-type="fig">Fig. 6</xref> are also implemented to the flipped images, which are the mirrored versions of the original images. At the end of the day, we gain twenty-four different images for a single image. Thus, the number of images in the COVID-19 class is augmented offline in the pre-processing of the dataset resulting in an acceptable amount. <xref rid="f0035" ref-type="fig">Fig. 7</xref>
shows a sample image both in original and flipped (mirrored) version.<fig id="f0030"><label>Fig. 6</label><caption><p>Offline augmentation: A demonstration on original image.</p></caption><graphic xlink:href="gr6_lrg"/></fig><fig id="f0035"><label>Fig. 7</label><caption><p>Original image and its flipped version.</p></caption><graphic xlink:href="gr7_lrg"/></fig></p></sec></sec><sec id="s0040"><title>Experiments</title><p id="p0185">In this section, the experimental setup and the evaluation of the proposed deep Bayes-SqueezeNet based rapid diagnosis system are presented. The impact of the proposed method on its accuracy and evaluation metrics are discussed with the computational efficiency. All the experiments are performed in MATLAB environment running on a workstation with 2.1&#x000a0;GHz dual Intel Xeon E5, Quadro M4000 8&#x000a0;GB GPU and 32&#x000a0;GB RAM memory. The remainder of the section includes the definitions of the evaluation metrics, findings of the experimental results and comparison of the state-of-the-art methods, respectively.</p><sec id="s0045"><title>Evaluation metrics</title><p id="p0190">In order to evaluate the quantitative performance of the proposed method, such evaluation metrics Accuracy (Acc), Correctness (COR), Completeness (COM), Specificity (SPE), F1 score and Matthew Correlation Coefficient (MCC) are statistically computed from the confusion matrix. Acc measures the classification performance, COR gives the rate of the truly classified X-ray images among the classes while COM defines the truly detected negative images. SPE represents the correctly classified the rate of opposite disease classes. F1 is a harmonic average and gives the combination of COR and COM. MCC measures the quality of the classification performance. According to the confusion matrix, the selected evaluation metrics are defined as:<disp-formula id="e0020"><label>(4)</label><mml:math id="M26" altimg="si24.svg"><mml:mrow><mml:mtext>Acc</mml:mtext><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="e0025"><label>(5)</label><mml:math id="M27" altimg="si25.svg"><mml:mrow><mml:mtext>COR</mml:mtext><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="e0030"><label>(6)</label><mml:math id="M28" altimg="si26.svg"><mml:mrow><mml:mtext>COM</mml:mtext><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="e0035"><label>(7)</label><mml:math id="M29" altimg="si27.svg"><mml:mrow><mml:mtext>SPE</mml:mtext><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="e0040"><label>(8)</label><mml:math id="M30" altimg="si28.svg"><mml:mrow><mml:mtext>F1</mml:mtext><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mtext>COR</mml:mtext><mml:mo>&#x000d7;</mml:mo><mml:mfrac><mml:mtext>COM</mml:mtext><mml:mrow><mml:mtext>COM</mml:mtext><mml:mo>+</mml:mo><mml:mtext>COR</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="e0045"><label>(9)</label><mml:math id="M31" altimg="si29.svg"><mml:mrow><mml:mtext>MCC</mml:mtext><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:msqrt><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfenced><mml:mo>&#x000d7;</mml:mo><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math></disp-formula>
</p><p id="p0195">Here, <inline-formula><mml:math id="M32" altimg="si30.svg"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> define the number of correctly classified diseases, number of correctly classified opposite classes, number of incorrectly classified diseases and number of the misclassified diseases, respectively. The classification procedure proves and determines the robustness, effectiveness and generalization ability of the proposed method using the aforementioned evaluation metrics.</p></sec><sec id="s0050"><title>Experimental results</title><p id="p0200">In the experimental setup, firstly we perform an offline augmentation to the raw COVIDx dataset. After the pre-processing, the augmented dataset is divided into three packages as training, validation and testing sets. The triple split of the dataset packages is formed as 80% for training, 10% for validation and 10% for testing. Training and validation datasets are designed for the Bayesian optimization-based online learning structure. As because of the Bayesian contribution of our model, it needs a validation result to minimize the objective function error. After the Bayesian optimization-based online training process, we reach the best network model to implement the testing phase. With a separate test dataset, the obtained best model is evaluated. All the input images are resized to 227&#x000a0;&#x000d7;&#x000a0;227 pixel size and transformed to RGB with 8-bit depth. In the meantime, all the dataset packages are shuffled to overcome the negative effect of the overfitting. Thus, we reach a robust decision-making performance for the classification of the infected patient cases. In the training process, mini-batch size is given as 32 and all images are normalized with the mean subtracting operation.</p><p id="p0205">
<xref rid="t0010" ref-type="table">Table 2</xref>
shows the class distribution of the raw and augmented dataset. In the pre-processing, we achieve 1536 images after the augmentation of COVID-19 class. Since other classes have sufficient images each, we perform the augmentation to just Covid class. We also provide a balanced dataset fixing the all class image numbers to 1536 samples to gain a robust training performance of the model. Briefly, our offline augmentation model enhances the Covid class approximately 20 times. In our proposed model, we improve the existing dataset by increasing the Covid class images.<table-wrap position="float" id="t0010"><label>Table 2</label><caption><p>COVIDx Dataset class distributions.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th/><th colspan="3">Raw Dataset<hr/></th><th colspan="3">Augmented Dataset<hr/></th></tr><tr><th>No</th><th>Class Label</th><th>Train</th><th>Validation</th><th>Test</th><th>Train</th><th>Validation</th><th>Test</th></tr></thead><tbody><tr><td>1</td><td>Covid</td><td>66</td><td>&#x02013;</td><td>10</td><td>1229</td><td>154</td><td>153</td></tr><tr><td>2</td><td>Normal</td><td>1349</td><td>&#x02013;</td><td>234</td><td>1229</td><td>154</td><td>153</td></tr><tr><td>3</td><td>Pneumonia</td><td>3895</td><td>&#x02013;</td><td>395</td><td>1229</td><td>154</td><td>153</td></tr><tr><td colspan="2">Total</td><td>5310</td><td>&#x02013;</td><td>639</td><td>3687</td><td>462</td><td>459</td></tr></tbody></table></table-wrap></p><p id="p0210">Proposed deep Bayes-SqueezeNet includes the Bayesian optimization in the training stage with validation process. The objective function of the optimization process is given in <xref rid="f0040" ref-type="fig">Fig. 8</xref>
. It can be seen that function evaluation ends with 35 iterations because of the model saturation. At the end of the 10th iteration, the minimum observed objective is achieved to construct the best model.<fig id="f0040"><label>Fig. 8</label><caption><p>Bayesian optimization - objective function tracking.</p></caption><graphic xlink:href="gr8_lrg"/></fig></p><p id="p0215">The optimized parameters i.e. initial learning rate (InitialLearnRate), momentum, and L2 Regularization are listed in <xref rid="t0015" ref-type="table">Table 3</xref>
along with iterations, model result, run time and observed - estimation values of the objective function. During the optimization process, it is clearly seen that after catching five different best models, Bayesian optimization points out the model of the 10th iteration as selected &#x0201c;best model&#x0201d;. After the training process, the obtained best model parameters are used in the proposed deep Bayes-SqueezeNet network and highlighted in <xref rid="t0015" ref-type="table">Table 3</xref>.<table-wrap position="float" id="t0015"><label>Table 3</label><caption><p>Bayesian optimization iteration results with model parameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Iter</th><th>Result</th><th>Objective</th><th>Run Time (s)</th><th>Observed</th><th>Estimation</th><th>InitialLearn Rate</th><th>Momentum</th><th>L2Regularization</th></tr></thead><tbody><tr><td>1</td><td>Best</td><td>0.032468</td><td>2272.7</td><td>0.032468</td><td>0.032468</td><td>0.0012837</td><td>0.87056</td><td>1.81E-06</td></tr><tr><td>2</td><td>Accept</td><td>0.66667</td><td>2262</td><td>0.032468</td><td>0.065569</td><td>0.025992</td><td>0.83518</td><td>0.0037856</td></tr><tr><td>3</td><td>Accept</td><td>0.66667</td><td>2277.4</td><td>0.032468</td><td>0.032531</td><td>0.017693</td><td>0.80247</td><td>8.26E-06</td></tr><tr><td>4</td><td>Best</td><td>0.028139</td><td>2258.6</td><td>0.028139</td><td>0.028157</td><td>0.0001101</td><td>0.81225</td><td>0.00045464</td></tr><tr><td>5</td><td>Best</td><td>0.025974</td><td>2266.2</td><td>0.025974</td><td>0.025902</td><td>0.00040989</td><td>0.88376</td><td>6.65E-06</td></tr><tr><td>6</td><td>Best</td><td>0.02381</td><td>2274.5</td><td>0.02381</td><td>0.023529</td><td>0.00076553</td><td>0.83936</td><td>0.0035748</td></tr><tr><td>7</td><td>Accept</td><td>0.028139</td><td>2269.2</td><td>0.02381</td><td>0.023379</td><td>0.00019459</td><td>0.84492</td><td>0.00036228</td></tr><tr><td>8</td><td>Accept</td><td>0.030303</td><td>2273.2</td><td>0.02381</td><td>0.025605</td><td>0.0009296</td><td>0.87648</td><td>1.70E-06</td></tr><tr><td>9</td><td>Accept</td><td>0.030303</td><td>2277.9</td><td>0.02381</td><td>0.02698</td><td>0.00056948</td><td>0.81638</td><td>1.16E-05</td></tr><tr><td>10</td><td><bold>Best</bold></td><td><bold>0.019481</bold></td><td><bold>2277.6</bold></td><td><bold>0.019481</bold></td><td><bold>0.021372</bold></td><td><bold>0.00029383</bold></td><td><bold>0.88203</bold></td><td><bold>0.00022577</bold></td></tr><tr><td>11</td><td>Accept</td><td>0.036797</td><td>2275.4</td><td>0.019481</td><td>0.025349</td><td>0.00029004</td><td>0.82578</td><td>5.16E-05</td></tr><tr><td>12</td><td>Accept</td><td>0.034632</td><td>2285.1</td><td>0.019481</td><td>0.026358</td><td>0.00010122</td><td>0.8988</td><td>2.59E-05</td></tr><tr><td>13</td><td>Accept</td><td>0.028139</td><td>2277.4</td><td>0.019481</td><td>0.026446</td><td>0.00015502</td><td>0.86513</td><td>0.0081237</td></tr><tr><td>14</td><td>Accept</td><td>0.036797</td><td>2293.7</td><td>0.019481</td><td>0.027786</td><td>0.00087009</td><td>0.89525</td><td>0.0056389</td></tr><tr><td>15</td><td>Accept</td><td>0.032468</td><td>2252.8</td><td>0.019481</td><td>0.028436</td><td>0.00040269</td><td>0.87339</td><td>0.00048719</td></tr><tr><td>16</td><td>Accept</td><td>0.036797</td><td>2311.4</td><td>0.019481</td><td>0.0285</td><td>0.00015923</td><td>0.88656</td><td>2.72E-06</td></tr><tr><td>17</td><td>Accept</td><td>0.02381</td><td>2312.7</td><td>0.019481</td><td>0.02726</td><td>0.00026917</td><td>0.89282</td><td>0.00046382</td></tr><tr><td>18</td><td>Accept</td><td>0.02381</td><td>2289.3</td><td>0.019481</td><td>0.026458</td><td>0.00026301</td><td>0.88663</td><td>0.0014638</td></tr><tr><td>19</td><td>Accept</td><td>0.66667</td><td>2149.5</td><td>0.019481</td><td>0.023422</td><td>0.099966</td><td>0.84025</td><td>1.23E-06</td></tr><tr><td>20</td><td>Accept</td><td>0.028139</td><td>2329.2</td><td>0.019481</td><td>0.026443</td><td>0.0010675</td><td>0.80008</td><td>0.0038983</td></tr><tr><td>21</td><td>Accept</td><td>0.33333</td><td>2308.4</td><td>0.019481</td><td>0.026572</td><td>0.0042908</td><td>0.89651</td><td>1.02E-06</td></tr><tr><td>22</td><td>Accept</td><td>0.59307</td><td>2331.9</td><td>0.019481</td><td>0.02079</td><td>0.0022645</td><td>0.86662</td><td>0.0087526</td></tr><tr><td>23</td><td>Accept</td><td>0.02381</td><td>2291.2</td><td>0.019481</td><td>0.020999</td><td>0.00065536</td><td>0.899</td><td>1.17E-06</td></tr><tr><td>24</td><td>Accept</td><td>0.02381</td><td>2351.4</td><td>0.019481</td><td>0.024937</td><td>0.0001248</td><td>0.89723</td><td>0.0021482</td></tr><tr><td>25</td><td>Accept</td><td>0.028139</td><td>2205.2</td><td>0.019481</td><td>0.023971</td><td>0.00022965</td><td>0.84862</td><td>0.00011305</td></tr><tr><td>26</td><td>Accept</td><td>0.030303</td><td>2337.2</td><td>0.019481</td><td>0.025463</td><td>0.0011636</td><td>0.89847</td><td>1.69E-06</td></tr><tr><td>27</td><td>Accept</td><td>0.66667</td><td>2362.9</td><td>0.019481</td><td>0.021554</td><td>0.0071359</td><td>0.82765</td><td>0.00016296</td></tr><tr><td>28</td><td>Accept</td><td>0.025974</td><td>2356.6</td><td>0.019481</td><td>0.021647</td><td>0.00094407</td><td>0.8011</td><td>0.00010491</td></tr><tr><td>29</td><td>Accept</td><td>0.032468</td><td>2339.6</td><td>0.019481</td><td>0.021141</td><td>0.00010048</td><td>0.89832</td><td>0.0069219</td></tr><tr><td>30</td><td>Accept</td><td>0.034632</td><td>2377.5</td><td>0.019481</td><td>0.022613</td><td>0.00033962</td><td>0.8959</td><td>2.41E-06</td></tr><tr><td>31</td><td>Accept</td><td>0.02381</td><td>2397.9</td><td>0.019481</td><td>0.021599</td><td>0.00048047</td><td>0.8965</td><td>8.22E-06</td></tr><tr><td>32</td><td>Accept</td><td>0.021645</td><td>2383.8</td><td>0.019481</td><td>0.021614</td><td>0.0011022</td><td>0.80386</td><td>1.12E-06</td></tr><tr><td>33</td><td>Accept</td><td>0.025974</td><td>2395.4</td><td>0.019481</td><td>0.022638</td><td>0.00082936</td><td>0.80318</td><td>0.0084898</td></tr><tr><td>34</td><td>Accept</td><td>0.032468</td><td>2388.1</td><td>0.019481</td><td>0.021811</td><td>0.00070627</td><td>0.80414</td><td>2.20E-06</td></tr><tr><td>35</td><td>Accept</td><td>0.034632</td><td>2299.5</td><td>0.019481</td><td>0.022807</td><td>0.00049401</td><td>0.8699</td><td>1.03E-06</td></tr></tbody></table></table-wrap></p><p id="p0220">In order to evaluate the effectiveness of our augmentation improvement, we first present the raw dataset results. Here, our aim is to prove the negative effect of the imbalance distributions in the raw dataset over the performance. It should be noted that we tune the SqueezeNet with the best model parameters for a regular training process. The re-training and testing processes are performed with the train and test packages of the related dataset, please see <xref rid="t0010" ref-type="table">Table 2</xref>. <xref rid="f0045" ref-type="fig">Fig. 9</xref>
demonstrates the confusion matrix of the test process of the re-trained SqueezeNet. In the confusion matrix presentation, accuracies and errors of each row and columns are given as the percentage value in the lower and right cells, respectively. The accuracy rates of each column show us the correctness value of each class and the accuracy values for each row state the single accuracy values of the classes.<fig id="f0045"><label>Fig. 9</label><caption><p>Confusion matrix of the re-trained SqueezeNet with raw dataset.</p></caption><graphic xlink:href="gr9_lrg"/></fig></p><p id="p0225">As shown in <xref rid="f0045" ref-type="fig">Fig. 9</xref>, the false classification rate appears majorly within Normal and Pneumonia. Pneumonia class achieves nearly the perfect classification whereas Covid class has 70% accuracy within 10 test samples. In the Normal class distribution, 141 samples are misclassified as Pneumonia. This situation shows the negative effect of the imbalanced distribution of the dominant Pneumonia class.</p><p id="p0230">In <xref rid="t0020" ref-type="table">Table 4</xref>
, we can see the detailed classification results of the SqueezeNet for the raw dataset. The obtained results show that Normal class has the lower values of Acc, COM, and F1 as 38.89%, 38.89%, and 55.83%, respectively. The model with the raw dataset just reaches the 76.37% overall accuracy and 70.00% single accuracy value of the Covid class. While the highest accuracy is presented by Pneumonia class, the lower values of MCC and SPE in Pneumonia point out poor classification performance.<table-wrap position="float" id="t0020"><label>Table 4</label><caption><p>Classification results of the re-trained SqueezeNet with raw dataset (%).</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Class</th><th>Acc</th><th>COR</th><th>COM</th><th>SPE</th><th>F1</th><th>MCC</th></tr></thead><tbody><tr><td>Covid</td><td>70.00</td><td>53.85</td><td>70.00</td><td>99.04</td><td>60.87</td><td>60.70</td></tr><tr><td>Normal</td><td>38.89</td><td>98.91</td><td>38.89</td><td>99.75</td><td>55.83</td><td>53.03</td></tr><tr><td>Pneumonia</td><td>98.73</td><td>73.03</td><td>98.73</td><td>40.98</td><td>83.96</td><td>52.07</td></tr><tr><td>Overall</td><td>76.37</td><td>75.26</td><td>69.21</td><td>79.93</td><td>66.89</td><td>55.27</td></tr></tbody></table></table-wrap></p><p id="p0235">The second phase of our experiments is performing the augmented dataset testing process. In this phase, the proposed deep Bayes-SqueezeNet model, which is obtained by the Bayesian optimization approach, is validated with the separate test dataset. It should be noted that the obtained best model is trained with the augmented dataset to overcome the above-mentioned imbalance effects as well as achieving a rapid system for COVID-19 diagnosis with a robust and sustainable structure. <xref rid="f0050" ref-type="fig">Fig. 10</xref>
presents the confusion matrix of the test phase. Here, we can see a tremendous performance boosting on all classes and overall accuracy. The deep Bayes-SqueezeNet model catches all the Covid samples in the X-rays, perfectly. There are just eight misclassified samples among 459 test samples. The error rate of the Normal class is 2% while it is 3.3% in Pneumonia. In addition, the most misclassification rate is presented by Pneumonia.<fig id="f0050"><label>Fig. 10</label><caption><p>Confusion matrix of the proposed deep Bayes-SqueezeNet in testing phase.</p></caption><graphic xlink:href="gr10_lrg"/></fig></p><p id="p0240">We can interpret the detailed test results from <xref rid="t0025" ref-type="table">Table 5</xref>
. In the decision-making system, Covid class reaches the perfect classification rate as showing the 100% test accuracy and completeness values. F1 and MCC values also prove that it is obtained a stable classification. The overall accuracy is 98.26% with a COM of 98.26%, it draws a picture that our model is well-trained and robust. Although Pneumonia accuracy decreases to 96.73% compared to former experiments, all other performance criteria of the related class are boosted and exhibit an effective prediction. The classification performance of the Normal class is visibly enhanced and it reaches to 98.04% Acc value.<table-wrap position="float" id="t0025"><label>Table 5</label><caption><p>Classification results of the proposed deep Bayes-SqueezeNet (%).</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Class</th><th>Acc</th><th>COR</th><th>COM</th><th>SPE</th><th>F1</th><th>MCC</th></tr></thead><tbody><tr><td>Covid</td><td>100.00</td><td>99.35</td><td>100.00</td><td>99.67</td><td>99.67</td><td>99.51</td></tr><tr><td>Normal</td><td>98.04</td><td>97.40</td><td>98.04</td><td>98.69</td><td>97.72</td><td>96.58</td></tr><tr><td>Pneumonia</td><td>96.73</td><td>98.01</td><td>96.73</td><td>99.02</td><td>97.37</td><td>96.07</td></tr><tr><td>Overall</td><td>98.26</td><td>98.26</td><td>98.26</td><td>99.13</td><td>98.25</td><td>97.39</td></tr></tbody></table></table-wrap></p><p id="p0245">In order to analyze the performance comparison between the experiments of the raw dataset and the augmented one, we report the increase rates of the performance values as in <xref rid="f0055" ref-type="fig">Fig. 11</xref>
. The sharp bounce is experienced in the Normal class by a boosting of 2.5 times. As it is the focus of our model, when we concentrate on the performance of the Covid then we detect 2.5 times boosting. In Pneumonia class, there is a decreasing percentage of 2.06% considering just the accuracy value. The overall accuracy rate has also a performance increasing at the rate of 28.66%. The overall accuracy rate has also a performance increase at a rate of 28.66%.<fig id="f0055"><label>Fig. 11</label><caption><p>Performance comparison of the raw and augmented dataset.</p></caption><graphic xlink:href="gr11_lrg"/></fig></p><p id="p0250">For a detailed visual analysis, we provide a class activation mapping images as shown in <xref rid="f0060" ref-type="fig">Fig. 12</xref>
. Class activation mapping is a way of generating visual explanations of the predictions of deep learning models. Misclassified or unreasonable predictions sometimes can rely on reasonable explanations. By the aid of the class activation mapping, we can investigate useful knowledge of the prediction regions. Activation mapping also defines the bias regions in the training images. The first column of <xref rid="f0060" ref-type="fig">Fig. 12</xref> defines the original input images while the second column includes the heat map images of the predicted samples. When all the class activation mappings are examined in <xref rid="f0060" ref-type="fig">Fig. 12</xref> (a) &#x02013; (c), the probability values of the predictions are nearly 1.00. According to the heat maps of the images, the trained network distinguishes the classes with an acceptable feature mapping. To form an outlier example, <xref rid="f0060" ref-type="fig">Fig. 12</xref> (d) presents a misclassified class sample i.e. Normal class is confused with Pneumonia. The probability values are 0.25 and 0.74, for Normal and Pneumonia respectively.<fig id="f0060"><label>Fig. 12</label><caption><p>Class activation mapping visualization of the proposed deep Bayes-SqueezeNet on sample images: a) Covid b) Normal c) Pneumonia d) Misclassified prediction.</p></caption><graphic xlink:href="gr12_lrg"/></fig></p><p id="p0255">The proposed deep Bayes-SqueezeNet with its low model size is easy to implement in hardware deployments. As shown in <xref rid="t0030" ref-type="table">Table 6</xref>
, the model size of the proposed network is less than 77.31 times lower compared to the AlexNet, which is the inspiration of the SqueezeNet architecture.<table-wrap position="float" id="t0030"><label>Table 6</label><caption><p>Model sizes in mega bytes.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Deep Bayes-SqueezeNet</th><th>AlexNet</th></tr></thead><tbody><tr><td>Storage size of the models (MB)</td><td><bold>2.6</bold></td><td>201</td></tr></tbody></table></table-wrap></p><p id="p0260">The overall experimental results show that proposed model has a significant and robust performance value. Over the COVID-19 patient cases, this study proposes a complete and compact solution using the chest X-ray images for rapid diagnosis.</p></sec><sec id="s0055"><title>Comparison between the State-of-the-Art methods</title><p id="p0265">The coronavirus disease 2019 was announced as an outbreak by WHO on February 11, 2020 <xref rid="b0005" ref-type="bibr">[1]</xref>. Due to the COVID-19 outbreak, the early diagnosis of this disease has become a key topic for clinicians and radiologists in the world. The AI techniques regarding the image classification approaches can help in early diagnose of the disease. Considering AI, CNN methods achieve better and faster results compared to the traditional diagnosis methods. In this paper, a rapid robust and efficient COVID-19 diagnosis method, which is namely deep Bayes-SqueezeNet, is proposed. The proposed method performs the X-ray images into multiclass as Normal, Pneumonia, and Covid. In order to evaluate the proposed CNN model, the general performance comparison of our study with the state-of-art methods is given in this section. In the model evaluations, the related studies depend on the multiclass classification of the chest X-ray images with various AI techniques. <xref rid="t0035" ref-type="table">Table 7</xref>
shows the comparison results with the related studies uses the same or similar datasets.<table-wrap position="float" id="t0035"><label>Table 7</label><caption><p>The general comparison of the proposed method between the state-of-the-art methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Study</th><th>Year</th><th>Methods</th><th>Class</th><th>Acc</th><th>COR</th><th>COM</th><th>SPE</th><th>F1</th><th>MCC</th></tr></thead><tbody><tr><td>Li and Zhu <xref rid="b0080" ref-type="bibr">[16]</xref></td><td>2020</td><td>DenseNet</td><td>3</td><td>0.889</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td></tr><tr><td>Wang and Wong <xref rid="b0055" ref-type="bibr">[11]</xref></td><td>2020</td><td>Tailored CNN</td><td>3</td><td>0.923</td><td>0.913</td><td>0.887</td><td>&#x02013;</td><td>0.900</td><td>&#x02013;</td></tr><tr><td>Afshar et al. <xref rid="b0085" ref-type="bibr">[17]</xref></td><td>2020</td><td>Capsule Networks</td><td>4</td><td>0.957</td><td>&#x02013;</td><td>0.900</td><td>0.958</td><td>&#x02013;</td><td>&#x02013;</td></tr><tr><td>Farooq and Hafeez <xref rid="b0090" ref-type="bibr">[18]</xref></td><td>2020</td><td>ResNet50</td><td>4</td><td>0.962</td><td>0.969</td><td>0.969</td><td>&#x02013;</td><td>0.969</td><td>&#x02013;</td></tr><tr><td>Chowdhury et al. <xref rid="b0095" ref-type="bibr">[19]</xref></td><td>2020</td><td>Sgdm-SqueezeNet</td><td>3</td><td><bold>0.983</bold></td><td><bold>1.000</bold></td><td>0.967</td><td>0.990</td><td><bold>0.983</bold></td><td>&#x02013;</td></tr><tr><td><bold>Proposed Method</bold></td><td>2020</td><td>Bayes-SqueezeNet</td><td>3</td><td><bold>0.983</bold></td><td>0.983</td><td><bold>0.983</bold></td><td><bold>0.991</bold></td><td><bold>0.983</bold></td><td>0.974</td></tr></tbody></table></table-wrap></p><p id="p0270">Li and Zhu <xref rid="b0080" ref-type="bibr">[16]</xref> propose a DenseNet based COVID-Xpert architecture classifying the three-class chest X-ray images. They use transfer learning and obtain an overall accuracy of 0.889. Wang and Wong <xref rid="b0055" ref-type="bibr">[11]</xref> present COVID-Net design to the diagnosis of the COVID-19 and in their study the main model is based on the tailored CNN. Machine-driven design is used to improve the model architecture. The overall accuracy, COM, and COR metrics of <xref rid="b0055" ref-type="bibr">[11]</xref> can be listed as 0.923, 0.887, and 0.913, respectively. The authors also share and collect the COVIDx dataset used in our study. Afshar et al. <xref rid="b0085" ref-type="bibr">[17]</xref> introduce a deep learning model based on a capsule network using a four-class dataset. Their model produces a 0.957 overall accuracy. Farooq and Hafeez <xref rid="b0090" ref-type="bibr">[18]</xref> present a ResNet based framework in a four-class dataset with augmentation. The model accuracy has remained as 0.962. Chowdhury et al. <xref rid="b0095" ref-type="bibr">[19]</xref> explain a bundle structure that includes various deep learning models using four different chest X-ray datasets. Amid the performance metrics that <xref rid="t0035" ref-type="table">Table 7</xref> gives, our model outperforms similar studies that use chest X-rays in the diagnosis of the COVID-19. Although it seems that some of the performance values have been achieved the same with the study <xref rid="b0095" ref-type="bibr">[19]</xref>, the whole performance of the proposed method in our study is better than it.</p><p id="p0275">In <xref rid="t0040" ref-type="table">Table 8</xref>
, the performance values of the listed studies are given in terms of COVID-19 class accuracy. While Chowdhury et al. <xref rid="b0095" ref-type="bibr">[19]</xref> have the same overall accuracy with our study, the COVID-19 class accuracy stays behind the proposed method. Farooq and Hafeez <xref rid="b0090" ref-type="bibr">[18]</xref> obtain the same accuracy of COVID-19 class, but our study outperforms it in the overall accuracy. In addition, the test dataset of the study includes just eight samples of COVID-19.<table-wrap position="float" id="t0040"><label>Table 8</label><caption><p>COVID-19 class comparison of the proposed method between the state-of-the-art methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Study</th><th>COVID-19 Class Acc</th><th>Overall Acc</th></tr></thead><tbody><tr><td>Li and Zhu <xref rid="b0080" ref-type="bibr">[16]</xref></td><td>0.792</td><td>0.889</td></tr><tr><td>Wang and Wong <xref rid="b0055" ref-type="bibr">[11]</xref></td><td>0.800</td><td>0.923</td></tr><tr><td>Afshar et al. <xref rid="b0085" ref-type="bibr">[17]</xref></td><td><bold>&#x02013;</bold></td><td>0.957</td></tr><tr><td>Chowdhury et al. <xref rid="b0095" ref-type="bibr">[19]</xref></td><td>0.967</td><td><bold>0.983</bold></td></tr><tr><td>Farooq and Hafeez <xref rid="b0090" ref-type="bibr">[18]</xref></td><td><bold>1.000</bold></td><td>0.962</td></tr><tr><td><bold>Proposed Method</bold></td><td><bold>1.000</bold></td><td><bold>0.983</bold></td></tr></tbody></table></table-wrap></p><p id="p0280">To the best of our knowledge, the proposed model reveals the excellent classification performance for the COVID-19 diagnosis with chest X-rays. The proposed model has a great advantage of owning a practical network architecture with a robust and stable operation. With its nature of including fewer parameters, our network is more favorable for embedded systems among existing deep learning models.</p></sec></sec><sec id="s0060"><title>Conclusions</title><p id="p0285">A rapid diagnosis method has a key role in the control of infectious diseases and pandemic situations like the up to date COVID-19. Some limitations of the RT-PCR nucleic acid-based test modules reveal a need for fast alternative methods to be able to serve the front-line experts to make them reach a quick and accurate diagnosis. In this study, we propose an AI-based decision-making system including the recognition of input X-ray images under the roof of a very practical deep learning model. This study is an important attempt including an easy to implement deep learning model which has an accuracy performance of 98.3% (among Normal, Pneumonia and Covid cases), and 100% for the single recognition of COVID-19 (among other classes). In these difficult days of the global COVID-19 pandemic, our model has a strong potential to build a tool design for COVID-19 monitoring. We would like to note that that the RT-PCR test method to detect the SARS-CoV-2 is still important. However, it is proved that there are also undeniable shortcomings along with the RT-PCR test method, which can be listed as follows: 1) its possible methodology lacks, 2) strict dependence on the level of the disease (timing), 3) the possibility for collecting the specimens in mistaken localizations and 4) its response time delay <xref rid="b0030" ref-type="bibr">[6]</xref>, <xref rid="b0035" ref-type="bibr">[7]</xref>. In our model working with a deep learning-based practical structure, the early stage detections of the COVID-19 cases could be done to manage and control the pandemic disease. In medical image processing, while deep learning methods are preferred in many areas, it is becoming more and more important especially in the interpretation of radiological images. As such, our model, which is extremely satisfactory even with its initial results, opens the door for the implementation of a comprehensive product that can work mobile and appeal to the end-user.</p><p id="p0290">Backbone of our model is the deep Bayes-SqueezeNet decision-making system for the COVID-19 diagnosis from X-ray images. SqueezeNet with much less model size is a state-of-the-art deep learning model, which is inspired by the well-known AlexNet. With its practical structure and generalization performance, the SqueezeNet is preferable in the embedded applications. We improve the SqueezeNet structure with Bayes optimization algorithm to build a robust and sustainable learning model. Bayesian optimization helps us to build a best-performed model with a validation dataset. The diagnosis system is trained using the public dataset proposed in <xref rid="b0055" ref-type="bibr">[11]</xref> with its augmented form. A separate test, which is independent of train and validation sets, performs the experiments. Our experimental results also present the performance boosting of the augmentation contribution to the dataset pre-processing. Thus, model training can be performed with a rich image set of X-rays of COVID-19. After comprehensive literature research, the up to date studies, which use the same or similar public datasets are detected and we evaluate our model with those. The proposed diagnosis model for COVID-19 using the X-ray images, the deep Bayes-SqueezeNet outperforms its competitors. We believe that with increased training dataset, it is expected to get higher results.</p><p id="p0295">In further works, we aim to plan our model to be able to work mobile appealing to the health care experts for diagnosis of the COVID-19. In addition, the possibility of presenting this diagnostic system as a solution for other medical image processing cases will also be explored.</p></sec><sec sec-type="COI-statement"><title>Declaration of Competing Interest</title><p id="p0300">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></sec></body><back><ref-list id="bi005"><title>References</title><ref id="b0005"><label>1</label><mixed-citation publication-type="other" id="h0005">WHO - Coronavirus disease 2019 info web site n.d. https://www.who.int/emergencies/diseases/novel-coronavirus-2019 (accessed April 6, 2020).</mixed-citation></ref><ref id="b0010"><label>2</label><element-citation publication-type="journal" id="h0010"><person-group person-group-type="author"><name><surname>Lai</surname><given-names>C.C.</given-names></name><name><surname>Shih</surname><given-names>T.P.</given-names></name><name><surname>Ko</surname><given-names>W.C.</given-names></name><name><surname>Tang</surname><given-names>H.J.</given-names></name><name><surname>Hsueh</surname><given-names>P.R.</given-names></name></person-group><article-title>Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and coronavirus disease-2019 (COVID-19): The epidemic and the challenges</article-title><source>Int J Antimicrob Agents</source><volume>55</volume><year>2020</year><object-id pub-id-type="publisher-id">105924</object-id><pub-id pub-id-type="doi">10.1016/j.ijantimicag.2020.105924</pub-id></element-citation></ref><ref id="b0015"><label>3</label><mixed-citation publication-type="other" id="h0015">Salman S, Salem ML. Routine childhood immunization may protect against COVID-19. vol. 140. Churchill Livingstone; 2020. doi:10.1016/j.mehy.2020.109689.</mixed-citation></ref><ref id="b0020"><label>4</label><element-citation publication-type="journal" id="h0020"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>D.</given-names></name><name><surname>Hu</surname><given-names>B.</given-names></name><name><surname>Hu</surname><given-names>C.</given-names></name><name><surname>Zhu</surname><given-names>F.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name></person-group><article-title>Clinical Characteristics of 138 Hospitalized Patients with 2019 Novel Coronavirus-Infected Pneumonia in Wuhan, China</article-title><source>JAMA - J Am Med Assoc</source><volume>323</volume><year>2020</year><fpage>1061</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1001/jama.2020.1585</pub-id></element-citation></ref><ref id="b0025"><label>5</label><mixed-citation publication-type="other" id="h0025">Xie M, Chen Q. Insight into 2019 novel coronavirus &#x02014; an updated intrim review and lessons from SARS-CoV and MERS-CoV. Int J Infect Dis 2020. doi:10.1016/j.ijid.2020.03.071.</mixed-citation></ref><ref id="b0030"><label>6</label><element-citation publication-type="journal" id="h0030"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>R.</given-names></name><name><surname>Han</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>F.</given-names></name><name><surname>Lv</surname><given-names>Z.</given-names></name><name><surname>Wu</surname><given-names>K.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name></person-group><article-title>Positive rate of RT-PCR detection of SARS-CoV-2 infection in 4880 cases from one hospital in Wuhan, China, from Jan to Feb 2020</article-title><source>Clin Chim Acta</source><volume>505</volume><year>2020</year><fpage>172</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/j.cca.2020.03.009</pub-id><pub-id pub-id-type="pmid">32156607</pub-id></element-citation></ref><ref id="b0035"><label>7</label><element-citation publication-type="journal" id="h0035"><person-group person-group-type="author"><name><surname>Chu</surname><given-names>D.K.W.</given-names></name><name><surname>Pan</surname><given-names>Y.</given-names></name><name><surname>Cheng</surname><given-names>S.M.S.</given-names></name><name><surname>Hui</surname><given-names>K.P.Y.</given-names></name><name><surname>Krishnan</surname><given-names>P.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name></person-group><article-title>Molecular Diagnosis of a Novel Coronavirus (2019-nCoV) Causing an Outbreak of Pneumonia</article-title><source>Clin Chem</source><volume>66</volume><year>2020</year><fpage>549</fpage><lpage>555</lpage><pub-id pub-id-type="doi">10.1093/clinchem/hvaa029</pub-id><pub-id pub-id-type="pmid">32031583</pub-id></element-citation></ref><ref id="b0040"><label>8</label><mixed-citation publication-type="other" id="h0040">3D medical animation corona virus.jpg - Wikimedia Commons. Wikimedia Commons n.d. https://commons.wikimedia.org/wiki/File:3D_medical_animation_corona_virus.jpg (accessed April 6, 2020).</mixed-citation></ref><ref id="b0045"><label>9</label><mixed-citation publication-type="other" id="h0045">Li Y, Xia L. Coronavirus Disease 2019 (COVID-19): Role of Chest CT in Diagnosis and Management. Am J Roentgenol 2020:1&#x02013;7. doi:10.2214/ajr.20.22954.</mixed-citation></ref><ref id="b0050"><label>10</label><element-citation publication-type="journal" id="h0050"><person-group person-group-type="author"><name><surname>Kermany</surname><given-names>D.S.</given-names></name><name><surname>Goldbaum</surname><given-names>M.</given-names></name><name><surname>Cai</surname><given-names>W.</given-names></name><name><surname>Valentim</surname><given-names>C.C.S.</given-names></name><name><surname>Liang</surname><given-names>H.</given-names></name><name><surname>Baxter</surname><given-names>S.L.</given-names></name></person-group><article-title>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</article-title><source>Cell</source><volume>172</volume><issue>1122&#x02013;1131</issue><year>2018</year><object-id pub-id-type="publisher-id">e9</object-id><pub-id pub-id-type="doi">10.1016/j.cell.2018.02.010</pub-id></element-citation></ref><ref id="b0055"><label>11</label><mixed-citation publication-type="other" id="h0055">Wang L, Wong A. COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images. ArXiv 2200309871 2020.</mixed-citation></ref><ref id="b0060"><label>12</label><mixed-citation publication-type="other" id="h0060">Cohen JP, Morrison P, Dao L. COVID-19 Image Data Collection. ArXiv 200311597 2020.</mixed-citation></ref><ref id="b0065"><label>13</label><mixed-citation publication-type="other" id="h0065">Gozes O, Ayan Frid-Adar M&#x02019;, Greenspan H, Browning PD, Zhang H, Ji W, et al. Rapid AI Development Cycle for the Coronavirus (COVID-19) Pandemic: Initial Results for Automated Detection &#x00026; Patient Monitoring using Deep Learning CT Image Analysis Authors. ArXiv 200305037 2020.</mixed-citation></ref><ref id="b0070"><label>14</label><mixed-citation publication-type="other" id="h0070">Xiaowei Xu;, Xiangao Jiang;, Chunlian Ma;, Peng Du;, Xukun Li;, Shuangzhi Lv;, et al. Deep Learning System to Screen Coronavirus Disease 2019 Pneumonia. ArXiv 200209334 2020:1&#x02013;29.</mixed-citation></ref><ref id="b0075"><label>15</label><mixed-citation publication-type="other" id="h0075">Wang S, Kang B, Ma J, Zeng X, Xiao M, Guo J, et al. A deep learning algorithm using CT images to screen for corona virus disease (COVID-19). MedRxiv 2020:2020.02.14.20023028. doi:10.1101/2020.02.14.20023028.</mixed-citation></ref><ref id="b0080"><label>16</label><mixed-citation publication-type="other" id="h0080">Li X, Zhu D. COVID-Xpert: An AI Powered Population Screening of COVID-19 Cases Using Chest Radiography Images. ArXiv:200403042 2020:1&#x02013;6..</mixed-citation></ref><ref id="b0085"><label>17</label><mixed-citation publication-type="other" id="h0085">Afshar P, Heidarian S, Naderkhani F, Oikonomou A, Plataniotis KN, Mohammadi A, et al. Covid-Caps: A Capsule Network-Based Framework for Identification of Covid-19 Cases From X-Ray Images. ArXiv Prepr ArXiv200402696 2020:1&#x02013;4.</mixed-citation></ref><ref id="b0090"><label>18</label><element-citation publication-type="journal" id="h0090"><person-group person-group-type="author"><name><surname>Farooq</surname><given-names>M.</given-names></name><name><surname>Hafeez</surname><given-names>A.</given-names></name></person-group><article-title>COVID-ResNet: A Deep Learning Framework for Screening of COVID19 from</article-title><source>Radiographs</source><year>2020</year></element-citation></ref><ref id="b0095"><label>19</label><mixed-citation publication-type="other" id="h0095">Chowdhury MEH, Rahman T, Khandakar A, Mazhar R, Kadir MA, Mahbub Z Bin, et al. Can AI help in screening Viral and COVID-19 pneumonia? ArXiv 200313145 2020.</mixed-citation></ref><ref id="b0100"><label>20</label><element-citation publication-type="journal" id="h0100"><person-group person-group-type="author"><name><surname>Lakhani</surname><given-names>P.</given-names></name><name><surname>Sundaram</surname><given-names>B.</given-names></name></person-group><article-title>Deep learning at chest radiography: Automated classification of pulmonary tuberculosis by using convolutional neural networks</article-title><source>Radiology</source><volume>284</volume><year>2017</year><fpage>574</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1148/radiol.2017162326</pub-id><pub-id pub-id-type="pmid">28436741</pub-id></element-citation></ref><ref id="b0105"><label>21</label><mixed-citation publication-type="other" id="h0105">Varshni D, Thakral K, Agarwal L, Nijhawan R, Mittal A. Pneumonia Detection Using CNN based Feature Extraction. Proc. 2019 3rd IEEE Int. Conf. Electr. Comput. Commun. Technol. ICECCT 2019, Institute of Electrical and Electronics Engineers Inc.; 2019. doi:10.1109/ICECCT.2019.8869364.</mixed-citation></ref><ref id="b0110"><label>22</label><element-citation publication-type="journal" id="h0110"><person-group person-group-type="author"><name><surname>Budak</surname><given-names>&#x000dc;.</given-names></name><name><surname>C&#x000f6;mert</surname><given-names>Z.</given-names></name><name><surname>&#x000c7;&#x00131;buk</surname><given-names>M.</given-names></name><name><surname>&#x0015e;eng&#x000fc;r</surname><given-names>A.</given-names></name></person-group><article-title>DCCMED-Net: Densely connected and concatenated multi Encoder-Decoder CNNs for retinal vessel extraction from fundus images</article-title><source>Med Hypotheses</source><volume>134</volume><year>2020</year><pub-id pub-id-type="doi">10.1016/j.mehy.2019.109426</pub-id></element-citation></ref><ref id="b0115"><label>23</label><element-citation publication-type="journal" id="h0115"><person-group person-group-type="author"><name><surname>&#x000d6;zyurt</surname><given-names>F.</given-names></name><name><surname>Sert</surname><given-names>E.</given-names></name><name><surname>Avc&#x00131;</surname><given-names>D.</given-names></name></person-group><article-title>An expert system for brain tumor detection: Fuzzy C-means with super resolution and convolutional neural network with extreme learning machine</article-title><source>Med Hypotheses</source><volume>134</volume><year>2020</year><pub-id pub-id-type="doi">10.1016/j.mehy.2019.109433</pub-id></element-citation></ref><ref id="b0120"><label>24</label><element-citation publication-type="journal" id="h0120"><person-group person-group-type="author"><name><surname>Iandola</surname><given-names>F.N.</given-names></name><name><surname>Han</surname><given-names>S.</given-names></name><name><surname>Moskewicz</surname><given-names>M.W.</given-names></name><name><surname>Ashraf</surname><given-names>K.</given-names></name><name><surname>Dally</surname><given-names>W.J.</given-names></name><name><surname>Keutzer</surname><given-names>K.</given-names></name></person-group><article-title>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &#x0003c;0.5MB model size</article-title><source>Arxiv</source><volume>160207360</volume><year>2016</year><fpage>1</fpage><lpage>13</lpage></element-citation></ref><ref id="b0125"><label>25</label><element-citation publication-type="journal" id="h0125"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>G.</given-names></name><name><surname>Chen</surname><given-names>F.</given-names></name><name><surname>Chen</surname><given-names>D.</given-names></name><name><surname>Dong</surname><given-names>Y.</given-names></name></person-group><article-title>Recognizing Multiple Types of Rocks Quickly and Accurately Based on Lightweight CNNs Model</article-title><source>IEEE Access</source><volume>8</volume><year>2020</year><fpage>55269</fpage><lpage>55278</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2982017</pub-id></element-citation></ref><ref id="b0130"><label>26</label><mixed-citation publication-type="other" id="h0130">Chappa RTNV., El-Sharkawy M. Squeeze-and-Excitation SqueezeNext: An Efficient DNN for Hardware Deployment. 2020 10th Annu. Comput. Commun. Work. Conf., IEEE; 2020, p. 0691&#x02013;7. doi:10.1109/ccwc47524.2020.9031119.</mixed-citation></ref><ref id="b0135"><label>27</label><element-citation publication-type="journal" id="h0135"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>X.Y.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Xiong</surname><given-names>L.D.</given-names></name><name><surname>Lei</surname><given-names>H.</given-names></name><name><surname>Deng</surname><given-names>S.H.</given-names></name></person-group><article-title>Hyperparameter optimization for machine learning models based on Bayesian optimization</article-title><source>J Electron Sci Technol</source><volume>17</volume><year>2019</year><fpage>26</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.11989/JEST.1674-862X.80904120</pub-id></element-citation></ref><ref id="b0140"><label>28</label><element-citation publication-type="journal" id="h0140"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Kuen</surname><given-names>J.</given-names></name><name><surname>Ma</surname><given-names>L.</given-names></name><name><surname>Shahroudy</surname><given-names>A.</given-names></name><name><surname>Shuai</surname><given-names>B.</given-names></name></person-group><article-title>Recent advances in convolutional neural networks</article-title><source>Pattern Recognit</source><volume>77</volume><year>2018</year><fpage>354</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2017.10.013</pub-id></element-citation></ref><ref id="b0145"><label>29</label><element-citation publication-type="journal" id="h0145"><person-group person-group-type="author"><name><surname>Raghu</surname><given-names>S.</given-names></name><name><surname>Sriraam</surname><given-names>N.</given-names></name><name><surname>Temel</surname><given-names>Y.</given-names></name><name><surname>Rao</surname><given-names>S.V.</given-names></name><name><surname>Kubben</surname><given-names>P.L.</given-names></name></person-group><article-title>EEG based multi-class seizure type classification using convolutional neural network and transfer learning</article-title><source>Neural Networks</source><volume>124</volume><year>2020</year><fpage>202</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2020.01.017</pub-id><pub-id pub-id-type="pmid">32018158</pub-id></element-citation></ref><ref id="b0150"><label>30</label><element-citation publication-type="journal" id="h0150"><person-group person-group-type="author"><name><surname>Jadhav</surname><given-names>P.</given-names></name><name><surname>Rajguru</surname><given-names>G.</given-names></name><name><surname>Datta</surname><given-names>D.</given-names></name><name><surname>Mukhopadhyay</surname><given-names>S.</given-names></name></person-group><article-title>Automatic sleep stage classification using time&#x02013;frequency images of CWT and transfer learning using convolution neural network</article-title><source>Biocybern Biomed Eng</source><volume>40</volume><year>2020</year><fpage>494</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1016/j.bbe.2020.01.010</pub-id></element-citation></ref><ref id="b0155"><label>31</label><element-citation publication-type="journal" id="h0155"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name></person-group><article-title>RobNet: real-time road-object 3D point cloud segmentation based on SqueezeNet and cyclic CRF</article-title><source>Soft Comput</source><volume>24</volume><year>2019</year><fpage>5805</fpage><lpage>5818</lpage><pub-id pub-id-type="doi">10.1007/s00500-019-04355-y</pub-id></element-citation></ref><ref id="b0160"><label>32</label><element-citation publication-type="journal" id="h0160"><person-group person-group-type="author"><name><surname>Su</surname><given-names>L.</given-names></name><name><surname>Ma</surname><given-names>L.</given-names></name><name><surname>Qin</surname><given-names>N.</given-names></name><name><surname>Huang</surname><given-names>D.</given-names></name><name><surname>Kemp</surname><given-names>A.H.</given-names></name></person-group><article-title>Fault Diagnosis of High-Speed Train Bogie by Residual-Squeeze Net</article-title><source>IEEE Trans Ind Informatics</source><volume>15</volume><year>2019</year><fpage>3856</fpage><lpage>3863</lpage><pub-id pub-id-type="doi">10.1109/TII.2019.2907373</pub-id></element-citation></ref><ref id="b0165"><label>33</label><element-citation publication-type="journal" id="h0165"><person-group person-group-type="author"><name><surname>Sameen</surname><given-names>M.I.</given-names></name><name><surname>Pradhan</surname><given-names>B.</given-names></name><name><surname>Lee</surname><given-names>S.</given-names></name></person-group><article-title>Application of convolutional neural networks featuring Bayesian optimization for landslide susceptibility assessment</article-title><source>Catena</source><volume>186</volume><year>2020</year><pub-id pub-id-type="doi">10.1016/j.catena.2019.104249</pub-id></element-citation></ref><ref id="b0170"><label>34</label><mixed-citation publication-type="other" id="h0170">Snoek J, Rippel O, Swersky K, Kiros R, Satish N, Sundaram N, et al. Scalable Bayesian Optimization Using Deep Neural Networks. 32nd Int. Conf. Mach. Learn. ICML 2015, vol. 3, International Machine Learning Society (IMLS); 2015, p. 2161&#x02013;70.</mixed-citation></ref><ref id="b0175"><label>35</label><element-citation publication-type="journal" id="h0175"><person-group person-group-type="author"><name><surname>Mockus</surname><given-names>J.</given-names></name></person-group><article-title>On the Bayes Methods for Seeking the Extremal Point</article-title><source>IFAC Proc</source><volume>8</volume><year>1975</year><fpage>428</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/s1474-6670(17)67769-3</pub-id></element-citation></ref><ref id="b0180"><label>36</label><element-citation publication-type="journal" id="h0180"><person-group person-group-type="author"><name><surname>Shahriari</surname><given-names>B.</given-names></name><name><surname>Swersky</surname><given-names>K.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Adams</surname><given-names>R.P.</given-names></name><name><surname>De Freitas</surname><given-names>N.</given-names></name></person-group><article-title>Taking the human out of the loop: A review of Bayesian optimization</article-title><source>Proc IEEE</source><volume>104</volume><year>2016</year><fpage>148</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1109/JPROC.2015.2494218</pub-id></element-citation></ref><ref id="b0185"><label>37</label><mixed-citation publication-type="other" id="h0185">Shallow Understanding on Bayesian Optimization - Towards Data Science 2020. https://towardsdatascience.com/shallow-understanding-on-bayesian-optimization-324b6c1f7083 (accessed April 9, 2020).</mixed-citation></ref><ref id="b0190"><label>38</label><mixed-citation publication-type="other" id="h0190">Kermany, Daniel; Zhang, Kang; Goldbaum M. Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification. Mendeley Data, V2 2018. http://dx.doi.org/10.17632/rscbjbr9sj.2.</mixed-citation></ref><ref id="b0195"><label>39</label><element-citation publication-type="journal" id="h0195"><person-group person-group-type="author"><name><surname>Buda</surname><given-names>M.</given-names></name><name><surname>Maki</surname><given-names>A.</given-names></name><name><surname>Mazurowski</surname><given-names>M.A.</given-names></name></person-group><article-title>A systematic study of the class imbalance problem in convolutional neural networks</article-title><source>Neural Networks</source><volume>106</volume><year>2018</year><fpage>249</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2018.07.011</pub-id><pub-id pub-id-type="pmid">30092410</pub-id></element-citation></ref></ref-list><sec id="s0070" sec-type="supplementary-material"><label>Appendix A</label><title>Supplementary data</title><p id="p0310">The following are the Supplementary data to this article:<supplementary-material content-type="local-data" id="m0005"><caption><title>Supplementary Data 1</title></caption><media xlink:href="mmc1.xml"/></supplementary-material>
</p></sec><fn-group><fn id="s0065" fn-type="supplementary-material"><label>Appendix A</label><p id="p0305">Supplementary data to this article can be found online at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.mehy.2020.109761" id="ir005">https://doi.org/10.1016/j.mehy.2020.109761</ext-link>.</p></fn></fn-group></back></article>