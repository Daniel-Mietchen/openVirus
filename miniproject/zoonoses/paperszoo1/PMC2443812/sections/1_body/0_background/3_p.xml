<?xml version="1.0" encoding="UTF-8"?>
<p>Two primary methods find use to date the time of viral subtype divergence. The most commonly employed approach determines the divergence time of subtypes using a molecular clock assumption (MCA) over an entire phylogeny [
 <xref ref-type="bibr" rid="B18">18</xref>,
 <xref ref-type="bibr" rid="B21">21</xref>,
 <xref ref-type="bibr" rid="B5">5</xref>,
 <xref ref-type="bibr" rid="B26">26</xref>]. In its strict formulation, the MCA posits a proportional relation between the number of substitutions and the intervening time period over the entire phylogeny. Looser forms of MCAs require only that the proportionality hold along individual branches, with the rates across branches drawn from a pre-specified distribution [
 <xref ref-type="bibr" rid="B5">5</xref>]. Committed to some variant of the MCA, current algorithms then estimate the rate of nucleotide substitution over all taxa in a given set. Consequently, these methods provide inference most suitable for situations where sequence evolution follows a MCA (e.g. influenza A-H3N2 in human hosts, as in [
 <xref ref-type="bibr" rid="B9">9</xref>]) or deviates from the MCA homogenously in time (e.g. perhaps influenza A in wild fowl, see [
 <xref ref-type="bibr" rid="B3">3</xref>]). In considering divergence events between viral subtypes, even when the MCA well-approximates nucleotide substitution within a given subtype, the above methods may incorrectly infer the time of divergence across subtypes. By either assuming that a single rate of nucleotide substitution holds for the region preceding the common ancestor of each subtype or by smoothing the rate of nucleotide substitution over clades with different numbers of taxa, the adherence to a MCA prevents direct inference of the rate during subtype divergence.
</p>
