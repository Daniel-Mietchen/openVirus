<?xml version="1.0" encoding="UTF-8"?>
<p id="p0025">Among the existing analytical tools artificial intelligence (AI) has been identified as the most powerful and promising for mankind (
 <xref rid="bb0280" ref-type="bibr">Silver et al., 2017</xref>). AI is the output from the input resource: big data that needs to be cleaned, structured, and integrated. What we refer as big data can be defined by volume, velocity, variety, variability, veracity, and complexity. These terms refer to the amount of data, the speed of data in and out, the range of data types and sources, and accuracy and correctness, respectively. However, most of the volume and velocity of data in health care as of today are not high enough to require big data. Most health-related studies do not require the support of data scientists but of bioinformaticians and statisticians. However, in a context of omics generating hundreds of thousands of data points for gene polymorphism, gene expression, metabolomics, lipidomics, and proteomics, there is a need to develop better tools to identify specific cases from the overall orientation of the mass of data.
</p>
