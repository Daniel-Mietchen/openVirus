<?xml version="1.0" encoding="UTF-8"?>
<p>However, the relative few antigenic data is available in some periods for H1N1 viruses, which could hinder the development of computational models and further hamper the performance of prediction on antigenic variants. Meanwhile, the mutation pattern analyses demonstrated the diversity of influenza virus antigens in different periods. Single model was built to predict their antigenicity at first. The results turned out that these single models performed much worse trained and tested in different types than in the same type, suggesting single model is not capable of predicting antigenicity across types with acceptable confidence. Therefore, a stacking model was developed that integrated all the situations of antigenic variants prediction of influenza H1N1 HA1 proteins in different types using all the antigenic data. Feature vectors extracted by three different methods were applied on the stacking model. Although it performed slightly inferior to single models which were trained and tested in the same type in 
 <xref rid="pone.0207777.t003" ref-type="table">Table 3</xref>, the performance of predicting antigenic variants by the stacking model across types was much better than the single model. Besides, we can also find that the stacking model showed the best performance compared with other classifiers applied at level 2, exceeding 0.87 in accuracy on average. This could be the optimized classifiers applied individual types that constitute the level 2 of the base models, enabling us to average out the noise from diverse models and thereby enhance the generalized prediction results. This is sometimes referred as an approach named “wisdom of crowds”, pulling from the age-old philosophy of Aristotle [
 <xref rid="pone.0207777.ref044" ref-type="bibr">44</xref>]. By combining antigenic data from all types in terms of epidemic and pandemic information and using diverse modeling approaches, the stacking model gain more accuracy and robustness than a fine-tuned single model can obtain.
</p>
