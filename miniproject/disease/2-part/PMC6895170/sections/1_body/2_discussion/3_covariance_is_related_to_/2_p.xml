<?xml version="1.0" encoding="UTF-8"?>
<p id="Par20">While the covariance networks can be statistically described using scale-free or random node-degree distributions, insights into the covariance come from the observed exponent, 
 <italic>γ</italic> ~ 1, in the scale-free distribution. Random networks (Erdos-Renyi model), small world networks (Watts-Strogatz model
 <sup>
  <xref ref-type="bibr" rid="CR39">39</xref>
 </sup>) and self-similar networks (Barabasi-Albert model
 <sup>
  <xref ref-type="bibr" rid="CR40">40</xref>,
  <xref ref-type="bibr" rid="CR41">41</xref>
 </sup>) arising in diverse contexts such as WWW, protein-protein interactions, citation networks, etc have been well studied. The powerlaw with 
 <italic>γ</italic> ~ 1 observed in the covariance network is different from the typical powerlaws 
 <italic>γ</italic> varying from 2 to 3 and is closer to the behavior in co-authorship networks. Some of the mechanisms that explain the observed phenomena are preferential attachment model
 <sup>
  <xref ref-type="bibr" rid="CR33">33</xref>
 </sup> where newer edges are added to a node depending on its current degree, or based on its pre-defined fitness or a potential for a degree. Unlike a citation network, there is no reason to believe that the covariance network evolves with a continuous increase in the number of nodes and edges. In the model presented in this work, powerlaw with exponent 
 <italic>γ</italic> ~ 1 was derived assuming that the covariance between a given pair of amino acids depends simultaneously on the conservation of both these amino acids under consideration. The model captures the observed powerlaw with the minimal assumption that the covariation of a pair of amino acids is related simultaneously to their conservations, which seems plausible.
</p>
