<?xml version="1.0" encoding="UTF-8"?>
<disp-quote content-type="editor-comment">
 <p>An attempt to fix this problem is made via the use of a method which estimates Ne along with a selection coefficient for each SNP. I am not convinced that this method is effective in the context of the data collected. Whereas the original application of this method was to a dataset for which sequence data was collected at 13 separate time-points (Foll et al., 2014), here only two time-points are available for each patient (Results section). In estimating the value of Ne from time-resolved data, the value of selection, speaking loosely, is estimated from the increase or decrease of an allele frequency over time, while the extent of drift (or Ne) is estimated from the extent of deviation of the data from a deterministic model of selection (see e.g. Feder et al., 2014). Where data is collected for only two time-points, a deterministic model (with effectively infinite Ne) can be fitted perfectly to any allele frequency data, with a different selection coefficient being fitted to each variant. I am therefore unclear where the value of Ne estimated from this method arises from; perhaps fitting a prior to the selection coefficient affects this? I note that the method, while validated for the inference of selection from two time-points, is not validated in the original publication for its ability to infer Ne.</p>
</disp-quote>
