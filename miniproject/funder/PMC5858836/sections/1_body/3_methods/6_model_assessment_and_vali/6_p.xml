<?xml version="1.0" encoding="UTF-8"?>
<p>For model validation, we compared model fitted values for epidemic intensity with CDC ILI and laboratory surveillance data, which are derived from approximately 2,000 ILI-reporting sentinel physicians and 100,000-200,000 respiratory specimens annually (details in Section 2 in 
 <xref ref-type="supplementary-material" rid="pcbi.1006020.s001">S1 Appendix</xref>). We assessed model robustness through additional cross-validation and out-of-sample validation analyses; the total population epidemic intensity model was refit where 20%, 40%, 60%, 80%, 90%, 95%, and 97.5% of all county observations were randomly replaced with NAs (
 <italic>sentinels in fixed locations</italic>), and where 20%, 40%, 60% and 80% of model observations were stratified by season and randomly replaced with NAs (
 <italic>sentinels in moving locations</italic>). We also refit three models where one, three, and five of seven flu seasons were randomly chosen and completely replaced with NAs (
 <italic>inclusion of historical data</italic>). To account for variability due to random chance, models were replicated ten times each with different random seeds. For each sequence of missingness, we performed out-of-sample validation by comparing the mean fitted values to the true observed values for all data that were randomly removed across seasons and replicates (Section 3.4 in 
 <xref ref-type="supplementary-material" rid="pcbi.1006020.s001">S1 Appendix</xref>). We then compared the magnitude and significance of socio-environmental and measurement drivers, and the posterior distributions of county-season fitted values. Fitted value distributions were noted as significantly different (i.e., values did not match) if the interquartile ranges for two fitted values failed to overlap with each other (Section 3.2 in 
 <xref ref-type="supplementary-material" rid="pcbi.1006020.s001">S1 Appendix</xref>). The results described in “Sentinel surveillance design” use methods identical to this analysis and may be interpreted additionally as model sensitivity and robustness.
</p>
