<?xml version="1.0" encoding="UTF-8"?>
<p>At this point we can only speculate but would argue that it is likely a combination of various factors. The first one is the already mentioned similarity in symptoms to other arboviral diseases, which, given the chikungunya outbreak that took place in 2014-2015, one season before the introduction of the Zika virus, could have led to a high number of misdiagnosed cases. Limited surveillance is certainly another big factor, and as shown in this study could have contributed to the large number of missed cases in 2015-2016. With regards to spatial effects, or rather the lack thereof in our ODE model approach, this is an interesting aspect and we agree that this could have led to an overall overestimation of the attack rate and hence underestimation of the observation rate (as is usually the case with ODE models). Unfortunately we do not have access to higher spatially resolved case data to explore this in more detail but have added this as a Discussion point in our revised version. Because of these uncertainties we present sensitivity analyses over the observation rate (
 <xref ref-type="fig" rid="fig5">Figure 5A</xref>) as well as the number of microcephaly (MC) cases and the associated risk. In this context, we would like to note that model validation comes partially from estimated parameters. That is, although we leave certain parameters free in the model, these are obtained by the fitting procedure and crucially match expectations from the literature (e.g. human infectious period, mosquito life-span, etc.). Furthermore, we obtain a risk of MC per pregnancy that matches previous reports. We therefore argue that although it is possible that several factors are missing from our modelling approach, such small validations are reassuring in the sense that they match expectations and dictate that model calibration by the MCMC approach, based on reported data, fits biological and epidemiological expectations.
</p>
