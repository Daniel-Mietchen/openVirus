<?xml version="1.0" encoding="UTF-8"?>
<p>This approach has several limitations. As far as data are concerned, crowdsourced digital data are intrinsically biased due to the fact that the participants are self-selected and not representative of the general population, as extensively explored in a previous work [
 <xref rid="pcbi.1006173.ref035" ref-type="bibr">35</xref>]. However, such sample biases do not affect the robustness and accuracy of the epidemiological signal detected through participatory surveillance [
 <xref rid="pcbi.1006173.ref037" ref-type="bibr">37</xref>, 
 <xref rid="pcbi.1006173.ref039" ref-type="bibr">39</xref>, 
 <xref rid="pcbi.1006173.ref043" ref-type="bibr">43</xref>]. Previous works have shown that selecting groups with specific reporting patterns or combining data sources can improve the representativeness [
 <xref rid="pcbi.1006173.ref028" ref-type="bibr">28</xref>, 
 <xref rid="pcbi.1006173.ref066" ref-type="bibr">66</xref>, 
 <xref rid="pcbi.1006173.ref067" ref-type="bibr">67</xref>]. Extending this study, we will incorporate in our framework the user attributes to account for selection biases.
</p>
