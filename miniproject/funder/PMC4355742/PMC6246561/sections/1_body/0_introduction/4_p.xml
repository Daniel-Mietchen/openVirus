<?xml version="1.0" encoding="UTF-8"?>
<p id="Par6">The fight against online misinformation requires a grounded assessment of the relative impact of different mechanisms by which it spreads. If the problem is mainly driven by cognitive limitations, we need to invest in news literacy education; if social media platforms are fostering the creation of echo chambers, algorithms can be tweaked to broaden exposure to diverse views; and if malicious bots are responsible for many of the falsehoods, we can focus attention on detecting this kind of abuse. Here we focus on gauging the latter effect. With few exception
 <sup>
  <xref ref-type="bibr" rid="CR2">2</xref>,
  <xref ref-type="bibr" rid="CR30">30</xref>,
  <xref ref-type="bibr" rid="CR32">32</xref>,
  <xref ref-type="bibr" rid="CR33">33</xref>
 </sup>, the literature about the role played by social bots in the spread of misinformation is largely based on anecdotal or limited evidence; a quantitative understanding of the effectiveness of misinformation-spreading attacks based on social bots is still missing. A large-scale, systematic analysis of the spread of misinformation by social bots is now feasible thanks to two tools developed in our lab: the Hoaxy platform to track the online spread of claims
 <sup>
  <xref ref-type="bibr" rid="CR33">33</xref>
 </sup> and the Botometer machine learning algorithm to detect social bots
 <sup>
  <xref ref-type="bibr" rid="CR26">26</xref>
 </sup>. Here we examine social bots and how they promote the spread of misinformation through millions of Twitter posts during and following the 2016 US presidential campaign. We find that social bots amplify the spread of misinformation by exposing humans to this content and inducing them to share it.
</p>
