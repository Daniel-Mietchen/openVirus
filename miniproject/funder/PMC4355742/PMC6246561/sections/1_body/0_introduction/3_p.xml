<?xml version="1.0" encoding="UTF-8"?>
<p id="Par5">Abuse of online information ecosystems can both exploit and reinforce these vulnerabilities. While fabricated news are not a new phenomenon
 <sup>
  <xref ref-type="bibr" rid="CR24">24</xref>
 </sup>, the ease with which social media can be manipulated
 <sup>
  <xref ref-type="bibr" rid="CR5">5</xref>
 </sup> creates novel challenges and particularly fertile grounds for sowing disinformation
 <sup>
  <xref ref-type="bibr" rid="CR25">25</xref>
 </sup>. Public opinion can be influenced thanks to the low cost of producing fraudulent websites and high volumes of software-controlled profiles, known as social bots
 <sup>
  <xref ref-type="bibr" rid="CR10">10</xref>,
  <xref ref-type="bibr" rid="CR26">26</xref>
 </sup>. These fake accounts can post content and interact with each other and with legitimate users via social connections, just like real people
 <sup>
  <xref ref-type="bibr" rid="CR27">27</xref>
 </sup>. Bots can tailor misinformation and target those who are most likely to believe it, taking advantage of our tendencies to attend to what appears popular, to trust information in a social setting
 <sup>
  <xref ref-type="bibr" rid="CR28">28</xref>
 </sup>, and to trust social contacts
 <sup>
  <xref ref-type="bibr" rid="CR29">29</xref>
 </sup>. Since earliest manifestations uncovered in 2010
 <sup>
  <xref ref-type="bibr" rid="CR4">4</xref>,
  <xref ref-type="bibr" rid="CR5">5</xref>
 </sup>, we have seen influential bots affect online debates about vaccination policies
 <sup>
  <xref ref-type="bibr" rid="CR10">10</xref>
 </sup> and participate actively in political campaigns, both in the United States
 <sup>
  <xref ref-type="bibr" rid="CR30">30</xref>
 </sup> and other countries
 <sup>
  <xref ref-type="bibr" rid="CR31">31</xref>,
  <xref ref-type="bibr" rid="CR32">32</xref>
 </sup>.
</p>
