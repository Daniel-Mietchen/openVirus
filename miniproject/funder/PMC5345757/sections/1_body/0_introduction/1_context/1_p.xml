<?xml version="1.0" encoding="UTF-8"?>
<p>It is perhaps unsurprising that societal advances in technology, education, and medicine are concomitant with reduced morbidity and mortality associated with infectious diseases [
 <xref rid="pcbi.1005248.ref001" ref-type="bibr">1</xref>]. This is exemplified by the staggering drop in infectious disease mortality in the United States during the 20th century [
 <xref rid="pcbi.1005248.ref002" ref-type="bibr">2</xref>]. Yet despite continued technological advances, the U.S. death rate due to infectious disease has not improved significantly since around the 1960s, and in fact has been rising since the 1980s [
 <xref rid="pcbi.1005248.ref003" ref-type="bibr">3</xref>]. It is evident that incremental advances in medical treatment are failing to reduce overall infectious disease mortality. One way in which the situation can be improved is through expanding our capacity for preparedness and preventionâ€”we need forewarning [
 <xref rid="pcbi.1005248.ref004" ref-type="bibr">4</xref>]. This is the defining problem out of which the nascent field of epidemiological forecasting has risen.
</p>
