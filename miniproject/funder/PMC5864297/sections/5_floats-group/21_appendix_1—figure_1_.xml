<?xml version="1.0" encoding="UTF-8"?>
<fig id="app1fig1" orientation="portrait" position="anchor">
 <object-id pub-id-type="doi">10.7554/eLife.30756.033</object-id>
 <label>Appendix 1—figure 1.</label>
 <caption>
  <title>Intuitive Description of Self and Cross Models.</title>
  <p>
   <italic>Plate A</italic> illustrates the notion of self-models. Historical data is first represented as a symbol sequence (denoted as ‘Data stream’ in Plate A) using space-time discretization and magnitude quantization. For example, we may use a spatial discretization of 
   <inline-formula>
    <math id="inf330">
     <mrow>
      <mo mathvariant="normal">±</mo>
      <msup>
       <mn mathvariant="normal">3</mn>
       <mo mathvariant="normal">∘</mo>
      </msup>
     </mrow>
    </math>
   </inline-formula> in both latitudes and longitudes, a temporal discretization of 
   <inline-formula>
    <math id="inf331">
     <mn mathvariant="normal">1</mn>
    </math>
   </inline-formula> week, and a binary magnitude quantization that maps all magnitudes below 
   <inline-formula>
    <math id="inf332">
     <mn mathvariant="normal">4.0</mn>
    </math>
   </inline-formula> to symbol 
   <inline-formula>
    <math id="inf333">
     <mn mathvariant="normal">0</mn>
    </math>
   </inline-formula>, and all higher magnitudes to symbol 
   <inline-formula>
    <math id="inf334">
     <mn mathvariant="normal">1</mn>
    </math>
   </inline-formula>. This symbol stream then represents a sample path from a hidden, quantized stochastic process. A self-model is a generative model of this data stream, which captures symbol patterns that causally determine (in a probabilistic sense) future symbols. Specifically, our inferred self-model (see Plate A(i) for an example) is a probabilistic, finite state automata (PFSA). 
   <italic>Plate B</italic> illustrates the notion of cross-models. Instead of inferring a model from a given stream to predict future symbols in the same stream, we now have two symbol streams (Data Stream I and Data Stream II), and the cross-model is essentially a generative model that attempts to predict symbols in one stream by reading historical data in another. Notably, as shown in Plate B(i), the cross-model is syntactically not exactly a PFSA (arcs have no probabilities in the cross-model, but each state has an output distribution). We call such models ”crossed probabilistic finite state automata,’ or XPFSA. Once these models are inferred, they may be used to predict the future evolution of the data streams. Thus, the self-model in Plate A may be initialized with its unique stationary distribution, after which a relatively short observed history would dictate the current distribution on the model states. This, in turn, would yield a distribution over the symbol alphabet in the next time step. For a cross-model, we would be able to obtain future symbol distribution in the second stream, given a short history in the first stream. Note that the cross-model from I
   <inline-formula>
    <math id="inf335">
     <mo mathvariant="normal">→</mo>
    </math>
   </inline-formula> II is not necessarily the same as the cross-model in the other direction.
  </p>
 </caption>
 <graphic xlink:href="elife-30756-app1-fig1" xmlns:xlink="http://www.w3.org/1999/xlink"/>
</fig>
