<?xml version="1.0" encoding="UTF-8"?>
<p>An issue in machine learning models is how good they are at generalizing to inputs outside their training set [
 <xref rid="pcbi.1006954.ref011" ref-type="bibr">11</xref>,
 <xref rid="pcbi.1006954.ref019" ref-type="bibr">19</xref>,
 <xref rid="pcbi.1006954.ref020" ref-type="bibr">20</xref>]. In computational studies about HIV neutralization epitopes it is relatively common to have one model trained for each antibody under study [
 <xref rid="pcbi.1006954.ref021" ref-type="bibr">21</xref>â€“
 <xref rid="pcbi.1006954.ref023" ref-type="bibr">23</xref>]. By contrast, in this work only one model was trained to predict the neutralization breadth of all antibodies. We note that our training set did contain some experimental data from each antibody under study. This suggests the generalization ability of the model should be examined. 
 <xref ref-type="fig" rid="pcbi.1006954.g006">Fig 6</xref> shows how the predicted breadth of each antibody changes when an increasing number of experimental data relative to that antibody are included in the training set. At zero, no relevant experimental data are included; e.g. for the VRC01 antibody, at zero no experimental IC
 <sub>50</sub> value of the VRC01 antibody is included in the training set. In these plots, the blue line is the breath computed using all available experimental data in the training set, while the red line is the experimental neutralization breadth. Comparing the plots for different antibodies, about half of them have a good breadth prediction even at zero, and the predicted breadth does not change significantly upon inclusion of more data; see for examples antibodies 1B2530, 8ANC131, 8ANC134, CH103, VRC01, VRC07, VRC-PG20. For other antibodies the prediction at zero is quite far from the experimental value; e.g. antibodies NIH45-46, CAP257-RH1, CH235.12, or N6. However, all these antibodies converge to the correct experimental value when a relatively small number of experimental values are included in the training set, usually between 10 and 20, relative to the total number of values available (see 
 <xref rid="pcbi.1006954.t001" ref-type="table">Table 1</xref>). The Pearson correlation coefficient between the computed and experimental breadth is 0.50 for the classifier with zero experimental data when all but 4 out of the 23 antibodies studied are included in the analysis (excluded antibodies are N6, CAP257-RH1, CH235.12 and NIH45-46, which have the highest error in the computed breadth). When the entire set of antibodies is considered, the correlation coefficient is 0.14; including just one experimental value per antibody, the Pearson coefficient increases to 0.54, and it reaches 0.90 when including only four experimental values. Another point to consider is that the good results obtained for some antibodies are due to their close similarity to other antibodies in the training set; e.g. the 8ANC131/8ANC134 pair and the VRC01/VRC07 pair. These results show that the neural network model is able to predict accurate values for the breadth in instances when a small number of experimental data for the antibody under study, or a close relative, are included in the training set.
</p>
