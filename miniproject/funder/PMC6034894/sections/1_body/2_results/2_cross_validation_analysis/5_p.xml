<?xml version="1.0" encoding="UTF-8"?>
<p>When given subsets of these forecasting methods as input, with regard to average performance: 
 <list list-type="bullet">
  <list-item>
   <p>the uniformly weighted ensemble often outperforms the best individual, but is sometimes slightly (≈ 0.1 log score) worse;</p>
  </list-item>
  <list-item>
   <p>the stacking approach improves upon the performance of the uniformly weighted ensemble; and</p>
  </list-item>
  <list-item>
   <p>the adaptive weighting scheme’s performance is equal to or better than that of the fixed-weight scheme, sometimes improving on the log score by ≈ 0.1. The adaptive weighting scheme’s relative performance appears to improve with more input seasons, fewer ensemble components, and increased variety in underlying methodologies and component performance. These trends suggest that using wider RelevanceWeight kernels, regularizing the component weights, or considering additional data from 2003/2004 to 2009/2010, for which ground truth wILI but not weekly ILINet reports are available, may improve the performance of the adaptive weighting scheme. In addition to these avenues for possible improvement in ensemble weights for the components presented in 
    <xref ref-type="fig" rid="pcbi.1006134.g005">Fig 5</xref>, the adaptive weighting scheme provides a natural way of incorporating forecasting methods that generate predictions for only a subset of all targets, forecast weeks, or forecast types (distributional forecast or point prediction). For example, in the 2015/2016 season, we incorporated a generalized additive model that provided point predictions (and later, distributional forecasts) for peak week and peak height given at least three weeks of observations from the current season.
   </p>
  </list-item>
 </list>
</p>
