<?xml version="1.0" encoding="UTF-8"?>
<fig id="pcbi.1006134.g006" orientation="portrait" position="float">
 <object-id pub-id-type="doi">10.1371/journal.pcbi.1006134.g006</object-id>
 <label>Fig 6</label>
 <caption>
  <title>The ensemble method matches or beats the best component overall, consistently improves log score across all times, and, for some sets of components, can provide significant improvements in both log score and mean absolute error.</title>
  <p>These plots display cross-validation performance for two ensembles and some components broken down by evaluation metric, target type, and forecast week; each point is an average of cross-validation evaluations for all 11 locations, seasons 2010/2011 to 2015/2016, and all targets of the given target type; data from the appropriate ILINet reports is used as input for the left-out seasons, while finalized wILI is used for the training seasons. Top half: log score evaluations (higher is better); bottom half: mean absolute error, normalized by the standard deviation of each target (lower is better). Left side: full Delphi-Stat ensemble, which includes additional methods not listed in thelegend; right side: ensemble of the three methods listed in the legend, plus a uniform distribution component for distributional forecasts. Many components of the full ensemble are not displayed. The “Targets, uniform” method is excluded from any mean absolute error plots as it was not incorporated into the point prediction ensembles.</p>
 </caption>
 <graphic xlink:href="pcbi.1006134.g006" xmlns:xlink="http://www.w3.org/1999/xlink"/>
</fig>
