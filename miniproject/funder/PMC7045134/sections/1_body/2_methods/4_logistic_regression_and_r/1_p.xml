<?xml version="1.0" encoding="UTF-8"?>
<p>In addition to XGBoost, we also employed other ML models, including logistic regression (LR) and random forest (RF). LR is a widely used method in medicine and is used as an ML model for classification tasks; however, LR is based on the assumption that a linear relationship exists between the input variables and the outcomes.
 <xref rid="R27" ref-type="bibr">27</xref> With regards to XGBoost and RF, both models are tree-based classifiers; however, these two ML models have substantial differences in ensemble method: XGBoost is based on boost, whereas RF is based on bagging.
 <xref rid="R24" ref-type="bibr">24 28</xref> In detail, XGBoost is based on the ensemble of weak learners and is characterised by high bias and low variance.
 <xref rid="R25" ref-type="bibr">25</xref> In contrast, RF is designed as fully grown decision trees and is hence characterised by low bias and high variance.
 <xref rid="R29" ref-type="bibr">29</xref> In RF, max_depth was 4 and n_estimators was 100, while default values were used for the other parameters in RF and LR (see 
 <xref ref-type="supplementary-material" rid="SP1">online supplementary table 1</xref> for detailed parameters).
</p>
