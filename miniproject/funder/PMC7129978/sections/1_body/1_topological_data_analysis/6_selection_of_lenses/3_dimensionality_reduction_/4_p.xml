<?xml version="1.0" encoding="UTF-8"?>
<p id="p0044">PCA reduces the data into linearly uncorrelated variables (called 
 <italic>principal components</italic>) such that the first component accounts for as much of the variability in the data as possible, and each succeeding component in turn accounts for the next highest variance possible and is orthogonal to the preceding components. When used in dimensionality reduction, one can take the first few principal components as the new set of features of the data set. To implement this, we used sklearn.decomposition.PCA.
</p>
