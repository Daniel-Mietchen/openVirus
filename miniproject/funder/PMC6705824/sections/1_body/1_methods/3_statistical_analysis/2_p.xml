<?xml version="1.0" encoding="UTF-8"?>
<p>To help facilitate the identification of an ML solution, we considered two different methods of reducing the amount of unknown information [
 <xref rid="pone.0221558.ref050" ref-type="bibr">50</xref>]. First, we considered all 12 indicators with Bayesian priors (1.0) and imposed parameter restrictions that constrained parameter estimates to be equivalent across classes for two indicators: “
 <italic>I am concerned about talking to HCPs about having sex with men</italic>” and “
 <italic>People might assume I am promiscuous</italic>.” These indicators were chosen because they were least prevalent within their respective domains and had similar item-response probabilities within classes to two other indicators (i.e., 
 <italic>“I am concerned about talking to HCPs about having sex with men”</italic> was similar to 
 <italic>“I will receive poor healthcare if HCPs know I have sex with men”</italic> and 
 <italic>“People might assume I am promiscuous”</italic> was similar to 
 <italic>“People might assume I am HIV+”</italic>) [
 <xref rid="pone.0221558.ref051" ref-type="bibr">51</xref>]. Second, we considered only 10 indicators, excluding 
 <italic>“I am concerned about talking to HCPs about having sex with men”</italic> and 
 <italic>“People might assume I am promiscuous</italic>.
 <italic>”</italic> Using the first method we were again unable to identify an ML solution for models with more than two classes. However, using the second method, we were able to identify models with one to three classes. Therefore, we proceeded with the models identified via the second method. Next, we examined bivariate residuals (BVRs) to determine whether the local independence assumption underlying LCA may be violated (
 <xref ref-type="supplementary-material" rid="pone.0221558.s001">S1 Table</xref>) and allowed for local dependence between pairs of indicators with statistically significant associations (i.e., BVR&gt;3.84) [
 <xref rid="pone.0221558.ref051" ref-type="bibr">51</xref>, 
 <xref rid="pone.0221558.ref052" ref-type="bibr">52</xref>]. To select our final model, we considered fit statistics (Akaike’s information criteria [AIC], Bayesian information criteria [BIC], sample size-adjusted Bayesian information criteria [a-BIC]) and entropy as a measure of classification certainty. Lower AIC and BIC values and higher values of entropy were considered indicators of better model fit. In addition, we examined class separation (e.g., distinct patterns of item-response probabilities across latent classes), within-class homogeneity (e.g., similarity of item-response probability patterns within classes), and the meaningfulness of identified classes [
 <xref rid="pone.0221558.ref050" ref-type="bibr">50</xref>, 
 <xref rid="pone.0221558.ref051" ref-type="bibr">51</xref>].
</p>
