<?xml version="1.0" encoding="UTF-8"?>
<p>LSTM, as an advanced intelligent algorithm, enables automatic finding of the characteristics of long-term trends and the short-term fluctuation of time series data. LSTMs belong to the class of improved recurrent neural networks (RNN) and relies on the memory cell with three gating functions incorporated into its construction (
 <xref ref-type="app" rid="app1-ijerph-17-00453">Figure S1</xref>) [
 <xref rid="B33-ijerph-17-00453" ref-type="bibr">33</xref>]. The ability of the LSTM neural network to find the connection automatically between attributes in a time series is derived from learning. A learning process in the neural network model is a weight adjustment from given examples, which makes the network output a true observation without changes in the network structure [
 <xref rid="B32-ijerph-17-00453" ref-type="bibr">32</xref>]. The LSTM model consisted of 10 input parameters, such as the monthly mean maximum temperature, monthly average relative humidity, monthly raining days, and the observation taken last month. The 
 <inline-formula>
  <math id="mm2">
   <mrow>
    <mrow>
     <msub>
      <mi>X</mi>
      <mrow>
       <mi>t</mi>
       <mi>i</mi>
      </mrow>
     </msub>
     <mo>=</mo>
     <mrow>
      <mo>(</mo>
      <mrow>
       <msubsup>
        <mrow>
         <mi>P</mi>
         <mi>r</mi>
        </mrow>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mrow>
         <mi>m</mi>
         <mi>a</mi>
         <mi>x</mi>
        </mrow>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mrow>
         <mi>P</mi>
         <mi>r</mi>
        </mrow>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mi>a</mi>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mrow>
         <mi>P</mi>
         <mi>r</mi>
        </mrow>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mi>w</mi>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mi>T</mi>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mrow>
         <mi>m</mi>
         <mi>i</mi>
         <mi>n</mi>
        </mrow>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mi>T</mi>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mrow>
         <mi>m</mi>
         <mi>a</mi>
         <mi>x</mi>
        </mrow>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mi>T</mi>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mi>h</mi>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mi>P</mi>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mi>a</mi>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mi>P</mi>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mi>d</mi>
       </msubsup>
       <mo>,</mo>
       <msubsup>
        <mi>H</mi>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
        <mi>a</mi>
       </msubsup>
       <mo>,</mo>
       <msub>
        <mi>D</mi>
        <mrow>
         <mi>t</mi>
         <mi>i</mi>
        </mrow>
       </msub>
      </mrow>
      <mo>)</mo>
     </mrow>
    </mrow>
   </mrow>
  </math>
 </inline-formula> is a set of input vector sequence in the same month. The 
 <inline-formula>
  <math id="mm3">
   <mrow>
    <mrow>
     <mi>c</mi>
     <mo>=</mo>
     <mrow>
      <mo>(</mo>
      <mrow>
       <msub>
        <mi>c</mi>
        <mn>1</mn>
       </msub>
       <mo>,</mo>
       <msub>
        <mi>c</mi>
        <mn>2</mn>
       </msub>
       <mo>,</mo>
       <mo>…</mo>
       <mo>,</mo>
       <msub>
        <mi>c</mi>
        <mrow>
         <mn>64</mn>
        </mrow>
       </msub>
      </mrow>
      <mo>)</mo>
     </mrow>
    </mrow>
   </mrow>
  </math>
 </inline-formula> is the number of hidden layers in a memory cell. The input time series 
 <inline-formula>
  <math id="mm4">
   <mrow>
    <mrow>
     <mi>X</mi>
     <mo>=</mo>
     <mrow>
      <mo>(</mo>
      <mrow>
       <msub>
        <mi>X</mi>
        <mrow>
         <mi>t</mi>
         <mn>1</mn>
        </mrow>
       </msub>
       <mo>,</mo>
       <msub>
        <mi>X</mi>
        <mrow>
         <mi>t</mi>
         <mn>2</mn>
        </mrow>
       </msub>
       <mo>,</mo>
       <mo>…</mo>
       <mo>,</mo>
       <msub>
        <mi>X</mi>
        <mrow>
         <mi>t</mi>
         <mn>12</mn>
        </mrow>
       </msub>
      </mrow>
      <mo>)</mo>
     </mrow>
    </mrow>
   </mrow>
  </math>
 </inline-formula> is transmitted to the hidden layers, which contain n memory cells in each one, through weighted connections to compute output 
 <inline-formula>
  <math id="mm5">
   <mrow>
    <mi>Y</mi>
   </mrow>
  </math>
 </inline-formula>, the logarithmic of dengue cases in the subsequent month. The inputs are shown in 
 <inline-formula>
  <math id="mm6">
   <mrow>
    <mrow>
     <msub>
      <mi>X</mi>
      <mrow>
       <mi>t</mi>
       <mn>1</mn>
      </mrow>
     </msub>
    </mrow>
   </mrow>
  </math>
 </inline-formula> to 
 <inline-formula>
  <math id="mm7">
   <mrow>
    <mrow>
     <msub>
      <mi>X</mi>
      <mrow>
       <mi>t</mi>
       <mn>12</mn>
      </mrow>
     </msub>
    </mrow>
   </mrow>
  </math>
 </inline-formula> and the output is shown in 
 <inline-formula>
  <math id="mm8">
   <mrow>
    <mi>Y</mi>
   </mrow>
  </math>
 </inline-formula> (
 <xref ref-type="fig" rid="ijerph-17-00453-f003">Figure 3</xref>).
</p>
