<?xml version="1.0" encoding="UTF-8"?>
<p>Theoretical work predicts the existence of a limiting value of error or mutation rate—termed the “error threshold”—that must not be surpassed if the wild-type is to be kept stable (Eigen 
 <xref ref-type="bibr" rid="CR30">1971</xref>, 
 <xref ref-type="bibr" rid="CR31">2002</xref>). It has been suggested that mutation rates for RNA viruses are close to the error threshold, and can be forced into error catastrophe by a moderate increase in mutation rate. Pioneer studies demonstrated that mutagenesis by a variety of chemical mutagens conferred only 1.1 – to 2.8-fold increases in mutation frequencies at defined single base sites in vesicular stomatitis virus and poliovirus (Holland et al. 
 <xref ref-type="bibr" rid="CR44">1990</xref>). These results suggested that a high mutation rate is an adaptive trait of RNA viruses and that RNA virus genomes are unable to tolerate many additional mutations without a loss of viability. Studies on HIV-1, lymphocytic choriomeningitis virus, and foot and mouth disease virus have led to similar conclusions (Grande-Perez et al. 
 <xref ref-type="bibr" rid="CR40">2002</xref>; Loeb et al. 
 <xref ref-type="bibr" rid="CR66">1999</xref>; Sierra et al. 
 <xref ref-type="bibr" rid="CR110">2000</xref>). This concept of the error threshold opened a new paradigm for how to fight viruses, not by inhibiting their replication but rather by favoring it with an increased rate of mutation (Fig. 
 <xref rid="Fig2" ref-type="fig">2</xref>). Several studies in cell culture and in vivo have supported lethal mutagenesis as a viable antiviral strategy (Lauring and Andino 
 <xref ref-type="bibr" rid="CR57">2010</xref>), and a clinical trial was recently reported in which a mutagenic pyrimidine analog was administered to HIV-1 infected patients (Mullins et al. 
 <xref ref-type="bibr" rid="CR83">2011</xref>). 
</p>
