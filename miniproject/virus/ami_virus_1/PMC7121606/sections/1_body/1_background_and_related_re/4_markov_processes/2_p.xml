<?xml version="1.0" encoding="UTF-8"?>
<p>A Markov process is a mathematical formalism used to describe changes occurring to the state of a stochastic system in discrete time steps (Solow and Smith 
 <xref ref-type="bibr" rid="CR32">2006</xref>; Winston 
 <xref ref-type="bibr" rid="CR41">1994</xref>). A Markov process consists of a number of states (or values) through which the system may transition at any given time. Mathematically, a Markov process is defined as a sequence of time dependent random variables 
 <italic>X</italic>
 <sub>0</sub>,
 <italic> X</italic>
 <sub>1</sub>,
 <italic> X</italic>
 <sub>2</sub>, ..., where 
 <italic>X</italic>
 <sub>
  <italic>t</italic>
 </sub> is a random variable that describes the state of the process at discrete time t. The initial or starting state of the system is typically represented by 
 <italic>X</italic>
 <sub>0</sub>. Transitions from one state to another are governed by the following three laws: (1) a Markov process may be in only one given state at any instant of time; (2) transition from one state to another occurs instantaneously in discrete time steps; and (3) the next state to which the process transitions is purely determined by the current state of the system and not its past. In other words, the past, present, and future states of a Markov process are independent of each other (Winston 
 <xref ref-type="bibr" rid="CR41">1994</xref>).
</p>
