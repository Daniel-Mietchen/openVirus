<?xml version="1.0" encoding="UTF-8"?>
<p id="par0050">The theory of sampling from an intractable distribution using Markov chains was originally presented in the early fifties, but, having been born from the field of physics, its potential as a tool in epidemic modelling went largely unnoticed. At the time, it was also not very practical for applied use: even with the most advanced tools available to the 1950s analyst, the original Metropolis paper reports that a run of less than 100 iterations took five hours to complete. These methods were brought more mainstream by Geman and Geman 1984, and Gelfand and Smith 1990. These methods, now referred to as Markov chain Monte Carlo (MCMC), to approximate the posterior distribution has provided an incredibly useful and simple iterative method. It is particularly useful inside the Bayesian framework, but also any situation where a probability distribution can be derived by linking the data and the parameters of the model. It provides a way of exploring the parameter space and obtaining representative samples of the parameters compatible with the target distributions. We assume in this special issue that the essentials of MCMC are known. Readers who might want to look for more information in implementing MCMC can refer to (
 <xref rid="bib0085" ref-type="bibr">Gilks et al., 1996</xref>; 
 <xref rid="bib0220" ref-type="bibr">van Ravenzwaaij et al., 2018</xref>).
</p>
