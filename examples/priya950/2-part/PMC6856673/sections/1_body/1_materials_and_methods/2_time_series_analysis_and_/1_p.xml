<?xml version="1.0" encoding="UTF-8"?>
<p>To the best of our knowledge there were no epidemics reported in the target cattle population during the study period. However, there was considerable variation in the data that was known to be caused by non-epidemic events. Because the historical baselines in our study were very short, extreme outliers had a substantial effect the HW models, resulting in poor TS predictions. Extreme single time point aberrations were removed in order to obtain aberration-free historical baseline data that improved the prediction performance of our models and the performance of aberration detection algorithms (
 <xref rid="B12" ref-type="bibr">12</xref>â€“
 <xref rid="B14" ref-type="bibr">14</xref>). We chose a manual approach for outlier removal in order to preserve as much of the natural variation as possible in the data. We examined each syndrome TS visually and manually removed only the most extreme peaks. Extreme peaks were defined as weeks where the number of reported cases equaled at least two times the number of reported cases in the neighboring weeks. Once extreme peaks were identified, they were investigated in more detail to determine if they were associated with a specific health related event or not. Peaks that were associated with health related events were considered abnormal. They were removed from baseline syndrome TS and replaced by the weekly average of the 10 previous time points. The 10 week average was used as it has been reported to provide the best prediction performance for HW models. Extreme peaks that were not associated with health related events were considered part of the normal variation and left in the baseline syndrome TS. In total there were 7 abnormal values identified, 1 week in ALIS_abortion because of suspicions of Neosporosis, and 6 weeks in ALIS_IBR likely because IBR suspect cases were identified and this may have increased veterinarian awareness of the disease, causing them to increase IBR sample submission. The best HW models were evaluated using the autocorrelation and partial autocorrelation functions of the residuals (ACF and PACF, respectively) (
 <xref rid="B15" ref-type="bibr">15</xref>) and the root-mean-squared error (RMSE) (
 <xref rid="B16" ref-type="bibr">16</xref>). RMSE is a measure of the difference between the values predicted by a model and the values actually observed from the environment that is being modeled. We calculated RMSE for the differences between the observations and the predicted values within both the training period (RMSE
 <sub>t</sub>) and the validation period (RMSEv). In both cases, the predictive performance of the HW model are better when the criterion is lower.
</p>
