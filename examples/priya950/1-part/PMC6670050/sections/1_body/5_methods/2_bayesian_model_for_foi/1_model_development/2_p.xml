<?xml version="1.0" encoding="UTF-8"?>
<p>For computational convenience, we worked with 
 <inline-formula>
  <math id="kwz110ImEq7">
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mi>t</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mspace width=".25em"/>
   <mi>log</mi>
   <mspace width=".25em"/>
   <msub>
    <mrow>
     <mi mathvariant="normal">λ</mi>
    </mrow>
    <mrow>
     <mi>t</mi>
    </mrow>
   </msub>
  </math>
 </inline-formula>, which has support on the real line. A first-order Gaussian random walk prior distribution was specified to impose smoothness in the 
 <inline-formula>
  <math id="kwz110ImEq8">
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mi>t</mi>
    </mrow>
   </msub>
  </math>
 </inline-formula> estimates: 
 <inline-formula>
  <math id="kwz110ImEq9">
   <mi>p</mi>
   <mrow>
    <mrow>
     <mo stretchy="true">(</mo>
     <mrow>
      <msub>
       <mrow>
        <mi mathvariant="normal">ϕ</mi>
       </mrow>
       <mrow>
        <mn>1931</mn>
       </mrow>
      </msub>
      <mo form="prefix">,</mo>
      <mi>…</mi>
      <mo form="prefix">,</mo>
      <msub>
       <mrow>
        <mi mathvariant="normal">ϕ</mi>
       </mrow>
       <mrow>
        <mn>2017</mn>
       </mrow>
      </msub>
     </mrow>
     <mo stretchy="true">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <munderover>
    <mo form="prefix">∏</mo>
    <mrow>
     <mi>t</mi>
     <mo>=</mo>
     <mn>1932</mn>
    </mrow>
    <mrow>
     <mn>2017</mn>
    </mrow>
   </munderover>
   <mi>p</mi>
   <mo stretchy="false">(</mo>
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mi>t</mi>
    </mrow>
   </msub>
   <mspace width=".25em"/>
   <mo>|</mo>
   <mspace width=".25em"/>
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mi>t</mi>
     <mo form="prefix">−</mo>
     <mn>1</mn>
    </mrow>
   </msub>
   <mo stretchy="false">)</mo>
  </math>
 </inline-formula>, where 
 <inline-formula>
  <math id="kwz110ImEq10">
   <mrow>
    <msub>
     <mrow>
      <mi mathvariant="normal">ϕ</mi>
     </mrow>
     <mrow>
      <mi>t</mi>
     </mrow>
    </msub>
   </mrow>
   <mo>|</mo>
   <mspace width=".25em"/>
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mi>t</mi>
     <mo form="prefix">−</mo>
     <mn>1</mn>
    </mrow>
   </msub>
   <mo>∼</mo>
   <mi>N</mi>
   <mo stretchy="false">(</mo>
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mi>t</mi>
     <mo form="prefix">−</mo>
     <mn>1</mn>
    </mrow>
   </msub>
   <mo>,</mo>
   <mspace width=".25em"/>
   <msup>
    <mrow>
     <mi mathvariant="normal">τ</mi>
    </mrow>
    <mrow>
     <mo form="prefix">−</mo>
     <mn>1</mn>
    </mrow>
   </msup>
   <mo stretchy="false">)</mo>
  </math>
 </inline-formula> and the precision parameter 
 <inline-formula>
  <math id="kwz110ImEq11">
   <mi mathvariant="normal">τ</mi>
  </math>
 </inline-formula> was assigned a weakly informative prior: 
 <inline-formula>
  <math id="kwz110ImEq12">
   <mi mathvariant="normal">τ</mi>
   <mspace width=".25em"/>
   <mo>~</mo>
   <mspace width=".25em"/>
   <mi>Γ</mi>
   <mo stretchy="false">(</mo>
   <mn>8</mn>
   <mo>,</mo>
   <mn>0.02</mn>
   <mo stretchy="false">)</mo>
  </math>
 </inline-formula>. The posterior distribution for 
 <inline-formula>
  <math id="kwz110ImEq13">
   <mi mathvariant="normal">θ</mi>
   <mo>=</mo>
   <mo stretchy="false">(</mo>
   <mi mathvariant="normal">α</mi>
   <mo>,</mo>
   <mi mathvariant="normal">τ</mi>
   <mo>,</mo>
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mn>1931</mn>
    </mrow>
   </msub>
   <mo form="prefix">,</mo>
   <mi>…</mi>
   <mo form="prefix">,</mo>
   <mspace width=".25em"/>
   <msub>
    <mrow>
     <mi mathvariant="normal">ϕ</mi>
    </mrow>
    <mrow>
     <mn>2017</mn>
    </mrow>
   </msub>
   <mo stretchy="false">)</mo>
  </math>
 </inline-formula> was sampled using the Markov chain Monte Carlo method over 170,000 iterations. We discarded the initial 20,000 iterations as burn-in data and subsequently saved every 30th iteration to obtain a posterior sample of size 5,000.
</p>
