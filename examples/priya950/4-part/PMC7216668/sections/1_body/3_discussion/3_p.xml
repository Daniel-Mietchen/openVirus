<?xml version="1.0" encoding="UTF-8"?>
<p id="Par57">In this study, we developed and validated an MTL-SGL method, allowing for the training and learning of multiple categories of features and the integration of datasets from multiple sources (e.g., those generated using different reagents, supplies, and protocols) in the sparse learning process. Specifically, two types of features (protein sequence and 
 <italic>N</italic>-glycosylation) were used; a multi-task framework was applied to strategically distribute multiple datasets as different tasks. Mathematically, MTL-SGL integrates Lasso (L1 norm), group lasso (L2 norm), and multi-task framework. The penalty combines with L1 and L2 norm regulate sparse at both the group and individual feature. Furthermore, multi-task penalty controls sparse across multiple tasks. Results from this study suggest the MTL-SGL model performed better than two conventional multi-task models (
 <italic>ℓ</italic>
 <sub>1, 2</sub> MTL and 
 <italic>ℓ</italic>
 <sub>1, ∞</sub> MTL) and two conventional single-task learning models (SGL and LASSO) (Table 
 <xref rid="Tab1" ref-type="table">1</xref>). These results suggested that considering features from different biological properties as different groups improves model performance. This MTL-SGL method has potential scalability in feature categories and can be expanded to add other types of features in HA into the learning process, even those across other genomic segments (e.g., NA).
</p>
