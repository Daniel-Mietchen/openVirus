<?xml version="1.0" encoding="UTF-8"?>
<p id="p0065">In this with the need to improve the utilization of AI in the context of infectious diseases, we believe that identification of earliest signs of transmission: the combination of extreme value theory and robust statistical methods-based analysis should be applied (
 <xref rid="bb0115" ref-type="bibr">Ferro and Segers, 2003</xref>; 
 <xref rid="bb0215" ref-type="bibr">Mikosch and Wintenberger, 2014</xref>; 
 <xref rid="bb0090" ref-type="bibr">Deheuvels, 1991</xref>; 
 <xref rid="bb0285" ref-type="bibr">Smith, 1989</xref>). The first two steps of correlation/event analysis framework should filter most of the data and only let a small fraction pass to the last step. The goal is to scrutinize the unfiltered data in order to detecting suspicious observations. Here again, the main issue lies in the learning of the dynamic BN. For this purpose, the first step is to store dataset in a convenient way, often in a specific database (e.g., not only structured query language: NoSQL) that will enable fast extraction. The second problem that must be handled lies in the scores used by learning algorithms to determine the conditional independences required to define the graphical structure of the BN. Actually, those are closely related to statistical independence tests (essentially to cross entropy) (
 <xref rid="bb0145" ref-type="bibr">Gonzales and Wuillemin, 2011</xref>). While this is meaningful in many contexts, it seems that this kind of test is inappropriate for learning anomalies because the latter should be related to rare events whereas the aforementioned statistical tests are not. Therefore, the focus should be in the rare events and to apply statistical methods suited for this context. This paradigm shift is important because, in our opinion, it is one of the keys to better detect outliers in medical database (
 <xref rid="bb0015" ref-type="bibr">Barnett and Lewis, 1995</xref>; 
 <xref rid="bb0120" ref-type="bibr">Filmoser et al., 2008</xref>). An important aspect of uncertainty discovery is the focus on rare events, which characterize precisely what the solution is looking for. For this purpose, we need to integrate into algorithms the most recent statistical techniques for the study of large multimodal datasets.
</p>
