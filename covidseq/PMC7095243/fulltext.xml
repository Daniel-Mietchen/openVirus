<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?OLF?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">AI Soc</journal-id><journal-id journal-id-type="iso-abbrev">AI Soc</journal-id><journal-title-group><journal-title>Ai &#x00026; Society</journal-title></journal-title-group><issn pub-type="ppub">0951-5666</issn><issn pub-type="epub">1435-5655</issn><publisher><publisher-name>Springer London</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">7095243</article-id><article-id pub-id-type="publisher-id">956</article-id><article-id pub-id-type="doi">10.1007/s00146-020-00956-6</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Big tech and societal sustainability: an ethical framework</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Arogyaswamy</surname><given-names>Bernard</given-names></name><address><email>arogyas@lemoyne.edu</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1">Madden School of Business, LeMoyne College, Syracuse, NY USA </aff></contrib-group><pub-date pub-type="epub"><day>19</day><month>3</month><year>2020</year></pub-date><fpage>1</fpage><lpage>12</lpage><history><date date-type="received"><day>2</day><month>11</month><year>2019</year></date><date date-type="accepted"><day>25</day><month>2</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; Springer-Verlag London Ltd., part of Springer Nature 2020</copyright-statement><license><license-p>This article is made available via the PMC Open Access Subset for unrestricted research re-use and secondary analysis in any form or by any means with acknowledgement of the original source. These permissions are granted for the duration of the World Health Organization (WHO) declaration of COVID-19 as a global pandemic.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Sustainability is typically viewed as consisting of three forces, economic, social, and ecological, in tension with one another. In this paper, we address the dangers posed to societal sustainability. The concern being addressed is the very survival of societies where the rights of individuals, personal and collective freedoms, an independent judiciary and media, and democracy, despite its messiness, are highly valued. We argue that, as a result of various technological innovations, a range of dysfunctional impacts are threatening social and political stability. For instance, robotics and automation are replacing human labor and decision-making in a range of industries; search engines, monetized through advertising, have access to, and track, our interests and preferences; social media, in connecting us to one another often know more about us than we ourselves do, enabling them to profit in ways which may not coincide with our well-being; online retailers have not only acquired the ability to track and predict our buying choices, but also they can squeeze vendors based on their outsize bargaining power; and, in general, virtual technologies have changed both the way we think and our sense of self. With the rising deployment of the Internet of Things, and developments in machine learning and artificial intelligence, the threats to individual freedoms and rights, societal cohesion and harmony, employment and economic well-being, and trust in democracy are being ratcheted up. This paper lauds the benefits and addresses the harm wrought by the high tech giants in Information and Communication Technologies (ICTs). The search for rapidly growing revenues (and shareholder returns and stock prices) drives firms to accelerate product innovation without fully investigating the entire gamut of their impacts. As greater wealth accrues to the leaders of tech firms, inequalities within firms and societies are widening, creating social tensions and political ferment. We explore the ethical nature of the challenge employing a simple utilitarian calculus, complemented by approaches rooted in rights, justice, and the common good. Various options to address the challenges posed by ICTs are considered and evaluated. We argue that regulation may do little more than slow down the damage to society, particularly since societal values and political preferences vary internationally. Firms need to establish ethical standards, imbuing the upholders of these standards with sufficient authority, while creating a culture of morality. User involvement and activism, and shareholders&#x02019; concerns for the sustainability of societies on whose continued prosperity they depend, are imperative to humanity&#x02019;s ability to decide the future direction of technology.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Big tech</kwd><kwd>Ethical criteria</kwd><kwd>Cognition</kwd><kwd>Social impacts</kwd><kwd>Centralized power</kwd><kwd>User activism</kwd></kwd-group></article-meta></front><body><sec id="Sec1"><title>Introduction: &#x0201c;Societal sustainability&#x0201d;</title><p id="Par2">Innovation in products, processes, marketing, and management has been central to the success of firms and nations both in manufacturing and service industries. The technology&#x02013;market linkage has fueled a growth trajectory that companies and countries hope to ride to ever-rising levels of prosperity. There are, to be sure, challenges to be overcome such as ecological and social sustainability. In this paper, we address the dangers posed by the constant drive to innovate (and disrupt) to another dimension of sustainability, that of our institutions, political systems, and of civil society itself, which we term <italic>societal sustainability</italic>. The concern addressed here is the very survival of societies where the rights of individuals, personal and collective freedoms, an independent judiciary and media, and democracy, despite its messiness, are highly valued (Levitsky and Ziblatt <xref ref-type="bibr" rid="CR51">2018</xref>; The Economist <xref ref-type="bibr" rid="CR95">2018</xref>). Robotics and automation are replacing human labor and decision-making in a range of industries; search engines, monetized through advertising, have access to, and track, our interests and preferences; social media, in connecting us to one another often know more about us than we ourselves do, enabling them to profit in ways which may not coincide with our well-being; online retailers have not only acquired the ability to track and predict our buying choices, but also they can squeeze vendors based on their outsize bargaining power; and, in general, digital technologies have changed both the way we think and our sense of self (Rosen <xref ref-type="bibr" rid="CR81">2007</xref>; Prado <xref ref-type="bibr" rid="CR73">2017</xref>).</p><p id="Par3">This paper acknowledges the benefits offered, and addresses the harm wrought, by the high tech giants (&#x02018;big tech&#x02019;) in Information and Communication Technologies (ICTs), and related industries. The search for rapidly growing revenues, shareholder returns and stock prices drives firms to accelerate innovation without fully investigating the entire gamut of their impacts. Additionally, greater wealth accrues to the leaders of big tech, and inequalities within firms and societies widen, creating societal tensions and political ferment (Brynjolfsson and McAfee <xref ref-type="bibr" rid="CR8">2014</xref>; Bridle <xref ref-type="bibr" rid="CR7">2018</xref>). Exploring the ethical nature of the various challenges, and suggesting possible ways in which the threat posed to individuals and institutions might be ameliorated, could be of interest to businesses and educational institutions, particularly ones where the virtues of big data are extolled while the ethical challenges that arise are often ignored or glossed over. In light of the increased scrutiny of big tech, the need to look beyond immediate (mainly financial) benefits, and study the long-term impacts on individuals and societies is also of great relevance now, both for businesses and policy makers.</p></sec><sec id="Sec2"><title>Ethical criteria</title><p id="Par4">The product choices that big tech companies make obviously have great significance to individuals and to society at large, creating ethical issues that need to be confronted. Product-related decisions may have a direct and immediate influence (say, on users in terms of privacy and security) or indirect and future (user data is used to cull information affecting insurance premiums, creditworthiness, and so on). Big tech firms need to consider the impacts on users, particularly the <italic>costs to society</italic> itself, regardless of the profit potential. The need to adopt this broad perspective, encompassing all stakeholders, was acknowledged recently when over 180 CEOs of major firms signed a declaration to this effect (Gelles and Yaffe-Bellamy <xref ref-type="bibr" rid="CR27">2019</xref>). An ethical screen could help evaluate the extent to which individual and collective stakeholder interests are satisfied (Laudon <xref ref-type="bibr" rid="CR49">1995</xref>; Varlan and Tomozei <xref ref-type="bibr" rid="CR98">2018</xref>). Among the approaches which could help in making ethical decisions, as distilled by Capsim (<xref ref-type="bibr" rid="CR10">2018</xref>) and the Markkula Center (<xref ref-type="bibr" rid="CR58">2019</xref>), are those based on <italic>rights</italic>, <italic>justice</italic>, <italic>common good</italic>, <italic>virtue</italic>, and <italic>utilitarianism</italic>. We now briefly develop the principles underlying each of these perspectives with a view to suitably framing the ethical challenges facing big tech.</p><p id="Par5">According to the <italic>rights</italic> approach, people ought to be treated as ends in themselves not as means or instruments to achieve desire results. The dignity of every individual and the freedom to make choices are to be carefully safeguarded. Ethics as <italic>justice</italic> calls for treating everyone fairly by applying a common, unbiased standard. In the <italic>common good</italic> approach, the community is the unit of analysis, and calls for acting in the best interests of society, especially those less able to fend for themselves. The virtue perspective asserts that certain universal values exist such as honesty, compassion, not harming others, integrity, and so on. All actions are evaluated through the prism of these values. <italic>Utilitarianism</italic>, more specifically act utilitarianism (De Lazari-Radek and Singer <xref ref-type="bibr" rid="CR202">2017</xref>), focuses on the consequences of decisions, maximizing the good done while keeping the harm inflicted to a minimum. This standard recognizes that few actions have purely beneficial outcomes, but that the latter should outweigh any ill effects which might arise. In the corporate context, utilitarianism offers a convenient way to evaluate the ethicality of decisions, in part, due to its greater amenability to measurement (Markkula Center <xref ref-type="bibr" rid="CR58">2019</xref>). The assessment of benefits and costs is often conducted with a view to creating greater shareholder value, using a monetary metric. The latter is generally easier to measure, which could lead to devaluing other stakeholders&#x02019; (customers, suppliers, local community) interests, and ignoring intangible costs (Kelman <xref ref-type="bibr" rid="CR42">1981</xref>; Lowry and Peterson <xref ref-type="bibr" rid="CR55">2011</xref>). In this paper, we evaluate the ethics of big tech using the utilitarian approach specifically from the stance of users, suppliers, and society itself. In making the ethical assessments, we fold in the common good, justice, and rights approaches, to complement the utilitarian perspective where applicable.</p><p id="Par6">Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> lays out some of the consequences, that is, benefits and costs (monetary and otherwise) primarily from the viewpoint of users, but, where applicable, also from the perspective of other stakeholders. We discuss some of the issues that arise from this analysis, and will attempt to devise strategies by which social, political, ethical and other challenges may be addressed. Some actions could directly affect users (e.g., privacy violations) with little time lag; while, the consequences of other decisions might be indirect and involve a delay (addictive viewing by children, which could result in less social interaction). The table presents the benefits of developments in the field of big tech, which are divided into two categories: Direct/Present (DP) versus Indirect/Future (IF). For each type of benefit, we identify costs or negative outcomes, which are classified similarly.<table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>Big tech benefits and costs: long term and short term</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Direct/present</th><th align="left">Indirect/future</th></tr></thead><tbody><tr><td align="left" colspan="2"><bold>Benefits</bold></td></tr><tr><td align="left">Access to information; sense of connectedness, social groups, self-esteem; sharing ideas and opinions; online-retailing goods, services, entertainment; lower prices, alternative services; mobile payments; educational applications-retraining, skill upgrades; voice-activated personal home assistants</td><td align="left">Use of data analytics, cloud computing, AI to solve medical, educational, social, transportation problems; ride-sharing, fewer automobiles, less pollution; extension of life span, more leisure, more surpluses due to higher efficiencies; widespread acceptance of high tech developments as being central to human happiness and progress</td></tr><tr><td align="left" colspan="2"><bold>Costs</bold></td></tr><tr><td align="left">Data privacy and security; sale of user data to third parties; shareholder interests prioritized over those of users and society; micro-targeting of user groups; platforms becoming content providers; reduced attention spans and cognitive capabilities; addiction especially in children; impact on employment tasks and equity; power shifts and divisions in society; distrust of media; elitism in, and power of, high tech</td><td align="left">Rising impact on employment and equity; increasing ability of large tech firms and centralized states to surveil, predict, and control behavior; erosion of human rights, privacy, and the intrinsic worth of individuals; diminution and devaluation of the ability to reflect and empathize; threat to democracy: manipulation and distortion of information, and passivity of electorate; rise of data oligarchies and autocratic rulers; geopolitical race to &#x0201c;win&#x0201d; the AI and 5G race potential for less human involvement in future technologies</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec3"><title>Consequences</title><sec id="Sec4"><title>Direct/present benefits</title><p id="Par7">We have mentioned some of the benefits such as increased, accelerated, multimedia access to information earlier. Other DP advantages are the instant access to entertainment anywhere through a host of music and visual streaming sites, games which can involve one or more players, taking photographs which can be sent to friends and family at any time, and so on. Social media not only connect individuals (and groups) but also can result in an extended network of like-minded people who engage with participants in their circle in a variety of ways. One can track down friends and acquaintances from the past, join common-interest groups, buy advertised products, share thoughts and opinions, follow and post replies to assertions made by others, alert one&#x02019;s friends to events and recent developments, catch up with the latest news, and so on. In addition, our devices keep us connected to a much larger and, if we wish, ever-expanding virtual range of friends. We have a variety of activities to occupy us, mitigating feelings of boredom and a sense of being alone, even if it be expressed in the form of a &#x0201c;like&#x0201d; (Prado <xref ref-type="bibr" rid="CR73">2017</xref>). Sharing thoughts and feelings without face-to-face contact could also reduce stress especially when others empathize and share their own experiences. In a sense, eliciting appreciative responses to sharing details of our personal life could also make us feel better about ourselves, enhancing our sense of self-esteem (Kingwell <xref ref-type="bibr" rid="CR44">2017</xref>). In today&#x02019;s &#x0201c;instant&#x0201d; society, not only can we find answers and communicate at the speed of thought, so to speak, but also we can buy anything that catches our fancy online. In addition, the websites themselves suggest items which might appeal to us, based on our previous, and inferred, preferences (Radovan <xref ref-type="bibr" rid="CR75">2013</xref>).</p><p id="Par8">In the case of services such as search, email, social media, navigation, and other apps, the dollar price is perceived as zero, creating an obvious consumer&#x02019;s surplus. The use of the &#x0201c;free&#x0201d; service becomes a &#x02019;no-brainer&#x02019; to the user. Scholars have pointed out, however, that &#x0201c;free&#x0201d; in this context should be taken to mean liberty or freedom to use rather than being related to price (Agar <xref ref-type="bibr" rid="CR2">2019</xref>). The mammoth profits earned by the likes of Facebook, Google, Amazon, Microsoft, and other big tech firms attest to how successfully these firms serve the needs of their clients (&#x0201c;client surplus&#x0201d;), their advertisers. To deliver more value to its clients, big tech needs to gather more and more data about its consumers, enabling it to track and even predict user behavior. The rising efficacy with which ads, news, and messages are delivered to users leads to an upward spiral of both consumer surplus and client surplus, while proving to be ever more lucrative to the firms fueling the &#x02018;data revolution&#x02019; (Greene <xref ref-type="bibr" rid="CR30">2018</xref>).</p></sec><sec id="Sec5"><title>Direct/present costs</title><p id="Par9">The problems arising from the availability of user data are well known. Just as social media can connect one to friends and family, they can also use the data to micro-target individuals for commercial and political purposes. Third parties may gain access to an individual&#x02019;s preferences as well as aggregate these preferences to generalize to an entire segment of users (e.g., senior citizens, women under thirty-five, recently naturalized citizens (Stahl et al. <xref ref-type="bibr" rid="CR90">2017</xref>; Sumpter <xref ref-type="bibr" rid="CR93">2018</xref>). The potential for foreign intervention in elections remains high (Rutenberg <xref ref-type="bibr" rid="CR83">2019</xref>), even if firms try to mitigate the threat (Satariano <xref ref-type="bibr" rid="CR85">2019</xref>). Search engines&#x02019; algorithms typically store results of previous searches, which can not only be a convenience, but can also be viewed as an intrusion into one&#x02019;s right to privacy. Users have apparently made a sort of Faustian bargain in which they share their data and identities in order to gain access to providers&#x02019; services. As Finnemore (<xref ref-type="bibr" rid="CR20">2018</xref>) notes, users are the crop harvested by big tech. The reluctance on the part of these mammoth corporations to be transparent or openly share what actions they undertake behind the scenes is what brings the issue of ethics into the picture (Jasanoff <xref ref-type="bibr" rid="CR41">2016</xref>). Of late, some of the big tech firms have issued statements assuring users that they are committed to maintaining the privacy of user data. However, critics argue that when it comes to a question of user privacy versus advertising revenues, firms are likely to dilute the privacy criterion (Mack <xref ref-type="bibr" rid="CR57">2014</xref>; Pichai <xref ref-type="bibr" rid="CR70">2019</xref>; Tufekci <xref ref-type="bibr" rid="CR97">2019</xref>; Wakabayashi and Chen <xref ref-type="bibr" rid="CR100">2019</xref>).</p><p id="Par10">Some writers have argued that, as in a production/service economy, economies of scale and scope are critical in a digital world as well. The only difference is that, rather than applying to volume and variety of output, the economies now apply to the extraction, analysis, application, and monitoring of data with a view to modifying, predicting and even controlling behavior. If D<sub>A</sub> is the amount of data needed to provide users with the value needed to retain their attention and loyalty, any additional data (say D<sub>B</sub>) extracted helps increase producer surplus now and into the future. The &#x0201c;behavioral surplus&#x0201d; D<sub>B</sub> serves to align user behavior with big tech and their clients&#x02019; needs (Zuboff <xref ref-type="bibr" rid="CR109">2019</xref>a). Innovation in the digital economy contributes to rising (perceived) consumer surplus, greater client surplus (effectiveness of advertisements), and, above all, scale economies in data extraction and use. Leveraging data among a firm&#x02019;s various products (present and potential) generates scope economies [e.g., using the same data to deliver targeted ads and to determine creditworthiness for a loan (Zuboff <xref ref-type="bibr" rid="CR109">2019</xref>b)].</p><sec id="Sec6"><title>Impact on cognition and attention; children as targets</title><p id="Par11">While much of the concern over the accelerating use and influence of the &#x0201c;gig economy&#x0201d; has been directed to issues such as data privacy and security (and rightly so, as noted earlier), there are other, potentially harmful, consequences which merit a closer look. Take, for instance, the extent to which many people have become dependent on digital sources for information, social interaction, lifestyle choices (where to live, whom to date, how to care for an infant), and so on. Such an abiding trust in, and reliance on, digital technology verges on addiction and could significantly alter our cognitive processes, our social skills, and even our emotional wellbeing (Kingwell <xref ref-type="bibr" rid="CR44">2017</xref>; McFarlane <xref ref-type="bibr" rid="CR60">2017</xref>). Sagan (<xref ref-type="bibr" rid="CR84">1974</xref>), Harari (<xref ref-type="bibr" rid="CR32">2011</xref>, <xref ref-type="bibr" rid="CR33">2018</xref>), and other scholars have theorized that homo sapiens, while in the hunter-gatherer stage, developed differently from other species by cultivating the ability to observe, reason, and remember, and to share information about food sources, weather patterns, geographic features, and so on. This &#x0201c;cognitive revolution&#x0201d;, it has been argued, was the point at which humankind diverged developmentally from all other species. As Carr (<xref ref-type="bibr" rid="CR11">2008</xref>) observes, we may be surrendering one of the defining characteristics which makes us human for the convenience of having technology (our creations and tools) assumes an increasing part of the process of cognition. There are early indications that attention spans are shortening, information is increasingly being sought for vicarious ends (e.g., following celebrity lifestyles, pornography, etc.), and we are losing the ability to treat technology as an extension of ourselves, and are becoming dependent on our creations (Prensky <xref ref-type="bibr" rid="CR74">2001</xref>; Kingwell <xref ref-type="bibr" rid="CR44">2017</xref>). Milner (<xref ref-type="bibr" rid="CR63">2016</xref>) provides several instances of the latter in regard to the use of GPS. He cites numerous instances of people blindly following instructions provided by their GPS app even when they knew it was leading them astray, sometimes with fatal consequences. The author argues we are undoing the neural connections that enabled our ancestors to reason along spatial and temporal dimensions. In a sense, human society is fast developing into a &#x0201c;technopoly&#x0201d; (Postman <xref ref-type="bibr" rid="CR72">1993</xref>)&#x02014;a society whose culture is shaped by technology rather than values. One technological development leads to another in a seemingly inexorable progression of new services to which most of us are drawn since they offer ever more convenience and gratification at little or no cost (Walsh <xref ref-type="bibr" rid="CR206">2018</xref>).</p><p id="Par12">An even more serious threat to society is that children are being targeted apparently as part of a plan to create a loyal base for the websites concerned for extended periods. While some children&#x02019;s programming may indeed inform and educate, the purpose of the underlying algorithms is to hold the user for as long a stretch of time as possible (Lafrance <xref ref-type="bibr" rid="CR47">2017</xref>). Apple, after soliciting apps to limit time spent on a device, has now taken over the task itself, no doubt realizing the lucrative and data-rich nature of the task. The company is also under fire for allegedly favoring its own apps over those of outside developers (de Looper <xref ref-type="bibr" rid="CR15">2019</xref>; Nicas <xref ref-type="bibr" rid="CR67">2019</xref>). You-tube operates a highly lucrative children&#x02019;s site but stands accused of creating techniques to foster addictive viewing and even of installing inadequate safeguards against switching over to adult programming (Bridle <xref ref-type="bibr" rid="CR7">2018</xref>). Fears have been expressed about the effect that long-term use of the internet, social media, digital assistants, and other accoutrements of digital technology might have on children&#x02019;s and adolescents&#x02019; behavior. The observed behaviors and effects include cyberbullying, depression, and sleep deprivation (Child Mind Institute <xref ref-type="bibr" rid="CR13">2017</xref>).</p></sec><sec id="Sec7"><title>Social influence</title><p id="Par13">The social impacts of ICTs are almost as deep and worrisome as the effects on cognition (Ross <xref ref-type="bibr" rid="CR82">2011</xref>). It is difficult to deny that social media (Facebook, Twitter, You-tube, and others) have, beside connecting us with others and enabling us to express our opinions, created a high degree of self-absorption and a craving for recognition (Rosen <xref ref-type="bibr" rid="CR81">2007</xref>). The resulting focus on oneself borders on narcissism, and has affected the ability of many people to interact in a healthy way with others at school, work, home, as well as in religious and civic organizations. In fact, the amount of time spent online not only means we have less time to spend with others, but also it could be changing the ways in which our brains are wired. In addition, linguistic abilities, the powers of reflection and introspection, and attentiveness to the task at hand may be adversely affected. Other, more obvious, problems include the ease with which hate speech and harmful content can be spread, and the extent to which bullying and divisiveness have entered common discourse (Ives <xref ref-type="bibr" rid="CR40">2019</xref>). Sites such as Facebook and You-tube are trying to monitor and control the posting of harmful content but it may be an uphill task given the need to track an ever-increasing number of participants who follow recommendations, pay for premium services, and buy sponsored products (Alba et al. <xref ref-type="bibr" rid="CR3">2019</xref>). In addition, the fact that &#x0201c;platforms&#x0201d; cannot, by law, be held responsible for content uploaded to their sites works in big tech&#x02019;s favor (Wakabayashi and Chen <xref ref-type="bibr" rid="CR100">2019</xref>). While pro-democracy movements such as the Arab Spring were partly fueled by social media, the latter have also enabled the spread of misinformation, rumors, and dangerous ideas. In Myanmar, Sri Lanka, New Zealand, and other countries, Facebook, Twitter, and Google were seen as spreading extremist and violent content (Wilson <xref ref-type="bibr" rid="CR105">2019</xref>; Mozur <xref ref-type="bibr" rid="CR65">2018</xref>). Big tech is also routinely used by governments to disseminate information aimed at stifling dissent (Kingsley <xref ref-type="bibr" rid="CR43">2019</xref>; Rezaian <xref ref-type="bibr" rid="CR79">2019</xref>). It is, indeed, chilling to read that India&#x02019;s democracy is being subverted using modern technology, in part, by shutting down access to the internet or cell phone communication more frequently than any other nation (Human Rights Watch <xref ref-type="bibr" rid="CR37">2016</xref>). Clearly, while many of big tech&#x02019;s innovations have been beneficial, they have also been subject to &#x02018;weaponization&#x02019; (Swisher <xref ref-type="bibr" rid="CR204">2019</xref>) by states, corporations, and other actors.</p><p id="Par14">Social services, such as administering the food stamp program, are already being outsourced to big tech, with the express purpose of making them more efficient which typically results in reducing or denying services (Eubanks <xref ref-type="bibr" rid="CR301">2019</xref>). Policing and crime reduction through the use of facial recognition software are also well advanced and, despite their flaws, biases, and obvious threats to privacy, are being extensively implemented&#x02014;and not just in authoritarian societies (Metz and Singer <xref ref-type="bibr" rid="CR62">2019</xref>; Newman <xref ref-type="bibr" rid="CR66">2019</xref>). Clearly, the <italic>rights</italic> of individuals are being jeopardized, often and ironically, under the guise of protecting free speech. It is also obvious that the common good is being sacrificed on the altar of efficiency, profits, and shareholder wealth (Chakhoyan <xref ref-type="bibr" rid="CR12">2018</xref>).</p></sec><sec id="Sec8"><title>Technology, power, and government</title><p id="Par15">As a result of their ability to tackle the provision of all sorts of services often at little or no obvious cost to customers, tech firms are viewed by many as being uniquely capable of accomplishing any task they undertake. Though few leaders of big tech would argue that governments are superfluous, their actions are directed to exercising greater influence over governments. For instance, lobbying and efforts to influence legislation have expanded over the past 10 years, rivalling those of more &#x0201c;traditional&#x0201d; industries such as energy and finance (Dellinger <xref ref-type="bibr" rid="CR17">2019</xref>). The fact that the U.S. federal government has little investment in the development of AI further increases its dependence on big tech (Webb <xref ref-type="bibr" rid="CR101">2019</xref>).</p><p id="Par16">With an increasing part of the population, in many countries, getting their news from search engines and social media, the role of print, television, and other journalism has declined precipitously. This &#x0201c;squeezing out&#x0201d; of journalism has also meant that the ethics of the field are being loosened. No longer do sources have to be vetted and corroboration sought, or opinion separated from fact, which can harm individuals&#x02019; rights and imperil the common good. Indeed, the Fifth Estate, as Greene (<xref ref-type="bibr" rid="CR30">2018</xref>) terms big tech, by displacing traditional media, is undermining civil society. It appears that the influence of, and potential for, misinformation and the sowing of chaos in politics, are likely to keep rising (Rutenberg <xref ref-type="bibr" rid="CR83">2019</xref>). For instance, Facebook appears to have thrown in the towel where curating of user uploaded news is concerned (Boyle <xref ref-type="bibr" rid="CR6">2019</xref>).</p><p id="Par17">It is clear that big tech firms view themselves collectively as laying a legitimate claim to being good for society by efficiently serving a variety of users&#x02019; needs in an expanding range of industries. At this point, it appears that big tech is not only too big to fail but also too big to regulate. The heads of the largest tech companies have been referred to as tech oligarchs (Greene <xref ref-type="bibr" rid="CR30">2018</xref>), whose ambition is not merely to disrupt one industry after another but to change the world to accord with their mental models. It is paradoxical that technologies such as the internet, personal computer, and smart phone, which ostensibly enable greater decentralization, have now resulted in a higher concentration of power especially where mammoth firms like Google, Facebook, Amazon, Microsoft, and Apple are concerned, or in the hands of authoritarian governments. Centralization of power has meant that we may be players in a new kind of economy, one that some authors have termed surveillance capitalism (Zuboff <xref ref-type="bibr" rid="CR109">2019</xref>; Webb <xref ref-type="bibr" rid="CR101">2019</xref>) or a surveillance state (Pinker <xref ref-type="bibr" rid="CR71">2019</xref>). The sense of omnipotence that pervades the digital giants is such that they are now engaged in grandiose pursuits such as settling on other planets (where, presumably, they would make up the rules, not live by someone else&#x02019;s), extending life indefinitely and perhaps achieving immortality, eliminating poverty, and so on. In the tech oligarch&#x02019;s world, technology can solve any problem (Greene <xref ref-type="bibr" rid="CR30">2018</xref>).</p><p id="Par18">Technology is, by its very nature, a political and cultural phenomenon (Winner <xref ref-type="bibr" rid="CR106">1986</xref>; Jasanoff <xref ref-type="bibr" rid="CR41">2016</xref>). For instance, the construction of certain highways with low overhead clearances in Long Island was meant to prevent low income individuals from living in those neighborhoods. The proliferation of multi-storied apartments and offices in cities creates a divide between urban residents and nature, the diffusion of the automobile resulted in a migration to the suburbs, television and the computer have tended to curb social interaction, and so on. With the passage of time and the increased emphasis on predictive data analytics combined with machine learning, <italic>real</italic> power has been rapidly accrued by big tech (Nicas et al. <xref ref-type="bibr" rid="CR68">2019</xref>), while <italic>apparent</italic> power still resides with the individual.</p><p id="Par19">While on the subject of individual rights, one cannot ignore the issue of employment. In the tech industries themselves, firms try to minimize the head count of permanent employees to the extent feasible. About half of Google&#x02019;s work force consists of contractors, vendors, and temps (&#x0201c;CVTs&#x0201d;), Uber treats its drivers as contract workers, and Facebook and You-tube have hired thousands of temps to review and screen uploads, thus taking us back almost to pre-union times when employees at lower income levels had little to no rights (Sheng <xref ref-type="bibr" rid="CR87">2018</xref>; Wong <xref ref-type="bibr" rid="CR107">2019</xref>). In their aggressive, male-dominated working environments, high tech firms have tended to tended to devalue women, particularly at firms&#x02019; higher echelons, much in the way that financial services firms have (Rangarajan <xref ref-type="bibr" rid="CR77">2018</xref>; Business Insider <xref ref-type="bibr" rid="CR9">2019</xref>). The relative lack of diversity stems from educational systems and corporate practices which give rise to &#x02018;tribes&#x02019; (Webb <xref ref-type="bibr" rid="CR101">2019</xref>), possessing a homogeneity in cognition and values.</p></sec></sec><sec id="Sec9"><title>Future benefits</title><p id="Par20">We have thus far reviewed some of the more immediate positive and negative outcomes (left half of Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>) from the deployment and widespread diffusion of digital technologies. Our attention now turns to the more enduring benefits and costs, some of which have already begun to manifest themselves, associated with high tech (shown on the upper right half of Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Brynjolfsson and McAfee (<xref ref-type="bibr" rid="CR8">2014</xref>) observe that Information and Communication Technologies (ICTs) are so-called general purpose technologies (GPTs) which serve as a base or platform for the development or advancement of other technologies. Nearly, every product or service we use has some form of ICT embedded in it. With the advent of the internet of things (IoTs), such smart devices have become ubiquitous (Husain <xref ref-type="bibr" rid="CR38">2017</xref>; The Economist <xref ref-type="bibr" rid="CR96">2019</xref>). Cars, homes and home appliances, stores, airplanes, luggage, electric grids, and much more, have been fitted with sensors to increase our ability to control them to our ends. This can be achieved by touch, voice, with a gesture, or, potentially, even with the blink of an eye. The use of ICTs in industry has helped increase efficiencies in production and service firms alike (Kvochko <xref ref-type="bibr" rid="CR46">2013</xref>), making goods (customized, if needed) available at competitive prices, and enhanced convenience at work and in leisure activities (Deb <xref ref-type="bibr" rid="CR16">2014</xref>). The automation of routine and low/middle-skill tasks is another dimension of AI which is likely to help in mitigating the boredom and tedium associated with many manufacturing and service jobs in particular.</p><p id="Par21">Perhaps, the most prominent development in the field is that of artificial intelligence (AI). Though the field of AI has developed in spurts, tending to ebb and flow over time (Lee <xref ref-type="bibr" rid="CR50">2018</xref>), it seems to have gathered a head of steam recently, and is likely to play an prominent part in our lives (Lee <xref ref-type="bibr" rid="CR50">2018</xref>; Webb <xref ref-type="bibr" rid="CR101">2019</xref>).Based on increasingly deep neural networks which introduce layers of data analysis capabilities, AI could be of the supervised or reinforcement varieties (Walsh <xref ref-type="bibr" rid="CR206">2018</xref>; Anderson <xref ref-type="bibr" rid="CR4">2019</xref>; Ramakrishnan <xref ref-type="bibr" rid="CR76">2019</xref>). In the former, the starting point is an algorithm to sort data and guide the analysis, with refinements being made in the process based on comparing predictions against actual outcomes. For instance, in predicting stock prices or the occurrence of a medical condition, if, based on a data set of tens of thousands of observations, predictions vary from reality, corrections are made autonomously, and applied to the next batch of data, and so on, until a close enough match between reality and predictions is achieved. In the case of reinforcement learning, no initial algorithm guides the analytic process, which depends on the machine learning from reams of past data and outcomes to predict outcomes from present data sets, and improving predictive capability in an evolutionary manner (Webb <xref ref-type="bibr" rid="CR101">2019</xref>). This kind of artificial narrow intelligence (ANI) is being used in stock selection, facial recognition, neighborhood surveillance to anticipate criminal activity, supporting medical diagnosis, identifying candidates for gene therapy, and so on (Adams <xref ref-type="bibr" rid="CR1">2017</xref>). Robots, which have been programmed to carry out specified tasks based on voice commands, are now being equipped with machine learning capabilities, so they can respond, based on reinforcement learning (their own as well of others in their cohort) to unanticipated requests. Self-driven cars are another ANI development which may be on the verge of introduction on an experimental scale. Ride-sharing is expected to increase, resulting in fewer cars on the road, and sharply reduced carbon emissions. The number of electric car models under development by the major automobile companies is an indicator of the likelihood of autonomous vehicles hitting the market, since electric cars are more amenable to being self-driven than traditional fossil-fuel-powered ones (Gardner <xref ref-type="bibr" rid="CR25">2016</xref>; Edwards <xref ref-type="bibr" rid="CR19">2019</xref>).</p></sec><sec id="Sec10"><title>Potential negative outcomes</title><p id="Par22">One of the likely immediate outcomes of automation, as with the development of efficiency-enhancing techniques in the past, is the possibility of rising unemployment. While this has been an ongoing feature of technological change historically, one can now envision as part of the &#x0201c;age of accelerations&#x0201d; (Friedman <xref ref-type="bibr" rid="CR24">2016</xref>) that up to 40% of existing low- and medium-skill jobs in manufacturing and service occupations will, by 2030, be performed by machines with minimal human intervention. Not only does this bode ill for present-day types of jobs, as a McKinsey (McKinsey Global Institute <xref ref-type="bibr" rid="CR61">2017</xref>) study notes, but it could mean that the jobs likely to be created in the coming years (which would normally be performed by humans) will also be taken over by sentient machines. Actions such as job-retraining undertaken by governments, fostering of entrepreneurship, and an increase in the supply of highly skilled workers may have minimal impact (Arogyaswamy and Hunter <xref ref-type="bibr" rid="CR5">2019</xref>). It has been noted by some experts that new technologies often result in the elimination of certain types of occupations, while creating a variety of new ones (White <xref ref-type="bibr" rid="CR104">2011</xref>; Gordon <xref ref-type="bibr" rid="CR29">2016</xref>). There is considerable evidence, however, that the new jobs created in the robotics/automation/AI revolution may be of the low-skilled, poorly paid kind, creating extensive underemployment. Current and emerging ICTs, are poised to transform societies in ways we have not hitherto experienced (Hirst <xref ref-type="bibr" rid="CR36">2014</xref>; Stettner <xref ref-type="bibr" rid="CR91">2018</xref>). The process might unwind over a few decades, but the writing is on the wall. If the tech oligarchs do not act in a manner respectful of social values and norms (e.g., paying their share of taxes, investing in worker retraining, accepting that they are not supra-societal entities), social and political instability could be the outcome. Civil society and democracy may prove to be unsustainable (Collier <xref ref-type="bibr" rid="CR14">2015</xref>; Ma <xref ref-type="bibr" rid="CR56">2018</xref>; Lanchester <xref ref-type="bibr" rid="CR48">2019</xref>).</p><p id="Par23">While the impact on employment could well be economically damaging, AI built on 5G networks could change other aspects of life for the worse in the United States, China, and other countries to which this technology is transferred. There are serious concerns about the efficacy and reliability of machine learning. One of the pitfalls is that many problems are more complex than can be addressed by statistical analysis (Pearl <xref ref-type="bibr" rid="CR69">2019</xref>). Not only are the numbers of variables extracted from the data likely to be dauntingly large, it might also be difficult to attach a conceptual meaning to each of the variables identified. Even more relevant, if the list of variables changes over time, the predictive power of machine learning could become even less effective. An equally valid criticism is that systems would remain opaque in regard to the process by which predictions are made. A total dependence on statistical machine learning would make it impossible to explain why decisions are made and, even more serious, for human actors to exercise rational or moral discretion. Agar (<xref ref-type="bibr" rid="CR2">2019</xref>) observes that following this path would create a new feudalism with users of Google and Facebook constituting the peasant farmers in an emerging cyberland. Ethically, the increase in the number and scope of interactive technologies raises the issue of how we should deal with distributed moralities (Floridi <xref ref-type="bibr" rid="CR21">2013</xref>). For instance, in attacking military targets with possible civilian casualties or in denying social services to certain individuals, the human&#x02013;machine interaction could result in machines making decisions involving moral choices, even if it is done unwittingly. Similar moral choices might confront physicians whose diagnoses differ from those of machines, and, in fact, in any area where empathy, compassion, and morality are involved. That is, in a machine-learning world, human actors may not be the only ones involved in making ethical decisions.</p><p id="Par24">Combining the added heightened threats to employment, privacy, security, decentralization of power, the exercise of individual and group cognitive capabilities, and the potential sidelining of human rationality and morality, it would appear that, unless action is undertaken in the immediate future, societies worldwide will face transformative, destabilizing change.</p></sec></sec><sec id="Sec11"><title>Options to consider</title><sec id="Sec12"><title>&#x0201c;Self-regulation&#x0201d;</title><p id="Par25">As the number of uploads to social media and search websites proliferates, and new products are introduced at an accelerated pace, keeping pace with the millions of new items appearing every day could become an insuperable task (Satariano <xref ref-type="bibr" rid="CR85">2019</xref>). The use of AI to monitor content may not lead to much improvement either, given how minor variations in input could throw an AI system off track (Condliffe <xref ref-type="bibr" rid="CR201">2019</xref> Employees of firms such as Google, Microsoft, and Amazon have occasionally attempted to influence corporate strategy (Dubal <xref ref-type="bibr" rid="CR18">2019</xref>), but not always effectively. Given the big tech culture of rapid and disruptive product introduction regardless of likely consequences, the belief in their own infallibility, and the lack of diverse, possibly dissenting voices from within, (which Heisler (<xref ref-type="bibr" rid="CR35">2018</xref>) views as one of the biggest risks to the continued success of big tech), organic moderation may be a chimera.). Self-regulation, therefore, can have initial and limited effectiveness, but can quickly be overcome by the sheer magnitude of screening required, the demands of shareholders for growth and profits, acquiescent corporate cultures, and sheer hubris.</p><p id="Par26">To deal more effectively with the top challenges confronting big tech such as balancing the risks and rewards of AI, data governance and security/privacy, and a decrease in public trust (Forbes Technical Council <xref ref-type="bibr" rid="CR23">2018</xref>), some companies are taking long-overdue steps such as the appointment of a Chief Ethics Officer (Swisher <xref ref-type="bibr" rid="CR94">2018</xref>), adopting a code of ethics (West <xref ref-type="bibr" rid="CR102">2018</xref>), and teaching high tech ethics (Singer <xref ref-type="bibr" rid="CR88">2018</xref>). The fact that over 30% of executives out of 1400 surveyed ranked ethics as one of their top concerns regarding AI (Forbes Insights <xref ref-type="bibr" rid="CR22">2019</xref>) speaks to the concerns arising from the expanding reach of big tech.</p><p id="Par27">When confronted with evidence of the harm wrought by their innovations, big tech firms often respond that the consequences were &#x02018;unintended&#x02019;. As (Jasanoff <xref ref-type="bibr" rid="CR41">2016</xref>) notes, firms typically evaluate the gains primarily to shareholders and secondarily to other stakeholders. The possible negative ramifications of their decisions are generally not investigated, given short shrift, or, worse viewed as beneficial to the firm even if the outcomes are likely to be harmful to specific constituents or society as a whole. Some researchers posit that, as technology becomes an increasingly dominant part of culture, the line between intended and unintended consequences tends to get blurred (Webb <xref ref-type="bibr" rid="CR101">2019</xref>). Consequences, even if unintended, are not necessarily unforeseeable. Firms focused on desirable and profitable outcomes alone, while failing to anticipate or ignoring undesirable, less profitable ones, are ill-equipped to regulate themselves (Vogelberg <xref ref-type="bibr" rid="CR205">2018</xref>).</p></sec><sec id="Sec13"><title>Regulation</title><p id="Par28">One of the policy proposals which has gained ground recently both in the EU and the US is regulation of big tech. For instance, the General Data Protection Regulation, or GDPR (<xref ref-type="bibr" rid="CR26">2018</xref>), adopted by the European Union (EU) is an attempt to ensure privacy of user data. Though its interpretation and enforcement could create complex challenges, it might be a precursor of more regulations to follow in the EU as well as in the United States. It needs to be noted, however, that numerous hurdles exist to regulating tech businesses which are constantly mutating. Foremost among these is the issue of how to regulate products which do not yet exist, and whose revenue-earning method cannot be anticipated. An often-mooted suggestion is that the bigger tech firms should be broken up as were oil and railroad firms at the turn of the twentieth century, and AT&#x00026;T in the 1970s (Lohr <xref ref-type="bibr" rid="CR53">2019a</xref>). While the concept might be an appealing one from the anti-trust perspective, the difference here is that the tech giants have diversified considerably and the principle adopted to split them up could create even more problems (Morozov <xref ref-type="bibr" rid="CR64">2019</xref>). For instance, separating Google Search from You-tube, and both from Android could render each of these entities far less effective in meeting users&#x02019; needs. Given Google&#x02019;s adoption of &#x0201c;free&#x0201d; services (advertising being the prime source of revenue), the costs to users could well rise, particularly since the synergies from sharing resources and information across platforms could be diminished. The interconnections among many of these firms&#x02019; products make it difficult to decide where one product (e.g., Messenger) ends and another (e.g. WhatsApp) begins (Stahl et al. <xref ref-type="bibr" rid="CR90">2017</xref>). Legal battles are likely to ensue if a breakup were proposed (Isaac <xref ref-type="bibr" rid="CR39">2019</xref>). Also, since Chinese firms, with the backing of their government, are engaged in a concerted effort to stake out a leadership position in the technologies of the future, it might not be seen as prudent to hobble big tech in the US and EU relative to foreign rivals, while possibly also reducing the level of service to users in these countries. In fact, American big tech firms often cite the national interest in arguing that they should not be tightly regulated (Roose <xref ref-type="bibr" rid="CR80">2019</xref>).</p><p id="Par29">However, perhaps due to the rising dismay over the perceived indifference of big tech to the social, political, economic, and technological forces it has unleashed, the Justice Department, some state governments, and Congress have embarked on investigations, and lawsuits have also been filed (Smith <xref ref-type="bibr" rid="CR89">2019</xref>). The charges against major ICT firms center around their dominance in digital advertising and whether this violates anti-trust legislation. Though limited in scope (privacy, security, and social and political impacts are not specifically included), the very fact that regulation is under consideration in the U.S. [even if the efficacy of the process is in some doubt (McCabe <xref ref-type="bibr" rid="CR59">2019</xref>)], has cast a shadow over the immediate future of the largest ICT businesses (Levy <xref ref-type="bibr" rid="CR52">2019</xref>). While some CEOs of tech giants have welcomed regulation, partly due to the likelihood of barriers to entry being raised, and also because users typically sign off on any new conditions added to terms of service, the uncertainty over the direction of pending inquiries is a source of mounting concern (Wharton <xref ref-type="bibr" rid="CR103">2019</xref>). By building bridges to, and partnering with, governments worldwide, while anticipating and guarding against potential problems, big tech could (as Microsoft appears to have done) conform to societal norms and enhance shareholder value (Lohr (<xref ref-type="bibr" rid="CR54">2019b</xref>); Ratnesar <xref ref-type="bibr" rid="CR78">2019</xref>).</p><p id="Par30">From around the early 1970s, maximizing shareholder value has been the single most important force driving corporate strategies for publicly owned businesses, and digital technology firms have focused predominantly on this criterion of performance. Big tech stock prices and market values have soared since the early 2000s, and have contributed significantly to a long-running bull market, before the outbreak of the Covid-19 pandemic. It appears that the apparently irresistible rise in the values of big tech shares has declined somewhat (Kramer <xref ref-type="bibr" rid="CR45">2019</xref>). Increased monitoring by governments and activists, critical media coverage, concerns over accelerating automation, threats to privacy and security, the long-term impact of screen addiction on children, and so forth, might well be playing a part in investors&#x02019; uncertainty over the future of major tech firms (Wursthorn <xref ref-type="bibr" rid="CR108">2019</xref>). Adding to shareholder anxiety concerning the prospects for firms like Apple, Google, Amazon, and Facebook, is the appointment by the E.U. of a &#x0201c;Digital Czar&#x0201d; who has vowed to expand investigations to include data appropriation and misuse, influence in elections, destabilization of society, and a whole panoply of other practices (Stevis-Gridneff <xref ref-type="bibr" rid="CR92">2019</xref>). Shareholders&#x02019; concerns over the threats facing big tech might well convince these firms to review the ethical problems associated with their actions.</p></sec><sec id="Sec14"><title>User involvement and activism</title><p id="Par31">The satisfaction of users&#x02019; needs while guaranteeing that their rights are not violated is best done by users themselves. Granted, users are fragmented in their expectations and often unclear about their rights. However, if the bulk of the user population remains indifferent to the kind of slippery slope individuals and societies are on now, no amount of regulation or &#x0201c;self-regulation&#x0201d; can be effective. Whether it is achieved through activism, concerted action by NGOs, or through consumer boycotts, or adverse publicity, users need to ensure that the aggregated, hidden, and lasting harm done to individuals and to society is mitigated to the extent possible. As behavioral economics suggests, we might be willing to accept and discount future losses, however heavy they might be, to experience immediate gratification (Hardisty et al. <xref ref-type="bibr" rid="CR34">2012</xref>). Awareness of the perils of technologies which not only have multiple impacts but also are hydra-headed has to start from the toddler stage which is when many parents introduce their offspring to electronic entertainment and communication. For those who have become addicted to high tech services, weaning them off such behavior is far more challenging. Digital addiction afflicts millions of people and may require treatment as a psychological condition, requiring the type of attention given to alcoholism or drug addiction (Glatter <xref ref-type="bibr" rid="CR28">2018</xref>; Gregory <xref ref-type="bibr" rid="CR31">2018</xref>). Privacy violations, security breaches, and posting of false and harmful information also need user (bottom-up) action to complement voluntary corporate and regulatory efforts. The role played by activists such as Lady Kidron in galvanizing public opinion (Singer <xref ref-type="bibr" rid="CR203">2019</xref>) to restrain the power of social media particularly where children are concerned is an instance of the type of action needed. To achieve any traction in the effort to restrain the overweening ambitions of, and the looming risks associated with, big tech, activism of this sort has to snowball, first, to create awareness, and then, to mobilize for action.</p></sec></sec><sec id="Sec15"><title>Conclusion</title><p id="Par32">The ability to store, analyze, and act based on immense quantities of data combined with the advances in machine learning, presents us with unprecedented opportunities to strive for the betterment of humanity in many ways. Artificial intelligence (AI) based on ever-deeper neural networks has the capability to transform medical care, revolutionize transportation, enhance security using sensory recognition, provide customized education, and so on. Its impact on the world economy alone could amount to an astounding $17 billion or more. While initially dependent on human inputs and algorithms, deep learning could lead to machines which teach themselves based on the data which they are fed. As the scale and scope of artificial narrow intelligence proliferate apace, we may, in a few decades reach the Singularity of Artificial General Intelligence, and Superintelligence&#x02014;a stage at which we may have little control over goals or decision-making, and even if we did, would hesitate to second guess our creations. We may, however, be nearing a&#x02019; pre-singularity&#x02019;, the point at which decisions on how much control to cede and what moral limits need to be in place, are taken out of our hands. As IoTs and AI become integral to our everyday lives, our powerlessness relative to big tech and authoritarian governments may become irreversible. It is imperative we reflect fully on the extent to which we are vesting our technologies with power over our lives both now (addiction, impacts on cognition, the welfare of children, etc.) and into the future. The immediate benefits should not blind us to the extent to which individual rights, social justice, and the common good are likely to be harmed. Complicating the assessment of the societal ramifications of technology in the long run is that the AI/5G race between the big tech firms in the United States and China is one in which neither side is likely to pause lest the other gain an immediate advantage. The fact that China&#x02019;s big tech firms (Baidu, Alibaba, and Tencent are the most prominent) are viewed as arms of the state, adds a tinge of nationalism to the urgency with which AI is being developed. The impact on the world of the 5G/AI revolution could well be as significant as the start of the nuclear age. In addition to regulation, the use of an ethical calculus, and safeguarding users&#x02019; and other stakeholders&#x02019; interests, corporate and national leaders need to negotiate and set boundaries for how AI will be used (Scharre <xref ref-type="bibr" rid="CR86">2019</xref>), rather than engaging in a race to gain the most financially, militarily, and politically.</p></sec></body><back><fn-group><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ref-list id="Bib1"><title>References</title><ref id="CR1"><mixed-citation publication-type="other">Adams R (2017) 10 Powerful Examples of Artificial Intelligence in use today. <ext-link ext-link-type="uri" xlink:href="https://www.forbes.com/sites/robertadams/2017/01/10/10-powerful-examples-of-artificial-intelligence-in-use-today/#6c96aae4420d">https://www.forbes.com/sites/robertadams/2017/01/10/10-powerful-examples-of-artificial-intelligence-in-use-today/#6c96aae4420d</ext-link></mixed-citation></ref><ref id="CR2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Agar</surname><given-names>N</given-names></name></person-group><source>How to be human in a digital economy</source><year>2019</year><publisher-loc>Cambridge</publisher-loc><publisher-name>The MIT Press</publisher-name><fpage>66</fpage><lpage>68</lpage></element-citation></ref><ref id="CR3"><mixed-citation publication-type="other">Alba D, Edmondson C, Isaac M (2019) Facebook takes steps to Combat extremism. The New York Times, pp. B1,4</mixed-citation></ref><ref id="CR4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>C</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Brockman</surname><given-names>J</given-names></name></person-group><article-title>Gradient ascent</article-title><source>Possible minds: 25 ways of looking at AI</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>Penguin</publisher-name></element-citation></ref><ref id="CR5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arogyaswamy</surname><given-names>B</given-names></name><name><surname>Hunter</surname><given-names>J</given-names></name></person-group><article-title>The impact of technology and globalization on employment and equity: an organizing framework for action</article-title><source>Int J Glob Sustain</source><year>2019</year><volume>3</volume><issue>1</issue><fpage>55</fpage><lpage>57</lpage></element-citation></ref><ref id="CR6"><mixed-citation publication-type="other">Boyle B (2019) Facebook just gave up the fight against fake news. Los Angeles Times</mixed-citation></ref><ref id="CR7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bridle</surname><given-names>J</given-names></name></person-group><source>New dark age: technology and the end of the future</source><year>2018</year><publisher-loc>London</publisher-loc><publisher-name>Verso</publisher-name><fpage>215</fpage><lpage>230</lpage></element-citation></ref><ref id="CR8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brynjolfsson</surname><given-names>E</given-names></name><name><surname>Mcfee</surname><given-names>A</given-names></name></person-group><source>The second machine age: work, progress, and prosperity in a time of brilliant technologies</source><year>2014</year><publisher-loc>New York</publisher-loc><publisher-name>W. W. Norton</publisher-name></element-citation></ref><ref id="CR9"><mixed-citation publication-type="other">Business Insider (2019) Google reportedly has a massive culture problem that&#x02019;s destroying it from the inside. <ext-link ext-link-type="uri" xlink:href="https://www.businessinsider.com/google-culture-problems-eric-schmidt-aberrant-geniuses-2019-8">https://www.businessinsider.com/google-culture-problems-eric-schmidt-aberrant-geniuses-2019-8</ext-link></mixed-citation></ref><ref id="CR10"><mixed-citation publication-type="other">Capsim (2018) Five ways to Shape Ethical Decisions. <ext-link ext-link-type="uri" xlink:href="https://www.capsim.com/blog/category/soft-skills/ethics/">https://www.capsim.com/blog/category/soft-skills/ethics/</ext-link></mixed-citation></ref><ref id="CR11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carr</surname><given-names>N</given-names></name></person-group><source>Is google making us stupid?</source><year>2008</year><publisher-loc>Boston</publisher-loc><publisher-name>The Atlantic</publisher-name></element-citation></ref><ref id="CR12"><mixed-citation publication-type="other">Chakhoyan A (2018) Tech companies could achieve much more by serving the Common Good. <ext-link ext-link-type="uri" xlink:href="https://www.weforum.org/agenda/2018/08/tech-companies-achieve-more-serving-common-good-3-steps">https://www.weforum.org/agenda/2018/08/tech-companies-achieve-more-serving-common-good-3-steps</ext-link></mixed-citation></ref><ref id="CR13"><mixed-citation publication-type="other">Child Mind Institute (2017) Children&#x02019;s Health Report: Smart phones and Social Media. <ext-link ext-link-type="uri" xlink:href="https://childmind.org/report/2017-childrens-mental-health-report/smartphones-social-media/">https://childmind.org/report/2017-childrens-mental-health-report/smartphones-social-media/</ext-link></mixed-citation></ref><ref id="CR14"><mixed-citation publication-type="other">Collier R (2015) The High Tech Economy, Work, and Democracy 2.0. <ext-link ext-link-type="uri" xlink:href="https://escholarship.org/uc/item/4t83j7cw">https://escholarship.org/uc/item/4t83j7cw</ext-link></mixed-citation></ref><ref id="CR201"><mixed-citation publication-type="other">Condliffe J (2019) Algorithmic bias is bad. Uncovering it is Good. <ext-link ext-link-type="uri" xlink:href="https://www.nytimes.com/2019/11/15/technology/algorithmic-ai-bias.html">https://www.nytimes.com/2019/11/15/technology/algorithmic-ai-bias.html</ext-link></mixed-citation></ref><ref id="CR202"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>De Lazari-Radek</surname><given-names>K</given-names></name><name><surname>Singer</surname><given-names>P</given-names></name></person-group><source>Utilitarianism: a very short introduction</source><year>2017</year><publisher-loc>Oxford</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="CR15"><mixed-citation publication-type="other">de Looper C (2019) Report finds Apple Routinely favors its own Apps in App Store searches. <ext-link ext-link-type="uri" xlink:href="https://www.digitaltrends.com/mobile/apple-app-store-search-rankings-news/">https://www.digitaltrends.com/mobile/apple-app-store-search-rankings-news/</ext-link></mixed-citation></ref><ref id="CR16"><mixed-citation publication-type="other">Deb S (2014) Information Technology, Its Impact on Society and Its Future. <ext-link ext-link-type="uri" xlink:href="http://article.sapub.org/10.5923.j.ac.20140401.07.html">http://article.sapub.org/10.5923.j.ac.20140401.07.html</ext-link></mixed-citation></ref><ref id="CR17"><mixed-citation publication-type="other">Dellinger A (2019) How the Biggest Tech Companies spent Half a Billion Dollars Lobbying Congress. <ext-link ext-link-type="uri" xlink:href="https://www.forbes.com/sites/ajdellinger/2019/04/30/how-the-biggest-tech-companies-spent-half-a-billion-dollars-lobbying-congress/#7dc596c957c9">https://www.forbes.com/sites/ajdellinger/2019/04/30/how-the-biggest-tech-companies-spent-half-a-billion-dollars-lobbying-congress/#7dc596c957c9</ext-link></mixed-citation></ref><ref id="CR18"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dubal</surname><given-names>V</given-names></name></person-group><source>Who stands between you and AI dystopia? These Google activists</source><year>2019</year><publisher-loc>London</publisher-loc><publisher-name>The Guardian</publisher-name><fpage>19</fpage></element-citation></ref><ref id="CR19"><mixed-citation publication-type="other">Edwards J (2019) &#x02018;Carcolypse&#x02019; now: Lyft&#x02019;s founders are right-we&#x02019;re now in the end game for car ownership. <ext-link ext-link-type="uri" xlink:href="https://www.businessinsider.com/carpocalypse-cars-automobile-sales-data-us-europe-2019-3">https://www.businessinsider.com/carpocalypse-cars-automobile-sales-data-us-europe-2019-3</ext-link></mixed-citation></ref><ref id="CR301"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eubanks</surname><given-names>V</given-names></name></person-group><source>Automating inequality: how tech tools profile, police, and punish the poor</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>St. Martin&#x02019;s Press</publisher-name></element-citation></ref><ref id="CR20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finnemore</surname><given-names>M</given-names></name></person-group><article-title>Ethical Dilemmas in Cyberspace</article-title><source>Ethics Int Aff.</source><year>2018</year><volume>32</volume><issue>4</issue><fpage>457</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1017/S0892679418000576</pub-id></element-citation></ref><ref id="CR21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Floridi</surname><given-names>L</given-names></name></person-group><article-title>Distributed morality in an information society</article-title><source>Sci Ethics</source><year>2013</year><volume>19</volume><issue>3</issue><fpage>727</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1007/s11948-012-9413-4</pub-id></element-citation></ref><ref id="CR22"><mixed-citation publication-type="other">Forbes Insights (2019) Rise of the Chief Ethics Officer. <ext-link ext-link-type="uri" xlink:href="https://www.forbes.com/sites/insights-intelai/2019/03/27/rise-of-the-chief-ethics-officer/#5b1f5c105aba">https://www.forbes.com/sites/insights-intelai/2019/03/27/rise-of-the-chief-ethics-officer/#5b1f5c105aba</ext-link></mixed-citation></ref><ref id="CR23"><mixed-citation publication-type="other">Forbes Technical Council (2018) <ext-link ext-link-type="uri" xlink:href="https://www.forbes.com/sites/forbestechcouncil/2018/12/27/13-tech-experts-predict-the-industrys-biggest-challenges-in-2019/#666b8de91bcd">https://www.forbes.com/sites/forbestechcouncil/2018/12/27/13-tech-experts-predict-the-industrys-biggest-challenges-in-2019/#666b8de91bcd</ext-link></mixed-citation></ref><ref id="CR24"><mixed-citation publication-type="other">Friedman T (2016) Thank you for being late. New York: an optimist&#x02019;s guide to thriving in the age of accelerations. New York: Farrar, Strauss, and Giroux</mixed-citation></ref><ref id="CR25"><mixed-citation publication-type="other">Gardner G (2016) Why most self-driving cars will be electric. <ext-link ext-link-type="uri" xlink:href="https://www.usatoday.com/story/money/cars/2016/09/19/why-most-self-driving-cars-electric/90614734/">https://www.usatoday.com/story/money/cars/2016/09/19/why-most-self-driving-cars-electric/90614734/</ext-link></mixed-citation></ref><ref id="CR26"><mixed-citation publication-type="other">GDPR (2018) 2018 reform of EU data protection rules, <ext-link ext-link-type="uri" xlink:href="https://ec.europa.eu/commission/priorities/justice-and-fundamental-rights/data-protection/2018-reform-eu-data-protection-rules_en">https://ec.europa.eu/commission/priorities/justice-and-fundamental-rights/data-protection/2018-reform-eu-data-protection-rules_en</ext-link></mixed-citation></ref><ref id="CR27"><mixed-citation publication-type="other">Gelles D, Yaffe-Bellamy D (2019) <ext-link ext-link-type="uri" xlink:href="https://www.nytimes.com/2019/08/19/business/business-roundtable-ceos-corporations.html">https://www.nytimes.com/2019/08/19/business/business-roundtable-ceos-corporations.html</ext-link></mixed-citation></ref><ref id="CR28"><mixed-citation publication-type="other">Glatter R (2018) Digital Addiction: A Recipe for Isolation, Depression, and Anxiety. <ext-link ext-link-type="uri" xlink:href="https://www.forbes.com/sites/robertglatter/2018/04/13/digital-addiction-a-recipe-for-isolation-depression-and-anxiety/#5f4049ef5f6b">https://www.forbes.com/sites/robertglatter/2018/04/13/digital-addiction-a-recipe-for-isolation-depression-and-anxiety/#5f4049ef5f6b</ext-link></mixed-citation></ref><ref id="CR29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>R</given-names></name></person-group><source>The rise and fall of American growth</source><year>2016</year><publisher-loc>Princeton</publisher-loc><publisher-name>Princeton University Press</publisher-name></element-citation></ref><ref id="CR30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Greene</surname><given-names>L</given-names></name></person-group><source>Silicon states: the power and politics of big tech</source><year>2018</year><publisher-loc>Berkeley</publisher-loc><publisher-name>Counterpoint</publisher-name></element-citation></ref><ref id="CR31"><mixed-citation publication-type="other">Gregory C (2018) Internet Addiction Disorder. <ext-link ext-link-type="uri" xlink:href="https://www.psycom.net/iadcriteria.html">https://www.psycom.net/iadcriteria.html</ext-link></mixed-citation></ref><ref id="CR32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harari</surname><given-names>Y</given-names></name></person-group><source>Sapiens: a brief history of humankind</source><year>2011</year><publisher-loc>New York</publisher-loc><publisher-name>Harper Collins</publisher-name></element-citation></ref><ref id="CR33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harari</surname><given-names>Y</given-names></name></person-group><source>Why technology favors tyranny</source><year>2018</year><publisher-loc>Boston</publisher-loc><publisher-name>The Atlantic</publisher-name></element-citation></ref><ref id="CR34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardisty</surname><given-names>D</given-names></name><name><surname>Appelt</surname><given-names>K</given-names></name><name><surname>Weber</surname><given-names>E</given-names></name></person-group><article-title>Good or bad, we want it now: fixed cost present bias for gains and losses explains magnitude asymmetries in intertemporal choice</article-title><source>J Behav Dec Mak</source><year>2012</year><volume>26</volume><issue>4</issue><fpage>348</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1002/bdm.1771</pub-id></element-citation></ref><ref id="CR35"><mixed-citation publication-type="other">Heisler A (2018) 5 Critical Risks facing the technology industry, risk and insurance</mixed-citation></ref><ref id="CR36"><mixed-citation publication-type="other">Hirst T (2014) Does Technological Innovation Increase Unemployment? World Economic Forum. <ext-link ext-link-type="uri" xlink:href="https://www.weforum.org/agenda/2014/11/does-technological-innovation-increase-unemployment/">https://www.weforum.org/agenda/2014/11/does-technological-innovation-increase-unemployment/</ext-link></mixed-citation></ref><ref id="CR37"><mixed-citation publication-type="other">Human Rights Watch (2016) Stifling Dissent: The Criminalization of Peaceful Expression in India. <ext-link ext-link-type="uri" xlink:href="https://www.hrw.org/sites/default/files/report_pdf/india0516.pdf">https://www.hrw.org/sites/default/files/report_pdf/india0516.pdf</ext-link></mixed-citation></ref><ref id="CR38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Husain</surname><given-names>A</given-names></name></person-group><source>The sentient machine: the coming age of artificial intelligence</source><year>2017</year><publisher-loc>New York</publisher-loc><publisher-name>Scribner</publisher-name></element-citation></ref><ref id="CR39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Isaac</surname><given-names>M</given-names></name></person-group><source>Facebook&#x02019;s reaction to an &#x02018;Existential&#x02019; Threat</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR40"><mixed-citation publication-type="other">Ives N (2019) Big Advertisers and Social Media Form Alliance to fight &#x02018;Unsafe&#x02019; Content Online, <italic>Wall St J</italic></mixed-citation></ref><ref id="CR41"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jasanoff</surname><given-names>S</given-names></name></person-group><source>The ethics of invention: technology and the human future</source><year>2016</year><publisher-loc>New York</publisher-loc><publisher-name>Norton</publisher-name></element-citation></ref><ref id="CR42"><mixed-citation publication-type="other">Kelman S (1981) Cost-Benefit Analysis: An Ethical Critique, <italic>Regulation</italic>, pp 33&#x02013;40</mixed-citation></ref><ref id="CR43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kingsley</surname><given-names>P</given-names></name></person-group><source>Life in an internet shutdown: crossing borders for email and contraband SIM cards</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kingwell</surname><given-names>M</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Prado</surname><given-names>C</given-names></name></person-group><article-title>Bored, addicted, or both: how we use social media now</article-title><source>Social media and your brain</source><year>2017</year><publisher-loc>ABC-CLIO</publisher-loc><publisher-name>Santa Barbara</publisher-name></element-citation></ref><ref id="CR45"><mixed-citation publication-type="other">Kramer N (2019) Big stocks&#x02019; Growth Engine faces a Big Slowdown. <ext-link ext-link-type="uri" xlink:href="https://www.investopedia.com/news/tech-stocks-growth-engine-faces-big-slowdown/">https://www.investopedia.com/news/tech-stocks-growth-engine-faces-big-slowdown/</ext-link></mixed-citation></ref><ref id="CR46"><mixed-citation publication-type="other">Kvochko E (2013) Five ways technology can help the Economy. <ext-link ext-link-type="uri" xlink:href="https://www.weforum.org/agenda/2013/04/five-ways-technology-can-help-the-economy/">https://www.weforum.org/agenda/2013/04/five-ways-technology-can-help-the-economy/</ext-link></mixed-citation></ref><ref id="CR47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lafrance</surname><given-names>A</given-names></name></person-group><source>The algorithm that makes preschoolers obsessed with youtube</source><year>2017</year><publisher-loc>Boston</publisher-loc><publisher-name>The Atlantic</publisher-name></element-citation></ref><ref id="CR48"><mixed-citation publication-type="other">Lanchester J (2019) Leveling the playing field. Time pp 75&#x02013;77</mixed-citation></ref><ref id="CR49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laudon</surname><given-names>K</given-names></name></person-group><article-title>Ethical concepts and information technology</article-title><source>Commun ACM.</source><year>1995</year><volume>38</volume><fpage>12</fpage><pub-id pub-id-type="doi">10.1145/219663.219677</pub-id></element-citation></ref><ref id="CR50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>K</given-names></name></person-group><source>AI Super-powers: China, silicon valley, and the new world order</source><year>2018</year><publisher-loc>New York</publisher-loc><publisher-name>Houghton Mifflin</publisher-name></element-citation></ref><ref id="CR51"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Levitsky</surname><given-names>S</given-names></name><name><surname>Ziblatt</surname><given-names>D</given-names></name></person-group><source>How democracies die</source><year>2018</year><publisher-loc>New York</publisher-loc><publisher-name>Crown Publishing</publisher-name></element-citation></ref><ref id="CR52"><mixed-citation publication-type="other">Levy A (2019) The government is threatening big tech-and the market just took notice. <ext-link ext-link-type="uri" xlink:href="https://www.cnbc.com/2019/06/03/apple-google-facebook-amazon-facing-potential-regulatory-scrutiny.html">https://www.cnbc.com/2019/06/03/apple-google-facebook-amazon-facing-potential-regulatory-scrutiny.html</ext-link></mixed-citation></ref><ref id="CR53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lohr</surname><given-names>S</given-names></name></person-group><source>How to Rein Big Tech? Here are 4 ideas from drastic to modest</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lohr</surname><given-names>S</given-names></name></person-group><source>Older and wiser, microsoft avoids scrutiny and blame</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR55"><mixed-citation publication-type="other">Lowry R, Peterson M (2011) Cost-benefit analysis and non-utilitarian ethics. <ext-link ext-link-type="uri" xlink:href="https://journals.sagepub.com/doi/10.1177/1470594X11416767">https://journals.sagepub.com/doi/10.1177/1470594X11416767</ext-link></mixed-citation></ref><ref id="CR56"><mixed-citation publication-type="other">Ma M (2018) The impact of technology on democracy. <ext-link ext-link-type="uri" xlink:href="https://www.wsj.com/articles/the-impact-of-technology-on-democracy-1541943796">https://www.wsj.com/articles/the-impact-of-technology-on-democracy-1541943796</ext-link></mixed-citation></ref><ref id="CR57"><mixed-citation publication-type="other">Mack, T. 2014. Privacy and the Surveillance Explosion. <italic>Futurist</italic>, Jan/Feb</mixed-citation></ref><ref id="CR58"><mixed-citation publication-type="other">Markkula Center (2019) Approaches to Ethical Decision-making. <ext-link ext-link-type="uri" xlink:href="https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/">https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/</ext-link></mixed-citation></ref><ref id="CR59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCabe</surname><given-names>D</given-names></name></person-group><article-title>Lawmakers urge aggressive action from regulators on Big Tech</article-title><source>The New York Times</source><year>2019</year><volume>18</volume><fpage>B4</fpage></element-citation></ref><ref id="CR60"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McFarlane</surname><given-names>L</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Prado</surname><given-names>C</given-names></name></person-group><article-title>Prices paid for Social Media use</article-title><source>Social Media and your Brain</source><year>2017</year><publisher-loc>ABC-CLIO</publisher-loc><publisher-name>Santa Barbara</publisher-name></element-citation></ref><ref id="CR61"><mixed-citation publication-type="other">McKinsey Global Institute (2017) Technology, Jobs, and the Future of Work</mixed-citation></ref><ref id="CR62"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Metz</surname><given-names>C</given-names></name><name><surname>Singer</surname><given-names>N</given-names></name></person-group><source>Amazon Asked to Limit Facial Recognition Software</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Milner</surname><given-names>G</given-names></name></person-group><source>Pinpoint: How GPS is changing Technology, Culture, and our Minds</source><year>2016</year><publisher-loc>New York</publisher-loc><publisher-name>Norton</publisher-name></element-citation></ref><ref id="CR64"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Morozov</surname><given-names>E</given-names></name></person-group><source>It is not enough to break up big tech. We need to imagine a better alternative</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The Guardian</publisher-name><fpage>11</fpage></element-citation></ref><ref id="CR65"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mozur</surname><given-names>A</given-names></name></person-group><source>A Genocide Incited on Facebook, with posts from Myanmar&#x02019;s military</source><year>2018</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR66"><mixed-citation publication-type="other">Newman L (2019) Facial Recognition has reached its Breaking Point. <ext-link ext-link-type="uri" xlink:href="https://www.wired.com/story/facial-recognition-regulation/">https://www.wired.com/story/facial-recognition-regulation/</ext-link></mixed-citation></ref><ref id="CR67"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nicas</surname><given-names>J</given-names></name></person-group><source>Purging rivals</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR68"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nicas</surname><given-names>J</given-names></name><name><surname>Weise</surname><given-names>K</given-names></name><name><surname>Isaac</surname><given-names>M</given-names></name></person-group><source>4 Tech Giants, one issue: power</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR69"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Brockman</surname><given-names>J</given-names></name></person-group><article-title>Limitations of opaque learning machines</article-title><source>Possible minds: 25 ways of looking at AI</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>Penguin</publisher-name></element-citation></ref><ref id="CR70"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pichai</surname><given-names>Z</given-names></name></person-group><source>Privacy should not be a luxury good</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name><fpage>A27</fpage></element-citation></ref><ref id="CR71"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pinker</surname><given-names>S</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Brockman</surname><given-names>J</given-names></name></person-group><article-title>The underappreciated causal power of ideas</article-title><source>Possible minds: 25 ways of looking at AI</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>Penguin</publisher-name></element-citation></ref><ref id="CR72"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Postman</surname><given-names>N</given-names></name></person-group><source>Technopoly: the surrender of culture to technology</source><year>1993</year><publisher-loc>New York</publisher-loc><publisher-name>Random House</publisher-name></element-citation></ref><ref id="CR73"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Prado</surname><given-names>C</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Prado</surname><given-names>C</given-names></name></person-group><article-title>The role of habit</article-title><source>Social media and your brain</source><year>2017</year><publisher-loc>ABC-CLIO</publisher-loc><publisher-name>Santa Barbara</publisher-name></element-citation></ref><ref id="CR74"><mixed-citation publication-type="other">Prensky M (2001) Do they really think differently? On the Horizon</mixed-citation></ref><ref id="CR75"><mixed-citation publication-type="other">Radovan M (2013) ICT and Human Progress, Information Society. vol. 25, Issue 5</mixed-citation></ref><ref id="CR76"><mixed-citation publication-type="other">Ramakrishnan V (2019) Will computers become our overlords? In: J. Brockman, ed. Possible Minds: 25 Ways of looking at AI</mixed-citation></ref><ref id="CR77"><mixed-citation publication-type="other">Rangarajan S (2018) Here&#x02019;s the clearest picture of Silicon Valley&#x02019;s diversity yet: It&#x02019;s bad. But some companies are less bad. <ext-link ext-link-type="uri" xlink:href="https://www.revealnews.org/article/heres-the-clearest-picture-of-silicon-valleys-diversity-yet/">https://www.revealnews.org/article/heres-the-clearest-picture-of-silicon-valleys-diversity-yet/</ext-link></mixed-citation></ref><ref id="CR78"><mixed-citation publication-type="other">Ratnesar R (2019) Trust: Microsoft&#x02019;s Brad Smith is trying to restore public faith in big tech, <italic>Time</italic></mixed-citation></ref><ref id="CR79"><mixed-citation publication-type="other">Rezaian J (2019) Dictators and the internet: a love story. The Washington Post</mixed-citation></ref><ref id="CR80"><mixed-citation publication-type="other">Roose K (2019). The Phony Patriots of Silicon Valley. <italic>The New York Times</italic>, Aug. 13, pp. B1, 5</mixed-citation></ref><ref id="CR81"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rosen</surname><given-names>C</given-names></name></person-group><source>Virtual friendship and the new narcissism</source><year>2007</year><publisher-loc>Summer</publisher-loc><publisher-name>The New Atlantis</publisher-name></element-citation></ref><ref id="CR82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>J</given-names></name></person-group><article-title>The obvious invisibility of the relationship between technology and social values</article-title><source>Int J Sci Soc</source><year>2011</year><volume>2</volume><fpage>1</fpage><pub-id pub-id-type="doi">10.18848/1836-6236/CGP/v02i01/51515</pub-id></element-citation></ref><ref id="CR83"><mixed-citation publication-type="other">Rutenberg J (2019) The dark, faceless threat to the 2020 race, The New York Times International Edition, p.8</mixed-citation></ref><ref id="CR84"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sagan</surname><given-names>C</given-names></name></person-group><source>Broca&#x02019;s brain</source><year>1974</year><publisher-loc>New York</publisher-loc><publisher-name>Random House</publisher-name></element-citation></ref><ref id="CR85"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Satariano</surname><given-names>A</given-names></name></person-group><source>As E.U. vote nears, Facebook uses hub to uproot meddling</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scharre</surname><given-names>P</given-names></name></person-group><article-title>Killer apps: the real dangers of an AI arms race</article-title><source>Foreign Affairs.</source><year>2019</year><volume>98</volume><fpage>135</fpage></element-citation></ref><ref id="CR87"><mixed-citation publication-type="other">Sheng E (2018) Silicon valley&#x02019;s dirty secret: using a shadow workforce of contract employees to drive profits. <ext-link ext-link-type="uri" xlink:href="https://www.cnbc.com/2018/10/22/silicon-valley-using-contract-employees-to-drive-profits.html">https://www.cnbc.com/2018/10/22/silicon-valley-using-contract-employees-to-drive-profits.html</ext-link></mixed-citation></ref><ref id="CR88"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>N</given-names></name></person-group><source>Tech&#x02019;s &#x02018;Dark Side&#x02019;</source><year>2018</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR203"><mixed-citation publication-type="other">Singer T (2019) The Baroness fighting to protect children online. <ext-link ext-link-type="uri" xlink:href="https://www.nytimes.com/2019/08/27/technology/baroness-kidron-children-tech.html">https://www.nytimes.com/2019/08/27/technology/baroness-kidron-children-tech.html</ext-link></mixed-citation></ref><ref id="CR89"><mixed-citation publication-type="other">Smith C (2019) Tech Companies Might Face More Antitrust Scrutiny From States. <ext-link ext-link-type="uri" xlink:href="https://www.barrons.com/articles/tech-companies-antitrust-scrutiny-state-attorneys-general-google-facebook-alphabet-amazon-apple-51566313415">https://www.barrons.com/articles/tech-companies-antitrust-scrutiny-state-attorneys-general-google-facebook-alphabet-amazon-apple-51566313415</ext-link></mixed-citation></ref><ref id="CR90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stahl</surname><given-names>B</given-names></name><name><surname>Timmermans</surname><given-names>J</given-names></name><name><surname>Flick</surname><given-names>C</given-names></name></person-group><article-title>Ethics of emerging information and communication technologies</article-title><source>Science and Public Policy</source><year>2017</year><volume>44</volume><fpage>3</fpage></element-citation></ref><ref id="CR91"><mixed-citation publication-type="other">Stettner A (2018) Mounting a Response to Technological Unemployment. The Century Foundation. <ext-link ext-link-type="uri" xlink:href="https://tcf.org/content/report/mounting-response-technological-unemployment/%3fsession%3d1">https://tcf.org/content/report/mounting-response-technological-unemployment/?session=1</ext-link></mixed-citation></ref><ref id="CR92"><mixed-citation publication-type="other">Stevis-Gridneff M (2019) E.U.&#x02019;s New Digital Czar: &#x02018;Most Powerful Regulator of big tech on the Planet&#x02019;. <ext-link ext-link-type="uri" xlink:href="https://www.nytimes.com/2019/09/10/world/europe/margrethe-vestager-european-union-tech-regulation.html">https://www.nytimes.com/2019/09/10/world/europe/margrethe-vestager-european-union-tech-regulation.html</ext-link></mixed-citation></ref><ref id="CR93"><mixed-citation publication-type="other">Sumpter D (2018) Outnumbered: From Facebook and Google to fake news and filter-bubbles-the algorithms that control our lives. London: Bloomsbury Sigma</mixed-citation></ref><ref id="CR94"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Swisher</surname><given-names>K</given-names></name></person-group><source>Who will teach Silicon Valley to be ethical?</source><year>2018</year><publisher-loc>New York</publisher-loc><publisher-name>The New York Times</publisher-name></element-citation></ref><ref id="CR204"><mixed-citation publication-type="other">Swisher K (2019) The expensive education of Mark Zuckerberg and Silicon Valley. <ext-link ext-link-type="uri" xlink:href="https://www.nytimes.com/2018/08/02/opinion/the-expensive-education-of-mark-zuckerberg-and-silicon-valley.html">https://www.nytimes.com/2018/08/02/opinion/the-expensive-education-of-mark-zuckerberg-and-silicon-valley.html</ext-link></mixed-citation></ref><ref id="CR95"><mixed-citation publication-type="other">The Economist (2018) How democracy dies</mixed-citation></ref><ref id="CR96"><mixed-citation publication-type="other">The Economist (2019) Technology Quarterly: The Internet of Things</mixed-citation></ref><ref id="CR97"><mixed-citation publication-type="other">Tufekci Z (2019) Zuckerberg&#x02019;s So-Called Shift toward Privacy. <ext-link ext-link-type="uri" xlink:href="https://www.nytimes.com/2019/03/07/opinion/zuckerberg-privacy-facebook.html">https://www.nytimes.com/2019/03/07/opinion/zuckerberg-privacy-facebook.html</ext-link></mixed-citation></ref><ref id="CR98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varlan</surname><given-names>S</given-names></name><name><surname>Tomozei</surname><given-names>C</given-names></name></person-group><article-title>Categories of ethical issues in the use of information and communication technologies</article-title><source>J Innov Psychol Educ Didact</source><year>2018</year><volume>22</volume><fpage>2</fpage></element-citation></ref><ref id="CR205"><mixed-citation publication-type="other">Vogelberg K (2018) Industries must adopt ethics along with technology. <ext-link ext-link-type="uri" xlink:href="https://techcrunch.com/2018/12/20/industries-must-adopt-ethics-along-with-technology/">https://techcrunch.com/2018/12/20/industries-must-adopt-ethics-along-with-technology/</ext-link></mixed-citation></ref><ref id="CR100"><mixed-citation publication-type="other">Wakabayashi D, Chen B (2019) Google says it has found religion on privacy. The New York Times, p. B3</mixed-citation></ref><ref id="CR206"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Walsh</surname><given-names>T</given-names></name></person-group><source>Machines that think: the future of artificial intelligence</source><year>2018</year><publisher-loc>New York</publisher-loc><publisher-name>Prometheus</publisher-name></element-citation></ref><ref id="CR101"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Webb</surname><given-names>A</given-names></name></person-group><source>The big nine: how the tech titans &#x00026; their thinking machines could warp humanity</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>Public Affairs</publisher-name><fpage>52</fpage><lpage>96</lpage></element-citation></ref><ref id="CR102"><mixed-citation publication-type="other">West D (2018) Why Tech Companies Need a Code of Ethics for Software Development, <ext-link ext-link-type="uri" xlink:href="https://www.entrepreneur.com/article/311410">https://www.entrepreneur.com/article/311410</ext-link></mixed-citation></ref><ref id="CR103"><mixed-citation publication-type="other">Wharton (2019) Regulating big tech: is the day of reckoning coming? <ext-link ext-link-type="uri" xlink:href="https://knowledge.wharton.upenn.edu/article/regulating-big-tech-is-a-day-of-reckoning-coming/">https://knowledge.wharton.upenn.edu/article/regulating-big-tech-is-a-day-of-reckoning-coming/</ext-link></mixed-citation></ref><ref id="CR104"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>White</surname><given-names>R</given-names></name></person-group><source>Railroaded: the transcontinental and the making of modern America</source><year>2011</year><publisher-loc>New York</publisher-loc><publisher-name>Norton</publisher-name></element-citation></ref><ref id="CR105"><mixed-citation publication-type="other">Wilson A (2019) A Global Call to end online Extremism. <ext-link ext-link-type="uri" xlink:href="https://foreignpolicy.com/2019/05/15/a-global-call-to-end-online-extremism-christchurch-jacinda-ardern-macron-violent-extremism-twitter-google-facebook-sri-lanka/">https://foreignpolicy.com/2019/05/15/a-global-call-to-end-online-extremism-christchurch-jacinda-ardern-macron-violent-extremism-twitter-google-facebook-sri-lanka/</ext-link></mixed-citation></ref><ref id="CR106"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Winner</surname><given-names>L</given-names></name></person-group><source>The whale and the reactor</source><year>1986</year><publisher-loc>Chicago</publisher-loc><publisher-name>University of Chicago Press</publisher-name></element-citation></ref><ref id="CR107"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>J</given-names></name></person-group><source>A White-collar sweat shop: Google Assistant contractors allege wage theft</source><year>2019</year><publisher-loc>Boston</publisher-loc><publisher-name>The Guardian</publisher-name></element-citation></ref><ref id="CR108"><mixed-citation publication-type="other">Wursthorn M (2019) Big Tech Stocks Lose their Luster. <ext-link ext-link-type="uri" xlink:href="https://www.wsj.com/articles/the-stock-market-needs-a-new-leader-11566811800">https://www.wsj.com/articles/the-stock-market-needs-a-new-leader-11566811800</ext-link></mixed-citation></ref><ref id="CR109"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zuboff</surname><given-names>S</given-names></name></person-group><source>The age of surveillance capitalism: the fight for a human future at the new frontier of power</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>Hachette</publisher-name></element-citation></ref></ref-list></back></article>